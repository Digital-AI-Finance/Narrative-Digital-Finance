
@inproceedings{shukla_raphael_2023,
	address = {Singapore (Hybrid)},
	title = {Raphael at {ArAIEval} {Shared} {Task}: {Understanding} {Persuasive} {Language} and {Tone}, an {LLM} {Approach}},
	shorttitle = {Raphael at {ArAIEval} {Shared} {Task}},
	url = {https://aclanthology.org/2023.arabicnlp-1.60/},
	doi = {10.18653/v1/2023.arabicnlp-1.60},
	abstract = {The widespread dissemination of propaganda and disinformation on both social media and mainstream media platforms has become an urgent concern, attracting the interest of various stakeholders such as government bodies and social media companies. The challenge intensifies when dealing with understudied languages like Arabic. In this paper, we outline our approach for detecting persuasion techniques in Arabic tweets and news article paragraphs. We submitted our system to ArAIEval 2023 Shared Task 1, covering both subtasks. Our main contributions include utilizing GPT-3 to discern tone and potential persuasion techniques in text, exploring various base language models, and employing a multi-task learning approach for the specified subtasks.},
	urldate = {2025-01-23},
	booktitle = {Proceedings of {ArabicNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Shukla, Utsav and Vyas, Manan and Tiwari, Shailendra},
	editor = {Sawaf, Hassan and El-Beltagy, Samhaa and Zaghouani, Wajdi and Magdy, Walid and Abdelali, Ahmed and Tomeh, Nadi and Abu Farha, Ibrahim and Habash, Nizar and Khalifa, Salam and Keleg, Amr and Haddad, Hatem and Zitouni, Imed and Mrini, Khalil and Almatham, Rawan},
	month = dec,
	year = {2023},
	pages = {589--593},
}

@article{wang_bankruptcy_2020,
	title = {Bankruptcy and the {COVID}-19 {Crisis}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3690398},
	doi = {10.2139/ssrn.3690398},
	abstract = {We examine the impact of the COVID-19 economic crisis on business and consumer bankruptcies in the United States using real-time data on the universe of ﬁlings. Historically, bankruptcies have closely tracked the business cycle and contemporaneous unemployment rates. However, this relationship has reversed during the COVID-19 crisis thus far. While aggregate ﬁling rates were very similar to 2019 levels prior to the severe onset of the pandemic, ﬁlings by consumers and small businesses dropped dramatically starting in mid-March, contrary to media reports and many experts’ expectations. The total number of bankruptcy ﬁlings is down by 27 percent year-over-year between January and August. Consumer and business Chapter 7 ﬁlings rebounded moderately starting in mid-April and stabilized around 20 percent below 2019 levels, but Chapter 13 ﬁlings remained at 55-65 percent below 2019 levels through the end of August. In contrast to the 2007-9 recession, states with a larger increase in unemployment between April and July experienced greater drops in bankruptcies. Although they make up a small share of overall bankruptcies, Chapter 11 ﬁlings by large corporations have increased since 2019, and are up nearly 200 percent year-over-year from January through August. These patterns suggest that the ﬁnancial experiences of consumers, small businesses, and large corporations have diverged during the COVID-19 crisis. Large businesses have continued to seek and receive relief from the bankruptcy system as they would during a normal recession, and relatively wealthy homeowners have on average beneﬁted from the ﬁscal stimulus and housing moratoria mandated by the CARES Act and other policies. However, non-homeowners and small businesses may face ﬁnancial, physical, and technological barriers to accessing the bankruptcy system, especially in the areas hardest-hit by unemployment.},
	language = {en},
	urldate = {2025-01-22},
	journal = {SSRN Electronic Journal},
	author = {Wang, Jialan and Yang, Jeyul and Iverson, Benjamin Charles and Kluender, Raymond},
	year = {2020},
}

@article{megerdoomian_automated_2019,
	title = {Automated {Narrative} {Extraction} from {Administrative} {Records}},
	abstract = {The U.S. Probation and Pretrial Services Office staff produce billions of pages of information on defendants’ and offenders’ profile and conduct. While it is critical for probation officers and district chiefs to have up-to-date knowledge on their clients to better assist and reduce risk of recidivism, the data are often stored in narrative texts in multiple large documents. As a result, these records remain mostly out of reach without the use of painstaking manual review. This paper describes an analytic prototype developed to automatically acquire structured information from natural language text in probation office documents through the application of PDF content extraction, text mining, and language analytics. Since serious mental illness is very prevalent in the U.S. corrections system, the first phase of the project focused on extracting information and constructing timelines from narrative text regarding the defendants’ mental health conditions, substance use and treatment history.},
	language = {en},
	author = {Megerdoomian, Karine and Marsh, Amy B and Scott, Eric O and Branting, Karl and Modly, Nick and Wariyar, Sujit B and Horowitz, Charles E and Petersen, Stacy J},
	year = {2019},
}

@article{diaz_sobrino_narrative_2022,
	title = {The narrative about the economy as a shadow forecast: an analysis using {Bank} of {Spain} quarterly reports},
	volume = {54},
	issn = {0003-6846},
	shorttitle = {The narrative about the economy as a shadow forecast},
	url = {https://doi.org/10.1080/00036846.2021.1999386},
	doi = {10.1080/00036846.2021.1999386},
	abstract = {This paper constructs a text-based indicator that reflects the sentiment of the Bank of Spain economic outlook reports. Our sentiment indicator mimics very closely the first release of the GDP growth rate, which is published after the publication of the reports, and the Bank of Spain’s quarterly forecasts of the GDP growth rate. In addition, not only the narrative is consistent with the quantitative projections, but it also complements them by discussing information which is not directly reflected in the point forecasts, and may put on the table potential risks that will be included in the numerical projections of the next quarter. Thus, while the quantitative projections tend to underestimate the GDP growth rate especially during upturns, the narrative allows to outweigh this conservative bias. Overall, from a Central Bank’s communication perspective, it is the combination of quantitative forecast and narrative that provides a more precise picture of expected economic activity.},
	number = {25},
	urldate = {2025-01-21},
	journal = {Applied Economics},
	author = {Díaz Sobrino, Nélida and Ghirelli, Corinna and Hurtado, Samuel and Pérez, Javier J. and Urtasun, Alberto},
	month = may,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00036846.2021.1999386},
	keywords = {C53, E37, E58, E66, Textual analysis, central bank reports, forecasting, gdp growth rate},
	pages = {2874--2887},
}

@article{chen_covid_2022,
	title = {{COVID} risk narratives: a computational linguistic approach to the econometric identification of narrative risk during a pandemic},
	volume = {4},
	issn = {2524-6186},
	shorttitle = {{COVID} risk narratives},
	url = {https://doi.org/10.1007/s42521-021-00045-3},
	doi = {10.1007/s42521-021-00045-3},
	abstract = {In this paper, we study the role of narratives in stock markets with a particular focus on the relationship with the ongoing COVID-19 pandemic. The pandemic represents a natural setting for the development of viral financial market narratives. We thus treat the pandemic as a natural experiment on the relation between prevailing narratives and financial markets. We adopt natural language processing (NLP) on financial news to characterize the evolution of important narratives. Doing so, we reduce the high-dimensional narrative information to few interpretable and important features while avoiding over-fitting. In addition to the common features, we consider virality as a novel feature of narratives, inspired by Shiller (Am Econ Rev 107:967–1004, 2017). Our aim is to establish whether the prevailing narratives drive or are driven by stock market conditions. Focusing on the coronavirus narratives, we document some stylized facts about its evolution around a severe event-driven stock market decline. We find the pandemic-relevant narratives are influenced by stock market conditions and act as a cellar for brewing a perennial economic narrative. We successfully identified a perennial risk narrative, whose shock is followed by a severe market drop and a long-term increase of market volatility. In the out-of-sample test, this narrative went viral since the start of the global COVID-19 pandemic, when the pandemic-relevant narratives dominate news media, show negative sentiment and were more linked to “crisis” context. Our findings encourage the use of narratives to evaluate long-term market conditions and to early warn event-driven severe market declines.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {Digital Finance},
	author = {Chen, Yuting and Bredin, Don and Potì, Valerio and Matkovskyy, Roman},
	month = mar,
	year = {2022},
	keywords = {C53, COVID-19, D81, E37, E71, Early warning indicator, G17, G41, Narrative economics, Natural language processing, Tone analysis},
	pages = {17--61},
}

@article{alonso-robisco_analysis_2023,
	title = {Analysis of {CBDC} narrative by central banks using large language models},
	volume = {58},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612323010152},
	doi = {10.1016/j.frl.2023.104643},
	abstract = {One topic that is gaining importance in central bank communication is central bank digital currency (CBDC). To better understand central banks’ stance towards CBDCs, we used different natural language processing techniques on a set of central bank speeches. We found that the sentiment calculated by Large Language Models, and in particular by ChatGPT, is the one that most resembles the sentiment identified by human experts in those same speeches. Our study suggests that LLMs are an effective tool for improving sentiment measurements on specific policy texts, although they are not infallible and may be subject to new risks.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Finance Research Letters},
	author = {Alonso-Robisco, Andres and Carbó, José Manuel},
	month = dec,
	year = {2023},
	pages = {104643},
}

@misc{miori_narratives_2023,
	title = {Narratives from {GPT}-derived {Networks} of {News}, and a link to {Financial} {Markets} {Dislocations}},
	url = {http://arxiv.org/abs/2311.14419},
	doi = {10.48550/arXiv.2311.14419},
	abstract = {Starting from a corpus of economic articles from The Wall Street Journal, we present a novel systematic way to analyse news content that evolves over time. We leverage on state-of-the-art natural language processing techniques (i.e. GPT3.5) to extract the most important entities of each article available, and aggregate co-occurrence of entities in a related graph at the weekly level. Network analysis techniques and fuzzy community detection are tested on the proposed set of graphs, and a framework is introduced that allows systematic but interpretable detection of topics and narratives. In parallel, we propose to consider the sentiment around main entities of an article as a more accurate proxy for the overall sentiment of such piece of text, and describe a case-study to motivate this choice. Finally, we design features that characterise the type and structure of news within each week, and map them to moments of financial markets dislocations. The latter are identified as dates with unusually high volatility across asset classes, and we find quantitative evidence that they relate to instances of high entropy in the high-dimensional space of interconnected news. This result further motivates the pursued efforts to provide a novel framework for the systematic analysis of narratives within news.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Miori, Deborah and Petrov, Constantin},
	month = nov,
	year = {2023},
	note = {arXiv:2311.14419 [q-fin]},
	keywords = {Economics - General Economics, Quantitative Finance - Computational Finance, Quantitative Finance - Economics},
}

@article{agarwal_investor_2024,
	title = {Investor emotions and market bubbles},
	issn = {1573-7179},
	url = {https://doi.org/10.1007/s11156-024-01309-w},
	doi = {10.1007/s11156-024-01309-w},
	abstract = {Asset pricing bubbles are highly emotional market episodes. Despite this, investor emotions are not part of traditional bubble models. We measure the powerful affects influencing investor decisions during speculative market bubbles directly employing textual analysis of media narratives and domain-specific emotion keyword dictionaries and show how understanding investor emotional dynamics helps explain market behavior. Specifically, we focus on the two Chinese stock market bubbles of 2005–2008 and 2014–2016; there is no evidence of investor learning from experience. Despite Chinese media being censored we show it still has strong explanatory power although the independent English language media can provide an additional perspective. Deeper emotions dominate more superficial feelings in information content.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Review of Quantitative Finance and Accounting},
	author = {Agarwal, Vineet and Taffler, Richard J. and Wang, Chenyang},
	month = jul,
	year = {2024},
	keywords = {Asset pricing bubbles, Chinese stock market, Economic narratives, G12, G15, G41, Investor emotions, Textual analysis},
}

@article{taffler_narrative_nodate,
	title = {Narrative {Emotions} and {Market} {Crises}},
	volume = {0},
	issn = {1542-7560},
	url = {https://doi.org/10.1080/15427560.2024.2365723},
	doi = {10.1080/15427560.2024.2365723},
	abstract = {Robert Shiller highlights the role popular stories play in driving economic behavior and argues the need to analyze these scientifically. However, their impacts are difficult to measure directly and often conflict. We show the strength of such stories resides in the emotions they generate, and that the tenor and persuasiveness of financial narratives and their association with the market can be empirically quantified. Specifically, we textually analyze financial media reports to identify the different powerful investor emotions manifest during three recent extreme market periods, dot.com mania, the Global Financial Crisis and the COVID-19 pandemic, constructing original context-specific emotion word dictionaries for this purpose. We find investor emotions are associated with up to 52\% of market returns and 67\% of market uncertainty during these market crises, and provide general evidence that investor emotional dynamics may be time and context invariant.},
	number = {0},
	urldate = {2025-01-21},
	journal = {Journal of Behavioral Finance},
	author = {Taffler, Richard J. and Agarwal, Vineet and Obring, Maximilian},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15427560.2024.2365723},
	keywords = {A12, B41, COVID-19 pandemic, G01, G12, G41, Global Financial Crisis, internet bubble, investor emotions, market pricing, media stories},
	pages = {1--21},
}

@inproceedings{diaf_uncovering_2024,
	address = {Cham},
	title = {Uncovering {Uncertainty} in {Narrative} {Economics}: {A} {Semantic} {Search} {Approach}},
	isbn = {978-3-031-55917-4},
	shorttitle = {Uncovering {Uncertainty} in {Narrative} {Economics}},
	doi = {10.1007/978-3-031-55917-4_26},
	abstract = {The study of narrative economics using text mining techniques has grown recently, with a dominance of unsupervised models built upon the bag-of-word assumption that try to extract meaningful information for further inferences. Yet, word independence remains a constraining hypothesis when the narratives rely on implicit word usage that belongs to a specific jargon. But recent advances in natural language processing offer powerful distributional representation tools to preserve the semantic and syntactic meaning of the text as a reliable alternative to frequency-based probabilistic topic models. Monetary policy, as an important application field of narrative economics, carries uncertainty in its decision-making process as a forward guidance tool, besides being a strategic aspect of its communication policy. It witnessed several attempts to construct uncertainty indices using uncertainty-related word counts, yielding questionable measurements that overlook key technical terms not encompassed in word lists, hence making the computed indices biased and semantically agnostic vis-à-vis the proper jargon. This work proposes an in-depth assessment of uncertainty in a collection of international central bankers’ speeches (1997–2022) and identifies its key drivers using semantic search models, namely, Top2Vec, to uncover nested semantic topic structures at the national and international levels as proxies of uncertainty sources. These proved to be robust in discerning uncertainty features associated with probability and risk, in line with the Keynes-Knight debate about uncertainty in macroeconomics. Moreover, a robust uncertainty index could be built from the similarity between each document and the term uncertainty, either country-specific or internationally, which was found to follow major world financial and banking events of the last two decades.},
	language = {en},
	booktitle = {New {Frontiers} in {Textual} {Data} {Analysis}},
	publisher = {Springer Nature Switzerland},
	author = {Diaf, Sami and Schütze, Florian},
	editor = {Giordano, Giuseppe and Misuraca, Michelangelo},
	year = {2024},
	pages = {323--335},
}

@article{le_studying_2024,
	title = {Studying the impact of profitability, bankruptcy risk, and pandemic on narrative tone in annual reports in an emerging market in the {East}},
	volume = {11},
	copyright = {2024 The Author(s)},
	issn = {2662-9992},
	url = {https://www.nature.com/articles/s41599-024-03980-9},
	doi = {10.1057/s41599-024-03980-9},
	abstract = {The purpose of this paper is to investigate whether the narrative tone of annual reports is influenced by profitability, bankruptcy risk, and pandemic in the context of Vietnam. The study applies the necessary regression analysis steps such as ordinary least squares (OLS), random effects model (REM), fixed effects model (FEM), and feasible generalized least squares (FGLS). Bootstrapping and System Generalized Method of Moments (SGMM) methods are used to test the robustness and address endogeneity and dynamic relationships in the data. The findings show that net tones increase while negative tones decrease in companies with high profitability. Companies at risk of bankruptcy use more negative tone and less net tone than companies that are not at risk of bankruptcy. The study also affirms that bankruptcy risk moderates the relationship between profitability and negative tone. During the COVID-19 pandemic, companies used more positive and negative tones than they did before the pandemic. After the COVID-19 situation stabilized, positive tones were used more, and negative tones were used less than during the outbreak. The research results also recognized that companies do not intend to hide information through impression management when faced with difficult economic conditions. This study has practical implications for investors and information users when considering management disclosures through the narrative tone of annual reports. To our knowledge, this is the first study (1) in an emerging market in the East—where there are fundamental cultural and linguistic differences compared to Western countries, (2) to build a list of Vietnamese words and phrases expressing emotional nuances used in finance and accounting, and (3) refers to the narrative tone of annual reports across different groups of companies.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {Humanities and Social Sciences Communications},
	author = {Le, Binh Thi Hai and Nguyen, Cong Van},
	month = oct,
	year = {2024},
	note = {Publisher: Palgrave},
	keywords = {Business and management, Finance},
	pages = {1--16},
}

@article{du_natural_2025,
	title = {Natural language processing in finance: {A} survey},
	volume = {115},
	issn = {15662535},
	shorttitle = {Natural language processing in finance},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253524005335},
	doi = {10.1016/j.inffus.2024.102755},
	abstract = {This survey presents an in-depth review of the transformative role of Natural Language Processing (NLP) in finance, highlighting its impact on ten major financial applications: (1) financial sentiment analysis, (2) financial narrative processing, (3) financial forecasting, (4) portfolio management, (5) question answering, virtual assistant and chatbot, (6) risk management, (7) regulatory compliance monitoring, (8) Environmental, Social, Governance (ESG) and sustainable finance, (9) explainable artificial intelligence (XAI) in finance and (10) NLP for digital assets. With the integration of vast amounts of unstructured financial data and advanced NLP techniques, the study explores how NLP enables data-driven decision-making and innovation in the financial sector, alongside the limitations and challenges. By providing a comprehensive analysis of NLP applications combining both academic and industrial perspectives, this study postulates the future trends and evolution of financial services. It introduces a unique review framework to understand the interaction of financial data and NLP technologies systematically and outlines the key drivers, transformations, and emerging areas in this field. This survey targets researchers, practitioners, and professionals, aiming to close their knowledge gap by highlighting the significance and future direction of NLP in enhancing financial services.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Information Fusion},
	author = {Du, Kelvin and Zhao, Yazhi and Mao, Rui and Xing, Frank and Cambria, Erik},
	month = mar,
	year = {2025},
	pages = {102755},
}

@article{herrmann-pillath_robert_2021,
	title = {Robert {J}. {Shiller}, {Narrative} {Economics}: {How} {Stories} {Go} {Viral} \& {Drive} {Major} {Economic} {Events}},
	issn = {2113-5207, 2269-8450},
	shorttitle = {Robert {J}. {Shiller}, {Narrative} {Economics}},
	url = {http://journals.openedition.org/oeconomia/11128},
	doi = {10.4000/oeconomia.11128},
	language = {fr},
	number = {11-2},
	urldate = {2025-01-21},
	journal = {OEconomia},
	author = {Herrmann-Pillath, Carsten},
	month = jun,
	year = {2021},
	pages = {403--408},
}

@article{dubremetz_rhetorical_2018,
	title = {Rhetorical {Figure} {Detection}: {Chiasmus}, {Epanaphora}, {Epiphora}},
	volume = {5},
	issn = {2297-2668},
	shorttitle = {Rhetorical {Figure} {Detection}},
	url = {https://www.frontiersin.org/journals/digital-humanities/articles/10.3389/fdigh.2018.00010/full},
	doi = {10.3389/fdigh.2018.00010},
	abstract = {{\textless}p{\textgreater}Rhetorical figures are valuable linguistic data for literary analysis. In this article, we target the detection of three rhetorical figures that belong to the family of repetitive figures: chiasmus (I {\textless}bold{\textgreater}go{\textless}/bold{\textgreater} where I {\textless}bold{\textgreater}please{\textless}/bold{\textgreater}, and I {\textless}bold{\textgreater}please{\textless}/bold{\textgreater} where I {\textless}bold{\textgreater}go{\textless}/bold{\textgreater}.), epanaphora also called anaphora (“{\textless}bold{\textgreater}Poor old{\textless}/bold{\textgreater} European Commission! {\textless}bold{\textgreater}Poor old{\textless}/bold{\textgreater} European Council.”) and epiphora (“This house is {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}. This car is {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}. You are {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}.”). Detecting repetition of words is easy for a computer but detecting only the ones provoking a rhetorical effect is difficult because of many accidental and irrelevant repetitions. For all figures, we train a log-linear classifier on a corpus of political debates. The corpus is only very partially annotated, but we nevertheless obtain good results, with more than 50\% precision for all figures. We then apply our models to totally different genres and perform a comparative analysis, by comparing corpora of fiction, science and quotes. Thanks to the automatic detection of rhetorical figures, we discover that chiasmus is more likely to appear in the scientific context whereas epanaphora and epiphora are more common in fiction.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-01-21},
	journal = {Frontiers in Digital Humanities},
	author = {Dubremetz, Marie and Nivre, Joakim},
	month = may,
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {Antimetabole, Chiasmus, Epiphora, Rhetorical Device, computational stylistics., epanaphora, repetitive figures},
}

@misc{ghosh_rheframedetect_2021,
	title = {{RheFrameDetect}: {A} {Text} {Classification} {System} for {Automatic} {Detection} of {Rhetorical} {Frames} in {AI} from {Open} {Sources}},
	shorttitle = {{RheFrameDetect}},
	url = {http://arxiv.org/abs/2112.14933},
	doi = {10.48550/arXiv.2112.14933},
	abstract = {Rhetorical Frames in AI can be thought of as expressions that describe AI development as a competition between two or more actors, such as governments or companies. Examples of such Frames include robotic arms race, AI rivalry, technological supremacy, cyberwarfare dominance and 5G race. Detection of Rhetorical Frames from open sources can help us track the attitudes of governments or companies towards AI, specifically whether attitudes are becoming more cooperative or competitive over time. Given the rapidly increasing volumes of open sources (online news media, twitter, blogs), it is difficult for subject matter experts to identify Rhetorical Frames in (near) real-time. Moreover, these sources are in general unstructured (noisy) and therefore, detecting Frames from these sources will require state-of-the-art text classification techniques. In this paper, we develop RheFrameDetect, a text classification system for (near) real-time capture of Rhetorical Frames from open sources. Given an input document, RheFrameDetect employs text classification techniques at multiple levels (document level and paragraph level) to identify all occurrences of Frames used in the discussion of AI. We performed extensive evaluation of the text classification techniques used in RheFrameDetect against human annotated Frames from multiple news sources. To further demonstrate the effectiveness of RheFrameDetect, we show multiple case studies depicting the Frames identified by RheFrameDetect compared against human annotated Frames.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Ghosh, Saurav and Loustaunau, Philippe},
	month = dec,
	year = {2021},
	note = {arXiv:2112.14933 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{yang_kolmogorov-arnold_2024,
	title = {Kolmogorov-{Arnold} {Transformer}},
	url = {http://arxiv.org/abs/2409.10594},
	doi = {10.48550/arXiv.2409.10594},
	abstract = {Transformers stand as the cornerstone of mordern deep learning. Traditionally, these models rely on multi-layer perceptron (MLP) layers to mix the information between channels. In this paper, we introduce the Kolmogorov-Arnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model. Integrating KANs into transformers, however, is no easy feat, especially when scaled up. Specifically, we identify three key challenges: (C1) Base function. The standard B-spline function used in KANs is not optimized for parallel computing on modern hardware, resulting in slower inference speeds. (C2) Parameter and Computation Inefficiency. KAN requires a unique function for each input-output pair, making the computation extremely large. (C3) Weight initialization. The initialization of weights in KANs is particularly challenging due to their learnable activation functions, which are critical for achieving convergence in deep neural networks. To overcome the aforementioned challenges, we propose three key solutions: (S1) Rational basis. We replace B-spline functions with rational functions to improve compatibility with modern GPUs. By implementing this in CUDA, we achieve faster computations. (S2) Group KAN. We share the activation weights through a group of neurons, to reduce the computational load without sacrificing performance. (S3) Variance-preserving initialization. We carefully initialize the activation weights to make sure that the activation variance is maintained across layers. With these designs, KAT scales effectively and readily outperforms traditional MLP-based transformers.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Yang, Xingyi and Wang, Xinchao},
	month = sep,
	year = {2024},
	note = {arXiv:2409.10594 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{behrouz_titans_2024,
	title = {Titans: {Learning} to {Memorize} at {Test} {Time}},
	shorttitle = {Titans},
	url = {http://arxiv.org/abs/2501.00663},
	doi = {10.48550/arXiv.2501.00663},
	abstract = {Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
	month = dec,
	year = {2024},
	note = {arXiv:2501.00663 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{nyman_news_2021,
	title = {News and narratives in financial systems: {Exploiting} big data for systemic risk assessment},
	volume = {127},
	issn = {0165-1889},
	shorttitle = {News and narratives in financial systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0165188921000543},
	doi = {10.1016/j.jedc.2021.104119},
	abstract = {This paper applies algorithmic analysis to financial market text-based data to assess how narratives and sentiment might drive financial system developments. We find changes in emotional content in narratives are highly correlated across data sources and show the formation (and subsequent collapse) of exuberance prior to the global financial crisis. Our metrics also have predictive power for other commonly used indicators of sentiment and appear to influence economic variables. A novel machine learning application also points towards increasing consensus around the strongly positive narrative prior to the crisis. Together, our metrics might help to warn about impending financial system distress.},
	urldate = {2025-01-21},
	journal = {Journal of Economic Dynamics and Control},
	author = {Nyman, Rickard and Kapadia, Sujit and Tuckett, David},
	month = jun,
	year = {2021},
	keywords = {Big data, Early warning indicators, Narratives, Sentiment, Systemic risk, Text mining, Uncertainty},
	pages = {104119},
}

@techreport{ward_identifying_2022,
	title = {Identifying {Disinformation} {Using} {Rhetorical} {Devices} in {Natural} {Language} {Models}},
	url = {https://www.osti.gov/servlets/purl/1891194/},
	abstract = {Foreign disinformation campaigns are strategically organized, extended efforts using disinformation – false or misleading information deliberately placed by an adversary – to achieve some goal. Disinformation campaigns pose severe threats to our nation’s security by misinforming decision makers and negatively influencing their actions when they are operating on limited amounts of evidence. Current efforts rely on subject matter experts to manually identify disinformation [1] [2], or on computers and traditional natural language processing algorithms to identify patterns in data to calculate the probability that something is disinformation or not. While both have their merits and successes, subject matter experts are unable to keep up with the high volumes of global information and traditional natural language algorithms do not do well in identifying “why” something is disinformation or not. Our hypothesis is that we can identify disinformation by looking at the way someone speaks, in the rhetorical devices they use. We have curated and annotated a dataset designed for multiple natural language processing tasks, but specifically useful for disinformation detection algorithms.},
	language = {en},
	number = {SAND2022-13730, 1891194, 710638},
	urldate = {2025-01-21},
	author = {Ward, Katrina and Link, Hamilton and Avramov, Kiril and Goodwin, Jean},
	month = sep,
	year = {2022},
	doi = {10.2172/1891194},
	pages = {SAND2022--13730, 1891194, 710638},
}

@inproceedings{volpetti_temporal_2020,
	address = {Shenzhen China},
	title = {Temporal {Word} {Embeddings} for {Narrative} {Understanding}},
	isbn = {978-1-4503-7642-6},
	url = {https://dl.acm.org/doi/10.1145/3383972.3383988},
	doi = {10.1145/3383972.3383988},
	abstract = {We propose temporal word embeddings as a suitable tool to study the evolution of characters and their sentiments across the plot of a narrative text. The dynamic evolution of instances within a narrative text is a challenging task, where complex behavioral evolutions and other characteristics specific to the narrative text need to be inferred and interpreted. While starting from an existing approach to the learning of these models, we propose an alternative initialization procedure which seems to be especially suited for the case of narrative text. As a validation benchmark, we use the Harry Potter series of books as a challenging case study for such character trait evolution. A benchmark data set based on temporal word analogies related to the characters in the plot of the series is considered. The results are promising, and the empirical validation seems to support the working ideas behind this proposal.},
	language = {en},
	urldate = {2025-01-21},
	booktitle = {Proceedings of the 2020 12th {International} {Conference} on {Machine} {Learning} and {Computing}},
	publisher = {ACM},
	author = {Volpetti, Claudia and Vani, K. and Antonucci, Alessandro},
	month = feb,
	year = {2020},
	pages = {68--72},
}

@book{shiller_narrative_2019,
	address = {Princeton},
	series = {Book collections on project {MUSE}},
	title = {Narrative economics: how stories go viral \& drive major economic events},
	isbn = {978-0-691-18229-2},
	shorttitle = {Narrative economics},
	abstract = {Economists have long based their forecasts on financial aggregates such as price-earnings ratios, asset prices, and exchange rate fluctuations, and used them to produce statistically informed speculations about the future, with limited success. Robert Shiller employs such aggregates in his own forecasts, but has famously complemented them with observations about the influence of mass psychology on certain events. This approach has come to be known as behavioral economics. How can economists effectively capture the effects of psychology and its influence on economic events and change? Shiller attempts to help us better understand how psychology affects events by explaining how popular economic stories arise, how they grow viral, and ultimately how they drive economic developments. After defining narrative economics in the book's preface with allusions to the advent of both the Great Depression and to World War II, Shiller presents an example of a recent economic narrative gone viral in the story of Bitcoin. Next, he explains how narrative economics works with reference to how other disciplines incorporate narrative into their analyses and also to how epidemiology explains how disease goes viral. He then presents accounts of recurring economic narratives, including the gold standard, real estate booms, war and depression, and stock market boom and crashes. He ends his book with a blueprint for future research by economists on narrative economics},
	language = {eng},
	publisher = {Princeton University press},
	author = {Shiller, Robert James},
	year = {2019},
}

@misc{lorenz_drift_2013,
	title = {Drift dependence of optimal trade execution strategies under transient price impact},
	url = {http://arxiv.org/abs/1204.2716},
	doi = {10.48550/arXiv.1204.2716},
	abstract = {We give a complete solution to the problem of minimizing the expected liquidity costs in presence of a general drift when the underlying market impact model has linear transient price impact with exponential resilience. It turns out that this problem is well-posed only if the drift is absolutely continuous. Optimal strategies often do not exist, and when they do, they depend strongly on the derivative of the drift. Our approach uses elements from singular stochastic control, even though the problem is essentially non-Markovian due to the transience of price impact and the lack in Markovian structure of the underlying price process. As a corollary, we give a complete solution to the minimization of a certain cost-risk criterion in our setting.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Lorenz, Christopher and Schied, Alexander},
	month = mar,
	year = {2013},
	note = {arXiv:1204.2716},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@article{almgren_optimal_2001,
	title = {Optimal execution of portfolio transactions},
	volume = {3},
	issn = {14651211},
	url = {http://www.risk.net/journal-of-risk/technical-paper/2161150/optimal-execution-portfolio-transactions},
	doi = {10.21314/JOR.2001.041},
	abstract = {We consider the execution of portfolio transactions with the aim of minimizing a combination of volatility risk and transaction costs arising from permanent and temporary market impact. For a simple linear cost model, we explicitly construct the eﬃcient frontier in the space of time-dependent liquidation strategies, which have minimum expected cost for a given level of uncertainty. We may then select optimal strategies either by minimizing a quadratic utility function, or by minimizing Value at Risk. The latter choice leads to the concept of Liquidity-adjusted VAR, or L-VaR, that explicitly considers the best tradeoﬀ between volatility risk and liquidation costs.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {The Journal of Risk},
	author = {Almgren, Robert and Chriss, Neil},
	month = jan,
	year = {2001},
	pages = {5--39},
}

@inproceedings{hutchison_evolving_2010,
	address = {Berlin, Heidelberg},
	title = {Evolving {Dynamic} {Trade} {Execution} {Strategies} {Using} {Grammatical} {Evolution}},
	volume = {6025},
	isbn = {978-3-642-12241-5 978-3-642-12242-2},
	url = {http://link.springer.com/10.1007/978-3-642-12242-2_20},
	doi = {10.1007/978-3-642-12242-2_20},
	abstract = {Although there is a plentiful literature on the use of evolutionary methodologies for the trading of financial assets, little attention has been paid to potential use of these methods for efficient trade execution. Trade execution is concerned with the actual mechanics of buying or selling the desired amount of a financial instrument of interest. Grammatical Evolution (GE) is an evolutionary automatic programming methodology which can be used to evolve rule sets. In this paper we use a GE algorithm to discover dynamic, efficient, trade execution strategies which adapt to changing market conditions. The strategies are tested in an artificial limit order market. GE was found to be able to evolve quality trade execution strategies which are highly competitive with two benchmark trade execution strategies.},
	urldate = {2024-10-31},
	publisher = {Springer Berlin Heidelberg},
	author = {Cui, Wei and Brabazon, Anthony and O’Neill, Michael},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Di Chio, Cecilia and Brabazon, Anthony and Di Caro, Gianni A. and Ebner, Marc and Farooq, Muddassar and Fink, Andreas and Grahl, Jörn and Greenfield, Gary and Machado, Penousal and O’Neill, Michael and Tarantino, Ernesto and Urquhart, Neil},
	year = {2010},
	doi = {10.1007/978-3-642-12242-2_20},
	note = {Book Title: Applications of Evolutionary Computation
Series Title: Lecture Notes in Computer Science},
	pages = {192--201},
}

@misc{ackermann_optimal_2021,
	title = {Optimal trade execution in an order book model with stochastic liquidity parameters},
	url = {http://arxiv.org/abs/2006.05843},
	doi = {10.48550/arXiv.2006.05843},
	abstract = {We analyze an optimal trade execution problem in a financial market with stochastic liquidity. To this end we set up a limit order book model in which both order book depth and resilience evolve randomly in time. Trading is allowed in both directions and at discrete points in time. We derive an explicit recursion that, under certain structural assumptions, characterizes minimal execution costs. We also discuss several qualitative aspects of optimal strategies, such as existence of profitable round trips or closing the position in one go, and compare our findings with the literature.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Ackermann, Julia and Kruse, Thomas and Urusov, Mikhail},
	month = apr,
	year = {2021},
	note = {arXiv:2006.05843},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@article{cheridito_optimal_2014,
	title = {Optimal {Trade} {Execution} {Under} {Stochastic} {Volatility} and {Liquidity}},
	volume = {21},
	issn = {1350-486X},
	url = {https://doi.org/10.1080/1350486X.2014.881005},
	doi = {10.1080/1350486X.2014.881005},
	abstract = {We study the problem of optimally liquidating a financial position in a discrete-time model with stochastic volatility and liquidity. We consider the three cases where the objective is to minimize the expectation, an expected exponential or a mean-variance criterion of the implementation cost. In the first case, the optimal solution can be fully characterized by a forward-backward system of stochastic equations depending on conditional expectations of future liquidity. In the other two cases, we derive Bellman equations from which the optimal solutions can be obtained numerically by discretizing the control space. In all three cases, we compute optimal strategies for different simulated realizations of prices, volatility and liquidity and compare the outcomes to the ones produced by the deterministic strategies of Bertsimas and Lo (1998; Optimal control of execution costs. Journal of Financial Markets, 1, 1–50) and Almgren and Chriss (2001; Optimal execution of portfolio transactions. Journal of Risk, 3, 5–33).},
	number = {4},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Cheridito, Patrick and Sepin, Tardu},
	month = jul,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2014.881005},
	keywords = {Bellman equation, Optimal trade execution, discrete-time stochastic control, implementation cost, stochastic liquidity, stochastic volatility},
	pages = {342--362},
}

@article{fruth_optimal_2019,
	title = {Optimal trade execution in order books with stochastic liquidity},
	volume = {29},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12180},
	doi = {10.1111/mafi.12180},
	abstract = {In financial markets, liquidity changes randomly over time. We consider such random variations of the depth of the order book and evaluate their influence on optimal trade execution strategies. If the stochastic structure of liquidity changes satisfies certain conditions, then the unique optimal trading strategy exhibits a conventional structure with a single wait region and a single buy region, and profitable round-trip strategies do not exist. In other cases, optimal strategies can feature multiple wait regions and optimal trade sizes that can be decreasing in the size of the position to be liquidated. Furthermore, round-trip strategies can be profitable depending on bid–ask spread assumptions. We illustrate our findings with several examples including the Cox–Ingersoll–Ross model for the evolution of liquidity.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Fruth, Antje and Schöneborn, Torsten and Urusov, Mikhail},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12180},
	keywords = {limit order book, market impact model, optimal order execution, profitable round trip trading strategies, resilience, stochastic order book depth, time-varying liquidity},
	pages = {507--541},
}

@article{gueant_optimal_2015,
	title = {Optimal {Execution} and {Block} {Trade} {Pricing}: {A} {General} {Framework}},
	volume = {22},
	issn = {1350-486X},
	shorttitle = {Optimal {Execution} and {Block} {Trade} {Pricing}},
	url = {https://doi.org/10.1080/1350486X.2015.1042188},
	doi = {10.1080/1350486X.2015.1042188},
	abstract = {In this article, we develop a general framework to study optimal execution and to price block trades. We prove existence of optimal liquidation strategies and provide regularity results for optimal strategies under very general hypotheses. We exhibit a Hamiltonian characterization for the optimal strategy that can be used for numerical approximation. We also focus on the important topic of block trade pricing and propose a methodology to give a price to financial (il)liquidity. In particular, we provide a closed-form formula for the price of a block trade when there is no time constraint to liquidate.},
	number = {4},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Guéant, Olivier},
	month = jul,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2015.1042188},
	keywords = {Hamilton-Jacobi equations, Optimal execution, block trade pricing, viscosity solutions},
	pages = {336--365},
}

@misc{graewe_optimal_2017,
	title = {Optimal {Trade} {Execution} with {Instantaneous} {Price} {Impact} and {Stochastic} {Resilience}},
	url = {http://arxiv.org/abs/1611.03435},
	doi = {10.48550/arXiv.1611.03435},
	abstract = {We study an optimal execution problem in illiquid markets with both instantaneous and persistent price impact and stochastic resilience when only absolutely continuous trading strategies are admissible. In our model the value function can be described by a three-dimensional system of backward stochastic differential equations (BSDE) with a singular terminal condition in one component. We prove existence and uniqueness of a solution to the BSDE system and characterize both the value function and the optimal strategy in terms of the unique solution to the BSDE system. Our existence proof is based on an asymptotic expansion of the BSDE system at the terminal time that allows us to express the system in terms of a equivalent system with finite terminal value but singular driver.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Graewe, Paulwin and Horst, Ulrich},
	month = jul,
	year = {2017},
	note = {arXiv:1611.03435},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@misc{ohnishi_trade_2024,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Trade {Execution} {Games} in a {Markovian} {Environment}},
	url = {https://papers.ssrn.com/abstract=4818028},
	doi = {10.2139/ssrn.4818028},
	abstract = {This paper examines a trade execution game for two large traders in a generalized price impact model. We incorporate a stochastic and sequentially dependent factor that exogenously affects the market price into financial markets. Our model accounts for how strategic and environmental uncertainties affect the large traders' execution strategies. We formulate an expected utility maximization problem for two large traders as a Markov game model. Applying the backward induction method of dynamic programming, we provide an explicit closed-form execution strategy at a Markov perfect equilibrium. Our theoretical results reveal that the execution strategy generally lies in a dynamic and non-randomized class; it becomes deterministic if the Markovian environment is also deterministic. In addition, our simulation-based numerical experiments suggest that the execution strategy captures various features observed in financial markets.},
	language = {en},
	urldate = {2024-10-31},
	publisher = {Social Science Research Network},
	author = {Ohnishi, Masamitsu and Shimoshimizu, Makoto},
	month = may,
	year = {2024},
	keywords = {Backward induction, Dynamic programming, Markov perfect equilibrium, Markovian environment, Price Impact, Trade execution game},
}

@article{kissell_practical_2004,
	title = {A practical framework for estimating transaction costs and developing optimal trading strategies to achieve best execution},
	volume = {1},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612303000047},
	doi = {10.1016/S1544-6123(03)00004-7},
	abstract = {In this paper we provide both a decision framework to estimate transaction costs and develop optimal trading strategies to achieve best execution. The methodology is based on an unbundling approach whereby costs are categorized into transparent and hidden, and ﬁxed and variable components. The classiﬁcation serves as the foundation for developing execution strategies for a fund’s implementation goals. For example, the methodology easily adapts to strategies aimed at preserving asset value, achieving the closing price or volume weighted average price (“VWAP”), and minimizing tracking error. Further, we show how to determine the best execution strategy (“BES”) from a set of optimal strategies given a fund’s goal and objectives via a set of decision-making criteria. Ultimately, best execution translates to lower transaction costs and higher portfolio returns.},
	language = {en},
	number = {1},
	urldate = {2024-10-31},
	journal = {Finance Research Letters},
	author = {Kissell, Robert and Glantz, Morton and Malamut, Roberto},
	month = mar,
	year = {2004},
	pages = {35--46},
}

@article{almgren_optimal_2003,
	title = {Optimal execution with nonlinear impact functions and trading-enhanced risk},
	volume = {10},
	issn = {1350-486X},
	url = {https://doi.org/10.1080/135048602100056},
	doi = {10.1080/135048602100056},
	abstract = {Optimal trading strategies are determined for liquidation of a large single-asset portfolio to minimize a combination of volatility risk and market impact costs. The market impact cost per share is taken to be a power law function of the trading rate, with an arbitrary positive exponent. This includes, for example, the square root law that has been proposed based on market microstructure theory. In analogy to the linear model, a ‘characteristic time’ for optimal trading is defined, which now depends on the initial portfolio size and decreases as execution proceeds. A model is also considered in which uncertainty of the realized price is increased by demanding rapid execution; it is shown that optimal trajectories are described by a ‘critical portfolio size’ above which this effect is dominant and below which it may be neglected.},
	number = {1},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Almgren, Robert F.},
	month = jan,
	year = {2003},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/135048602100056},
	keywords = {Liquidity Modeling, Market Impact, Trading Strategy},
	pages = {1--18},
}

@article{donnelly_optimal_2022,
	title = {Optimal {Execution}: {A} {Review}},
	volume = {29},
	issn = {1350-486X},
	shorttitle = {Optimal {Execution}},
	url = {https://doi.org/10.1080/1350486X.2022.2161588},
	doi = {10.1080/1350486X.2022.2161588},
	abstract = {This review article is intended to collect and summarize many of the results in the field of optimal execution over the last twenty years. In doing so, we describe the general workings of the limit order book so that the sources of costs and risks which need to be optimized are understood. The initial models considered propose simple dynamics for prices which allow easily computable strategies which maximize risk-adjusted profits. Subsequently, the review is divided into two major parts. The first explores several works which investigate how optimal liquidation strategies are modified to account for more complex dynamics, namely other stochastic or non-linear factors. The second presents optimal trading strategies when the agent utilizes benchmarks in addition to risk-adjusted wealth, or when she has objectives beyond optimal liquidation.},
	number = {3},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Donnelly, Ryan},
	month = may,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2022.2161588},
	keywords = {Algorithmic trading, price impact, stochastic optimization},
	pages = {181--212},
}

@article{guilbaud_optimal_2013,
	title = {Optimal high-frequency trading with limit and market orders},
	volume = {13},
	issn = {1469-7688},
	url = {https://doi.org/10.1080/14697688.2012.708779},
	doi = {10.1080/14697688.2012.708779},
	abstract = {We propose a framework for studying optimal market-making policies in a limit order book (LOB). The bid–ask spread of the LOB is modeled by a tick-valued continuous-time Markov chain. We consider a small agent who continuously submits limit buy/sell orders at best bid/ask quotes, and may also set limit orders at best bid (resp. ask) plus (resp. minus) a tick for obtaining execution order priority, which is a crucial issue in high-frequency trading. The agent faces an execution risk since her limit orders are executed only when they meet counterpart market orders. She is also subject to inventory risk due to price volatility when holding the risky asset. The agent can then also choose to trade with market orders, and therefore obtain immediate execution, but at a less favorable price. The objective of the market maker is to maximize her expected utility from revenue over a short-term horizon by a trade-off between limit and market orders, while controlling her inventory position. This is formulated as a mixed regime switching regular/impulse control problem that we characterize in terms of a quasi-variational system by dynamic programming methods. Calibration procedures are derived for estimating the transition matrix and intensity parameters for the spread and for Cox processes modelling the execution of limit orders. We provide an explicit backward splitting scheme for solving the problem and show how it can be reduced to a system of simple equations involving only the inventory and spread variables. Several computational tests are performed both on simulated and real data, and illustrate the impact and profit when considering execution priority in limit orders and market orders.},
	number = {1},
	urldate = {2024-10-31},
	journal = {Quantitative Finance},
	author = {Guilbaud, Fabien and Pham, Huyên},
	month = jan,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14697688.2012.708779},
	keywords = {Applied mathematical finance, G1, G10, G11, Market microstructure, Portfolio optimization, Quantitative finance techniques, Stochastic control, Trading strategies},
	pages = {79--94},
}

@article{cartea_optimal_2015,
	title = {Optimal execution with limit and market orders},
	volume = {15},
	issn = {1469-7688},
	url = {https://doi.org/10.1080/14697688.2015.1032543},
	doi = {10.1080/14697688.2015.1032543},
	abstract = {We develop an optimal execution policy for an investor seeking to execute a large order using limit and market orders. The investor solves the optimal policy considering different restrictions on volume of both types of orders and depth at which limit orders are posted. We show how the execution policies perform when targeting the volume schedule of the Almgren–Chriss execution strategy. The different strategies considered by the investor outperform the Almgren–Chriss price with an average savings per share of about one to two and a half times the spread. This improvement over Almgren–Chriss is due to the strategies benefiting from the optimal mix of limit orders, which earn the spread and market orders, which keep the investor’s inventory schedule on target.},
	number = {8},
	urldate = {2024-10-31},
	journal = {Quantitative Finance},
	author = {Cartea, Álvaro and Jaimungal, Sebastian},
	month = aug,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14697688.2015.1032543},
	keywords = {Acquisition, Algorithmic trading, High-frequency trading, Impulse control, Liquidation, TWAP},
	pages = {1279--1291},
}

@article{fruth_optimal_2019-1,
	title = {Optimal trade execution in order books with stochastic liquidity},
	volume = {29},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12180},
	doi = {10.1111/mafi.12180},
	abstract = {In financial markets, liquidity changes randomly over time. We consider such random variations of the depth of the order book and evaluate their influence on optimal trade execution strategies. If the stochastic structure of liquidity changes satisfies certain conditions, then the unique optimal trading strategy exhibits a conventional structure with a single wait region and a single buy region, and profitable round-trip strategies do not exist. In other cases, optimal strategies can feature multiple wait regions and optimal trade sizes that can be decreasing in the size of the position to be liquidated. Furthermore, round-trip strategies can be profitable depending on bid–ask spread assumptions. We illustrate our findings with several examples including the Cox–Ingersoll–Ross model for the evolution of liquidity.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Fruth, Antje and Schöneborn, Torsten and Urusov, Mikhail},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12180},
	keywords = {limit order book, market impact model, optimal order execution, profitable round trip trading strategies, resilience, stochastic order book depth, time-varying liquidity},
	pages = {507--541},
}

@article{dixon_high-frequency_2018,
	title = {A high-frequency trade execution model for supervised learning},
	volume = {1},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {2470-6981},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hf2.10016},
	doi = {10.1002/hf2.10016},
	abstract = {This article introduces a high-frequency trade execution model to evaluate the economic impact of supervised machine learners. Extending the concept of a confusion matrix, we present a “trade information matrix” to attribute the expected profit and loss of the high-frequency strategy under execution constraints, such as fill probabilities and position dependent trade rules, to correct and incorrect predictions. We apply the trade execution model and trade information matrix to Level II E-mini S\&P 500 futures history and demonstrate an estimation approach for measuring the sensitivity of the P\&L to the error of a recurrent neural network. Our approach directly evaluates the performance sensitivity of a market-making strategy to prediction error and augments traditional market simulation-based testing.},
	language = {en},
	number = {1},
	urldate = {2024-10-31},
	journal = {High Frequency},
	author = {Dixon, Matthew},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hf2.10016},
	keywords = {execution model, high frequency trading, market making, recurrent neural networks, supervised learning},
	pages = {32--52},
}

@article{bayraktar_optimal_2011,
	title = {Optimal {Trade} {Execution} in {Illiquid} {Markets}},
	volume = {21},
	copyright = {© 2010 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9965.2010.00446.x},
	doi = {10.1111/j.1467-9965.2010.00446.x},
	abstract = {We study optimal trade execution strategies in financial markets with discrete order flow. The agent has a finite liquidation horizon and must minimize price impact given a random number of incoming trade counterparties. Assuming that the order flow N is given by a Poisson process, we give a full analysis of the properties and computation of the optimal dynamic execution strategy. Extensions, whereby N is a Markov-modulated compound Poisson process are also considered. We derive and compare the properties of the various cases and illustrate our results with computational examples.},
	language = {en},
	number = {4},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Bayraktar, Erhan and Ludkovski, Michael},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9965.2010.00446.x},
	keywords = {Markov-modulated Poisson process, dark pools, liquidity modeling, optimal order execution},
	pages = {681--701},
}

@article{bessembinder_issues_nodate,
	title = {Issues in assessing trade execution costs\$},
	abstract = {This study assesses the sensitivity of trading cost estimates derived from publicly-available trade and quote data to two methodological issues: the time adjustment made before comparing trades to quotes, and the procedure used to designate trades as buyer or sellerinitiated. The results indicate that making no allowance for trade reporting lags is optimal when assessing whether trades are buyer or seller initiated, for both Nasdaq and NYSE stocks. However, trade prices are best compared to earlier quotations when assessing trade execution costs, in order to capture the effect of systematic quotation revisions in the seconds before trades are reported. A technique for inferring trade direction recommended by Ellis et al. (J. Financial Quant. Anal. 35 (2000) 529) leads to signiﬁcantly smaller estimates of trading costs than the well-known Lee and Ready (J. Finance 46 (1991) 733) algorithm. Despite the sensitivity of trading cost measures to these methodological issues, inference as to whether the Nasdaq dealer market or the NYSE auction market provides lower trade execution costs is not sensitive.},
	language = {en},
	author = {Bessembinder, Hendrik},
}

@misc{noauthor_updating_2018,
	title = {Updating {Chrome} extension},
	url = {https://forums.zotero.org/discussion/69790/updating-chrome-extension},
	abstract = {Zotero is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share research.},
	language = {en},
	urldate = {2024-10-03},
	journal = {Zotero Forums},
	month = jan,
	year = {2018},
}
