
@incollection{brunnermeier_chapter_2013,
	title = {Chapter 18 - {Bubbles}, {Financial} {Crises}, and {Systemic} {Risk}},
	volume = {2},
	url = {https://www.sciencedirect.com/science/article/pii/B9780444594068000184},
	abstract = {This chapter surveys the literature on bubbles, financial crises, and systemic risk. The first part of the chapter provides a brief historical account of bubbles and financial crisis. The second part of the chapter gives a structured overview of the literature on financial bubbles. The third part of the chapter discusses the literatures on financial crises and systemic risk, with particular emphasis on amplification and propagation mechanisms during financial crises, and the measurement of systemic risk. Finally, we point toward some questions for future research.},
	urldate = {2024-10-23},
	booktitle = {Handbook of the {Economics} of {Finance}},
	publisher = {Elsevier},
	author = {Brunnermeier, Markus K. and Oehmke, Martin},
	editor = {Constantinides, George M. and Harris, Milton and Stulz, Rene M.},
	month = jan,
	year = {2013},
	doi = {10.1016/B978-0-44-459406-8.00018-4},
	keywords = {Bubbles, Crashes, Financial crises, Systemic risk},
	pages = {1221--1288},
}

@article{hirano_bubble_2024,
	title = {Bubble economics},
	volume = {111},
	issn = {03044068},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304406824000065},
	doi = {10.1016/j.jmateco.2024.102944},
	abstract = {This article provides a self-contained overview of the theory of rational asset price bubbles. We cover topics from basic definitions, properties, and classical results to frontier research, with an emphasis on bubbles attached to real assets such as stocks, housing, and land. The main message is that bubbles attached to real assets are fundamentally nonstationary phenomena related to unbalanced growth. We present a bare-bones model and draw three new insights: (i) the emergence of asset price bubbles is a necessity, instead of a possibility; (ii) asset pricing implications are markedly different between balanced growth of stationary nature and unbalanced growth of nonstationary nature; and (iii) asset price bubbles occur within larger historical trends involving shifts in industrial structure driven by technological innovation, including the transition from the Malthusian economy to the modern economy.},
	language = {en},
	urldate = {2024-10-22},
	journal = {Journal of Mathematical Economics},
	author = {Hirano, Tomohiro and Toda, Alexis Akira},
	month = apr,
	year = {2024},
	pages = {102944},
}

@article{siegel_what_2003,
	title = {What {Is} an {Asset} {Price} {Bubble}? {An} {Operational} {Definition}},
	volume = {9},
	issn = {1354-7798, 1468-036X},
	shorttitle = {What {Is} an {Asset} {Price} {Bubble}?},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/1468-036X.00206},
	doi = {10.1111/1468-036X.00206},
	abstract = {This paper reviews and analyses the current definitions of bubbles in asset prices. It makes the case that one cannot identify a bubble immediately, but one has to wait a sufficient amount of time to determine whether the previous prices can be justified by subsequent cash flows. The paper proposes an operational definition of a bubble as any time the realised asset return over given future period is more than two standard deviations from its expected return. Using this framework, the paper shows how the great crash of 1929 and 1987— both periods generally characterised as bubbles —prove not to be bubbles but the low point in stock prices in 1932 is a ‘negative bubble.’ The paper then extends this analysis to the internet stocks and concludes that it is virtually certain that it is a bubble.},
	language = {en},
	number = {1},
	urldate = {2024-10-20},
	journal = {European Financial Management},
	author = {Siegel, Jeremy J.},
	month = mar,
	year = {2003},
	pages = {11--24},
}

@article{khadjeh_nassirtoussi_text_2014,
	title = {Text mining for market prediction: {A} systematic review},
	volume = {41},
	issn = {09574174},
	shorttitle = {Text mining for market prediction},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417414003455},
	doi = {10.1016/j.eswa.2014.06.009},
	abstract = {The quality of the interpretation of the sentiment in the online buzz in the social media and the online news can determine the predictability of ﬁnancial markets and cause huge gains or losses. That is why a number of researchers have turned their full attention to the different aspects of this problem lately. However, there is no well-rounded theoretical and technical framework for approaching the problem to the best of our knowledge. We believe the existing lack of such clarity on the topic is due to its interdisciplinary nature that involves at its core both behavioral-economic topics as well as artiﬁcial intelligence. We dive deeper into the interdisciplinary nature and contribute to the formation of a clear frame of discussion. We review the related works that are about market prediction based on onlinetext-mining and produce a picture of the generic components that they all have. We, furthermore, compare each system with the rest and identify their main differentiating factors. Our comparative analysis of the systems expands onto the theoretical and technical foundations behind each. This work should help the research community to structure this emerging ﬁeld and identify the exact aspects which require further research and are of special signiﬁcance.},
	language = {en},
	number = {16},
	urldate = {2024-10-09},
	journal = {Expert Systems with Applications},
	author = {Khadjeh Nassirtoussi, Arman and Aghabozorgi, Saeed and Ying Wah, Teh and Ngo, David Chek Ling},
	month = nov,
	year = {2014},
	pages = {7653--7670},
}

@article{kearns_machine_nodate,
	title = {Machine {Learning} for {Market} {Microstructure} and {High} {Frequency} {Trading}},
	language = {en},
	author = {Kearns, Michael and Nevmyvaka, Yuriy},
}

@misc{barez_exploring_2023,
	title = {Exploring the {Advantages} of {Transformers} for {High}-{Frequency} {Trading}},
	url = {http://arxiv.org/abs/2302.13850},
	abstract = {This paper explores the novel deep learning Transformers architectures for high-frequency Bitcoin-USDT log-return forecasting and compares them to the traditional Long Short-Term Memory models. A hybrid Transformer model, called HFformer, is then introduced for time series forecasting which incorporates a Transformer encoder, linear decoder, spiking activations, and quantile loss function, and does not use position encoding. Furthermore, possible high-frequency trading strategies for use with the HFformer model are discussed, including trade sizing, trading signal aggregation, and minimal trading threshold. Ultimately, the performance of the HFformer and Long Short-Term Memory models are assessed and results indicate that the HFformer achieves a higher cumulative PnL than the LSTM when trading with multiple signals during backtesting1.},
	language = {en},
	urldate = {2024-10-09},
	publisher = {arXiv},
	author = {Barez, Fazl and Bilokon, Paul and Gervais, Arthur and Lisitsyn, Nikita},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13850 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance},
}

@misc{wu_bloomberggpt_2023,
	title = {{BloombergGPT}: {A} {Large} {Language} {Model} for {Finance}},
	shorttitle = {{BloombergGPT}},
	url = {http://arxiv.org/abs/2303.17564},
	abstract = {The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg’s extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.},
	language = {en},
	urldate = {2024-10-09},
	publisher = {arXiv},
	author = {Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
	month = dec,
	year = {2023},
	note = {arXiv:2303.17564 [cs, q-fin]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Quantitative Finance - General Finance},
}

@misc{lis_analyzing_2023,
	title = {Analyzing {Credit} {Risk} {Model} {Problems} through {NLP}-{Based} {Clustering} and {Machine} {Learning}: {Insights} from {Validation} {Reports}},
	shorttitle = {Analyzing {Credit} {Risk} {Model} {Problems} through {NLP}-{Based} {Clustering} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/2306.01618},
	abstract = {This paper explores the use of clustering methods and machine learning algorithms, including Natural Language Processing (NLP), to identify and classify problems identified in credit risk models through textual information contained in validation reports. Using a unique dataset of 657 findings raised by validation teams in a large international banking group between January 2019 and December 2022. The findings are classified into nine validation dimensions and assigned a severity level by validators using their expert knowledge. The authors use embedding generation for the findings’ titles and observations using four different pre-trained models, including "module\_url" from TensorFlow Hub and three models from the SentenceTransformer library, namely "all-mpnet-base-v2", "allMiniLM-L6-v2", and "paraphrase-mpnet-base-v2". The paper uses and compares various clustering methods in grouping findings with similar characteristics, enabling the identification of common problems within each validation dimension and severity. The results of the study show that clustering is an effective approach for identifying and classifying credit risk model problems with accuracy higher than 60\%. The authors also employ machine learning algorithms, including logistic regression and XGBoost, to predict the validation dimension and its severity, achieving an accuracy of 80\% for XGBoost algorithm. Furthermore, the study identifies the top 10 words that predict a validation dimension and severity. Overall, this paper makes a contribution by demonstrating the usefulness of clustering and machine learning for analyzing textual information in validation reports, and providing insights into the types of problems encountered in the development and validation of credit risk models.},
	language = {en},
	urldate = {2024-10-09},
	publisher = {arXiv},
	author = {Lis, Szymon and Kubkowski, Mariusz and Borkowska, Olimpia and Serwa, Dobromił and Kurpanik, Jarosław},
	month = jun,
	year = {2023},
	note = {arXiv:2306.01618 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{ghosh_recent_2023,
	title = {Recent trends in financial natural language processing research},
	volume = {8},
	issn = {27725693},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2772569323001457},
	doi = {10.1016/j.sctalk.2023.100270},
	language = {en},
	urldate = {2024-10-09},
	journal = {Science Talks},
	author = {Ghosh, Sohom and Naskar, Sudip Kumar},
	month = dec,
	year = {2023},
	pages = {100270},
}

@article{noauthor_application_2024,
	title = {Application of {Natural} {Language} {Processing} in {Financial} {Risk} {Detection}},
	volume = {7},
	issn = {25232576},
	url = {https://www.clausiuspress.com/article/12720.html},
	doi = {10.23977/ferm.2024.070401},
	abstract = {This paper explores the application of Natural Language Processing (NLP) in financial risk detection. By constructing an NLP-based financial risk detection model, this study aims to identify and predict potential risks in financial documents and communications. First, the fundamental concepts of NLP and its theoretical foundation, including text mining methods, NLP model design principles, and machine learning algorithms, are introduced. Second, the process of text data preprocessing and feature extraction is described. Finally, the effectiveness and predictive performance of the model are validated through empirical research. The results show that the NLP-based financial risk detection model performs excellently in risk identification and prediction, providing effective risk management tools for financial institutions. This study offers valuable references for the field of financial risk management, utilizing advanced NLP techniques to improve the accuracy and efficiency of financial risk detection.},
	language = {en},
	number = {4},
	urldate = {2024-10-09},
	journal = {Financial Engineering and Risk Management},
	year = {2024},
}

@article{li_financial_2024,
	title = {Financial {Risk} {Prediction} and {Management} using {Machine} {Learning} and {Natural} {Language} {Processing}},
	volume = {15},
	issn = {21565570, 2158107X},
	url = {http://thesai.org/Publications/ViewPaper?Volume=15&Issue=6&Code=ijacsa&SerialNo=23},
	doi = {10.14569/IJACSA.2024.0150623},
	abstract = {With the continuous development and changes in the global financial markets, financial risk management has become increasingly important for the stable operation of enterprises. Traditional financial risk management methods, primarily relying on financial statement analysis and historical data statistics, show clear limitations when dealing with largescale unstructured data. The rapid development of machine learning and Natural Language Processing (NLP) technologies in recent years offers new perspectives and methods for financial risk prediction and management. This paper explores and conducts empirical analysis financial risk management using these advanced technologies, with a particular focus on the application of NLP in measuring financial risk tendencies, and the financial risk prediction and management based on a Deep neural network - Factorization Machine (DeepFM) model. Through in-depth analysis and research, this paper proposes a new financial risk management model that combines NLP and deep learning technologies, aimed at improving the accuracy and efficiency of financial risk prediction. This study not only broadens the theoretical horizons of financial risk management but also provides effective technical support and decision-making references for practical operations.},
	language = {en},
	number = {6},
	urldate = {2024-10-09},
	journal = {International Journal of Advanced Computer Science and Applications},
	author = {Li, Tianyu and Dai, Xiangyu},
	year = {2024},
}

@article{xing_natural_2018,
	title = {Natural language based financial forecasting: a survey},
	volume = {50},
	issn = {0269-2821, 1573-7462},
	shorttitle = {Natural language based financial forecasting},
	url = {http://link.springer.com/10.1007/s10462-017-9588-9},
	doi = {10.1007/s10462-017-9588-9},
	abstract = {Natural language processing (NLP), or the pragmatic research perspective of computational linguistics, has become increasingly powerful due to data availability and various techniques developed in the past decade. This increasing capability makes it possible to capture sentiments more accurately and semantics in a more nuanced way. Naturally, many applications are starting to seek improvements by adopting cutting-edge NLP techniques. Financial forecasting is no exception. As a result, articles that leverage NLP techniques to predict ﬁnancial markets are fast accumulating, gradually establishing the research ﬁeld of natural language based ﬁnancial forecasting (NLFF), or from the application perspective, stock market prediction. This review article clariﬁes the scope of NLFF research by ordering and structuring techniques and applications from related work. The survey also aims to increase the understanding of progress and hotspots in NLFF, and bring about discussions across many different disciplines.},
	language = {en},
	number = {1},
	urldate = {2024-10-09},
	journal = {Artificial Intelligence Review},
	author = {Xing, Frank Z. and Cambria, Erik and Welsch, Roy E.},
	month = jun,
	year = {2018},
	pages = {49--73},
}

@inproceedings{konstantinidis_comparative_2023,
	title = {A comparative study on {ML}-based approaches for {Main} {Entity} {Detection} in {Financial} {Reports}},
	url = {https://ieeexplore.ieee.org/document/10167951/?arnumber=10167951},
	doi = {10.1109/DSP58604.2023.10167951},
	abstract = {Modern AI technologies which exploit the classification and/or prediction capacities of Deep Neural Architectures demonstrate superior performance to traditional approaches in most cases. However, they come with the unavoidable shortcoming of lack of transparency in their outcomes. This attribute renders them unsuitable for big industrial sectors, such as finance, investment management, etc. Specifically, their "black-box" nature makes them unattractive in cases where human understanding in the decision making process is required and may be legally mandatory. In such cases, traditional (i.e., non-deep learning) ML approaches are still preferred, to minimize for example the presence of false positives. In this context, this paper introduces an unsupervised, trustful, bottom-up probabilistic approach for Named Entity Recognition (NER) in financial reports, while in parallel it provides a comparative study on well-known ML-approaches in terms of their performance. The proposed approach builds on the probability of appearance of representative tokens within the given reports and utilizes Kronecker’s Delta and the Total Probability Theorem to construct a probabilistic model that estimates the overall classification probability of a document.},
	urldate = {2024-10-09},
	booktitle = {2023 24th {International} {Conference} on {Digital} {Signal} {Processing} ({DSP})},
	author = {Konstantinidis, Thanos and Xu, Yao Lei and Constantinides, Tony G. and Mandic, Danilo P.},
	month = jun,
	year = {2023},
	note = {ISSN: 2165-3577},
	keywords = {Artificial intelligence, Closed box, Decision making, Digital signal processing, Finance, Investment, Probabilistic logic},
	pages = {1--5},
}

@misc{tran_predicting_2022,
	title = {Predicting {Digital} {Asset} {Prices} using {Natural} {Language} {Processing}: a survey},
	shorttitle = {Predicting {Digital} {Asset} {Prices} using {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/2212.00726},
	abstract = {The introduction of blockchain technology has changed the way people think about how they used to store and trade their assets, as it introduced us to a whole new way to transact: using digital currencies. One of the major innovations of blockchain technology is decentralization, meaning that traditional ﬁnancial intermediaries, such as asset-backed security issuers and banks, are eliminated in the process. Even though the blockchain technology has been utilized in a wide range of industries, its most prominent application is still cryptocurrencies, with Bitcoin being the ﬁrst one proposed. At its peak in 2021, the market cap for Bitcoin once surpassed 1 trillion US dollars. The open nature of the crypto market poses various challenges and concerns for both potential retail investors and institutional investors, as the price of the investment is highly volatile and its ﬂuctuations are unpredictable. The rise of Machine Learning, and Natural Language Processing, in particular, has shed some light on monitoring and predicting the price behaviors of cryptocurrencies. This paper aims to review and analyze the recent eﬀorts in applying Machine Learning and Natural Language Processing methods to predict the prices and analyze the behaviors of digital assets such as Bitcoin and Ethereum.},
	language = {en},
	urldate = {2024-10-07},
	publisher = {arXiv},
	author = {Tran, Trang},
	month = nov,
	year = {2022},
	note = {arXiv:2212.00726 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Cryptography and Security},
}

@inproceedings{olaniyan_sentiment_2015,
	title = {Sentiment and stock market volatility predictive modelling — {A} hybrid approach},
	url = {https://ieeexplore.ieee.org/document/7344855/?arnumber=7344855},
	doi = {10.1109/DSAA.2015.7344855},
	abstract = {The frequent ups and downs are characteristic to the stock market. The conventional standard models that assume that investors act rationally have not been able to capture the irregularities in the stock market patterns for years. As a result, behavioural finance is embraced to attempt to correct these model shortcomings by adding some factors to capture sentimental contagion which may be at play in determining the stock market. This paper assesses the predictive influence of sentiment on the stock market returns by using a non-parametric nonlinear approach that corrects specific limitations encountered in previous related work. In addition, the paper proposes a new approach to developing stock market volatility predictive models by incorporating a hybrid GARCH and artificial neural network framework, and proves the advantage of this framework over a GARCH only based framework. Our results reveal also that past volatility and positive sentiment appear to have strong predictive power over future volatility.},
	urldate = {2024-10-07},
	booktitle = {2015 {IEEE} {International} {Conference} on {Data} {Science} and {Advanced} {Analytics} ({DSAA})},
	author = {Olaniyan, Rapheal and Stamate, Daniel and Ouarbya, Lahcen and Logofatu, Doina},
	month = oct,
	year = {2015},
	keywords = {Benchmark testing, EGARCH, Electric shock, GARCH, Granger causality, Monte Carlo methods, Monte Carlo simulations, Neural networks, Predictive models, Standards, Stock markets, artificial neural networks, non-parametric test, sentiment, stock market, volatility},
	pages = {1--10},
}

@article{gros-klusmann_when_2011,
	title = {When machines read the news: {Using} automated text analytics to quantify high frequency news-implied market reactions},
	volume = {18},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {09275398},
	shorttitle = {When machines read the news},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0927539810000873},
	doi = {10.1016/j.jempfin.2010.11.009},
	language = {en},
	number = {2},
	urldate = {2024-10-07},
	journal = {Journal of Empirical Finance},
	author = {Groß-Klußmann, Axel and Hautsch, Nikolaus},
	month = mar,
	year = {2011},
	pages = {321--340},
}

@inproceedings{phillips_predicting_2017,
	address = {Honolulu, HI},
	title = {Predicting cryptocurrency price bubbles using social media data and epidemic modelling},
	isbn = {978-1-5386-2726-6},
	url = {http://ieeexplore.ieee.org/document/8280809/},
	doi = {10.1109/SSCI.2017.8280809},
	abstract = {Financial price bubbles have previously been linked with the epidemic-like spread of an investment idea; such bubbles are commonly seen in cryptocurrency prices. This paper aims to predict such bubbles for a number of cryptocurrencies using a hidden Markov model previously utilised to detect influenza epidemic outbreaks, based in this case on the behaviour of novel online social media indicators. To validate the methodology further, a trading strategy is built and tested on historical data. The resulting trading strategy outperforms a buy and hold strategy. The work demonstrates both the broader utility of epidemic-detecting hidden Markov models in the identification of bubble-like behaviour in time series, and that social media can provide valuable predictive information pertaining to cryptocurrency price movements.},
	language = {en},
	urldate = {2024-10-04},
	booktitle = {2017 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	publisher = {IEEE},
	author = {Phillips, Ross C. and Gorse, Denise},
	month = nov,
	year = {2017},
	pages = {1--7},
}

@article{ashtiani_news-based_2023,
	title = {News-based intelligent prediction of financial markets using text mining and machine learning: {A} systematic literature review},
	volume = {217},
	issn = {09574174},
	shorttitle = {News-based intelligent prediction of financial markets using text mining and machine learning},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417423000106},
	doi = {10.1016/j.eswa.2023.119509},
	abstract = {Researchers and practitioners have attempted to predict the financial market by analyzing textual (e.g., news articles and social media) and numeric data (e.g., hourly stock prices, and moving averages). Among textual data, while many papers have been published that analyze social media, news content has gained limited attention in predicting the stock market. Acknowledging that news is critical in predicting the stock market, the focus of this systematic review is on papers investigating machine learning and text mining techniques to predict the stock market using news. Using Kitchenham’s methodology, we present a systematic review of the literature on intelligent financial market prediction, examining data mining and machine learning approaches and the employed datasets. From five digital libraries, we identified 61 studies from 2015–2022 for synthesis and interpretation. We present notable gaps and barriers to predicting financial markets, then recommend future research scopes. Various input data, including numerical (stock prices and technical indicators) and textual data (news text and sentiment), have been employed for news-based stock market prediction. News data collection can be costly and time-consuming: most studies have used custom crawlers to gather news articles; however, there are financial news databases available that could significantly facilitate news collection. Furthermore, although most datasets have covered fewer than 100K records, deep learning and more sophisticated artificial neural networks can process enormous datasets faster, improving future model performance. There is a growing trend toward using artificial neural networks, particularly recurrent neural networks and deep learning models, from 2018 to 2021. Furthermore, regression and gradient-boosting models have been developed for stock market prediction during the last four years. Although word embedding approaches for feature representation have been employed recently with good accuracy, emerging language models may be a focus for future research. Advanced natural language processing methods like transformers have undeniably contributed to intelligent stock market prediction. However, stock market prediction has not yet taken full advantage of them.},
	language = {en},
	urldate = {2024-10-04},
	journal = {Expert Systems with Applications},
	author = {Ashtiani, Matin N. and Raahemi, Bijan},
	month = may,
	year = {2023},
	pages = {119509},
}

@article{zadeh_predicting_nodate,
	title = {Predicting {Market}-{Volatility} from {Federal} {Reserve} {Board} {Meeting} {Minutes} {NLP} for {Finance}},
	language = {en},
	author = {Zadeh, Reza Bosagh and Zollmann, Andreas},
}

@article{kumar_survey_2016,
	title = {A survey of the applications of text mining in financial domain},
	volume = {114},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705116303872},
	doi = {10.1016/j.knosys.2016.10.003},
	abstract = {Text mining has found a variety of applications in diverse domains. Of late, proliﬁc work is reported in using text mining techniques to solve problems in ﬁnancial domain. The objective of this paper is to provide a state-of-the-art survey of various applications of Text mining to ﬁnance. These applications are categorized broadly into FOREX rate prediction, stock market prediction, customer relationship management (CRM) and cyber security. Since ﬁnance is a service industry, these problems are paramount in operational and customer growth aspects. We reviewed 89 research papers that appeared during the period 2000–2016, highlighted some of the issues, gaps, key challenges in this area and proposed some future research directions. Finally, this review can be extremely useful to budding researchers in this area, as many open problems are highlighted.},
	language = {en},
	urldate = {2024-10-03},
	journal = {Knowledge-Based Systems},
	author = {Kumar, B. Shravan and Ravi, Vadlamani},
	month = dec,
	year = {2016},
	pages = {128--147},
}

@article{johansen_crashes_2000,
	title = {Crashes as critical points},
	volume = {03},
	issn = {0219-0249},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0219024900000115},
	doi = {10.1142/S0219024900000115},
	abstract = {We study a rational expectation model of bubbles and crashes. The model has two components: (1) our key assumption is that a crash may be caused by local self-reinforcing imitation between noise traders. If the tendency for noise traders to imitate their nearest neighbors increases up to a certain point called the "critical" point, all noise traders may place the same order (sell) at the same time, thus causing a crash. The interplay between the progressive strengthening of imitation and the ubiquity of noise is characterized by the hazard rate, i.e. the probability per unit time that the crash will happen in the next instant if it has not happened yet. (2) Since the crash is not a certain deterministic outcome of the bubble, it remains rational for traders to remain invested provided they are compensated by a higher rate of growth of the bubble for taking the risk of a crash. Our model distinguishes between the end of the bubble and the time of the crash: the rational expectation constraint has the specific implication that the date of the crash must be random. The theoretical death of the bubble is not the time of the crash because the crash could happen at any time before, even though this is not very likely. The death of the bubble is the most probable time for the crash. There also exists a finite probability of attaining the end of the bubble without crash. Our model has specific predictions about the presence of certain critical log-periodic patterns in pre-crash prices, associated with the deterministic components of the bubble mechanism. We provide empirical evidence showing that these patterns were indeed present before the crashes of 1929, 1962 and 1987 on Wall Street and the 1997 crash on the Hong Kong Stock Exchange. These results are compared with statistical tests on synthetic data.},
	number = {02},
	urldate = {2024-10-03},
	journal = {International Journal of Theoretical and Applied Finance},
	author = {Johansen, Anders and Ledoit, Olivier and Sornette, Didier},
	month = apr,
	year = {2000},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {219--255},
}

@article{feigenbaum_discrete_1996,
	title = {Discrete scale invariance in stock markets before crashes},
	volume = {10},
	issn = {0217-9792},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S021797929600204X},
	doi = {10.1142/S021797929600204X},
	abstract = {We propose a picture of stock market crashes as critical points in a system with discrete scale invariance. The critical exponent is then complex, leading to log-periodic fluctuations in stock market indexes. We present “experimental” evidence in favor of this prediction. This picture is in the spirit of the known earthquake-stock market analogy and of recent work on log-periodic fluctuations associated with earthquakes.},
	number = {27},
	urldate = {2024-10-02},
	journal = {International Journal of Modern Physics B},
	author = {Feigenbaum, James A. and Freund, Peter G.o.},
	month = dec,
	year = {1996},
	note = {Publisher: World Scientific Publishing Co.},
	pages = {3737--3745},
}

@article{sornette_stock_1996,
	title = {Stock {Market} {Crashes}, {Precursors} and {Replicas}},
	volume = {6},
	copyright = {Les Editions de Physique},
	issn = {1155-4304, 1286-4862},
	url = {http://dx.doi.org/10.1051/jp1:1996135},
	doi = {10.1051/jp1:1996135},
	abstract = {Journal de Physique I, Journal de Physique Archives représente une mine d informations facile à consulter sur la manière dont la physique a été publiée depuis 1872.},
	language = {en},
	number = {1},
	urldate = {2024-10-02},
	journal = {Journal de Physique I},
	author = {Sornette, Didier and Johansen, Anders and Bouchaud, Jean-Philippe},
	month = jan,
	year = {1996},
	note = {Publisher: EDP Sciences},
	pages = {167--175},
}

@article{shu_detection_2024,
	title = {Detection of financial bubbles using a log‐periodic power law singularity ( {\textless}span style="font-variant:small-caps;"{\textgreater}{LPPLS}{\textless}/span{\textgreater} ) model},
	volume = {16},
	issn = {1939-5108, 1939-0068},
	shorttitle = {Detection of financial bubbles using a log‐periodic power law singularity ( {\textless}span style="font-variant},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/wics.1649},
	doi = {10.1002/wics.1649},
	abstract = {This article provides a systematic review of the theoretical and empirical academic literature on the development and extension of the log-periodic power law singularity (LPPLS) model, which is also known as the Johansen–Ledoit–Sornette (JLS) model or log-periodic power law (LPPL) model. Developed at the interface of financial economics, behavioral finance and statistical physics, the LPPLS model provides a flexible and quantitative framework for detecting financial bubbles and crashes by capturing two salient empirical characteristics of price trajectories in speculative bubble regimes: the faster-than-exponential growth of price leading to unsustainable growth ending with a finite crashtime and the accelerating log-periodic oscillations. We also demonstrate the LPPLS model by detecting the recent bubble status of the S\&P 500 index between April 2020 and December 2022, during which the S\&P 500 index reaches its all-time peak at the end of 2021. We find that the strong corrections of the S\&P 500 index starting from January 2022 stem from the increasingly systemic instability of the stock market itself, while the well-known external shocks, such as the decades-high inflation, aggressive monetary policy tightening by the Federal Reserve, and the impact of the Russia/Ukraine war, may serve as sparks.},
	language = {en},
	number = {2},
	urldate = {2024-10-02},
	journal = {WIREs Computational Statistics},
	author = {Shu, Min and Song, Ruiqiang},
	month = mar,
	year = {2024},
	pages = {e1649},
}

@article{campbell_stock_1988,
	title = {Stock {Prices}, {Earnings}, and {Expected} {Dividends}},
	volume = {43},
	issn = {0022-1082},
	url = {https://www.jstor.org/stable/2328190},
	doi = {10.2307/2328190},
	abstract = {Long historical averages of real earnings help forecast present values of future real dividends. With aggregate U.S. stock market data (1871-1986), a vector-autoregressive forecast of the present value of future dividends is, for each year, roughly a weighted average of moving-average earnings and current real price, with between two thirds and three fourths of the weight on the earnings measure. We develop the implications of this for the present-value model of stock prices and for recent results that long-horizon stock returns are highly forecastable.},
	number = {3},
	urldate = {2024-10-02},
	journal = {The Journal of Finance},
	author = {Campbell, John Y. and Shiller, Robert J.},
	year = {1988},
	note = {Publisher: [American Finance Association, Wiley]},
	pages = {661--676},
}

@article{ait-sahalia_nonparametric_1998,
	title = {Nonparametric {Estimation} of {State}-{Price} {Densities} {Implicit} in {Financial} {Asset} {Prices}},
	abstract = {Implicit in the prices of traded financial assets are Arrow–Debreu prices or, with continuous states, the state-price density (SPD). We construct a nonparametric estimator for the SPD implicit in option prices and we derive its asymptotic sampling theory. This estimator provides an arbitrage-free method of pricing new, complex, or illiquid securities while capturing those features of the data that are most relevant from an asset-pricing perspective, for example, negative skewness and excess kurtosis for asset returns, and volatility “smiles” for option prices. We perform Monte Carlo experiments and extract the SPD from actual S\&P 500 option prices.},
	language = {en},
	journal = {The Journal of Finance},
	author = {Aït-Sahalia, Yacine and Lo, Andrew W},
	month = apr,
	year = {1998},
}

@article{cox_local_2005,
	title = {Local martingales, bubbles and option prices},
	volume = {9},
	copyright = {http://www.springer.com/tdm},
	issn = {0949-2984, 1432-1122},
	url = {http://link.springer.com/10.1007/s00780-005-0162-y},
	doi = {10.1007/s00780-005-0162-y},
	abstract = {In this article we are interested in option pricing in markets with bubbles. A bubble is deﬁned to be a price process which, when discounted, is a local martingale under the risk-neutral measure but not a martingale. We give examples of bubbles both where volatility increases with the price level, and where the bubble is the result of a feedback mechanism. In a market with a bubble many standard results from the folklore become false. Put-call parity fails, the price of an American call exceeds that of a European call and call prices are no longer increasing in maturity (for a ﬁxed strike). We show how these results must be modiﬁed in the presence of a bubble. It turns out that the option value depends critically on the deﬁnition of admissible strategy, and that the standard mathematical deﬁnition may not be consistent with the deﬁnitions used for trading.},
	language = {en},
	number = {4},
	urldate = {2024-09-26},
	journal = {Finance and Stochastics},
	author = {Cox, Alexander M. G. and Hobson, David G.},
	month = oct,
	year = {2005},
	pages = {477--492},
}

@article{loewenstein_rational_2000,
	title = {Rational {Equilibrium} {Asset}-{Pricing} {Bubbles} in {Continuous} {Trading} {Models}},
	volume = {91},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00220531},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022053199925899},
	doi = {10.1006/jeth.1999.2589},
	language = {en},
	number = {1},
	urldate = {2024-09-26},
	journal = {Journal of Economic Theory},
	author = {Loewenstein, Mark and Willard, Gregory A.},
	month = mar,
	year = {2000},
	pages = {17--58},
}

@article{jarrow_inferring_2021,
	title = {Inferring financial bubbles from option data},
	volume = {36},
	issn = {1099-1255},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.2862},
	doi = {10.1002/jae.2862},
	abstract = {Financial bubbles arise when the underlying asset's market price deviates from its fundamental value. Unlike other bubble tests that use time series data and assume a reduced-form price process, we infer the existence of bubbles nonparametrically using option price data. Under no-arbitrage and acknowledging data constraints, we can partially identify asset price bubbles using a cross section of European option prices. In the empirical analysis, we obtain interval estimates of price bubbles embedded in the S\&P 500 Index. The estimated index bubbles are then used to construct profitable momentum trading strategies that consistently outperform a buy-and-hold trading strategy.},
	language = {en},
	number = {7},
	urldate = {2024-09-24},
	journal = {Journal of Applied Econometrics},
	author = {Jarrow, Robert A. and Kwok, Simon S.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2862},
	keywords = {asset price bubble, fundamental value, nonparametric estimation, partial identi.cation, risk-neutral probability measure, state price distribution},
	pages = {1013--1046},
}

@misc{woodman_defining_2021,
	title = {Defining, detecting and measuring asset price bubbles - {News} \& insight},
	url = {https://www.jbs.cam.ac.uk/2021/defining-detecting-measuring-asset-price-bubbles/},
	abstract = {One of the most frequently asked questions in the financial news media this year has been whether the stock market is in a 'bubble'?},
	language = {en-GB},
	urldate = {2024-09-23},
	journal = {Cambridge Judge Business School},
	author = {Woodman, Charlie},
	month = apr,
	year = {2021},
}

@techreport{hofmann_probabilistic_1999,
	title = {Probabilistic {Latent} {Semantic} {Analysis}},
	abstract = {Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.},
	number = {arXiv:1301.6705},
	urldate = {2024-08-28},
	institution = {arXiv},
	author = {Hofmann, Thomas},
	year = {1999},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{gurkaynak_econometric_2008,
	title = {Econometric {Tests} of {Asset} {Price} {Bubbles}: {Taking} {Stock}},
	volume = {22},
	issn = {1467-6419},
	shorttitle = {Econometric {Tests} of {Asset} {Price} {Bubbles}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6419.2007.00530.x},
	doi = {10.1111/j.1467-6419.2007.00530.x},
	abstract = {Can asset price bubbles be detected? This survey of econometric tests of asset price bubbles shows that, despite recent advances, econometric detection of asset price bubbles cannot be achieved with a satisfactory degree of certainty. For each paper that finds evidence of bubbles, there is another one that fits the data equally well without allowing for a bubble. We are still unable to distinguish bubbles from time-varying or regime-switching fundamentals, while many small sample econometrics problems of bubble tests remain unresolved.},
	language = {en},
	number = {1},
	urldate = {2024-09-20},
	journal = {Journal of Economic Surveys},
	author = {Gürkaynak, Refet S.},
	year = {2008},
	keywords = {Bubbles, Econometric tests, Identification},
	pages = {166--186},
}

@book{cooper_origin_2008,
	title = {The {Origin} of {Financial} {Crises}},
	isbn = {978-0-307-47368-4},
	abstract = {In a series of disarmingly simple arguments financial market analyst George Cooper challenges the core principles of today's economic orthodoxy and explains how we have created an economy that is inherently unstable and crisis prone. With great skill, he examines the very foundations of today's economic philosophy and adds a compelling analysis of the forces behind economic crisis. His goal is nothing less than preventing the seemingly endless procession of damaging boom-bust cycles, unsustainable economic bubbles, crippling credit crunches, and debilitating inflation. His direct, conscientious, and honest approach will captivate any reader and is an invaluable aid in understanding today's economy.},
	language = {en},
	publisher = {Knopf Doubleday Publishing Group},
	author = {Cooper, George},
	month = dec,
	year = {2008},
	keywords = {Business \& Economics / Economic History, Business \& Economics / Economics / Theory, History / United States / 21st Century},
}

@article{cooper_origin_2008-1,
	title = {The {Origin} of {Financial} {Crises}: {Central} {Banks}, {Credit} {Bubbles}, and the {Efficient} {Market} {Fallacy}},
	doi = {null},
	abstract = {Preface 1. Introduction 2. Efficient Markets \& Central Banks? 3. Money, Banks \& Central Banks 4. Stable and Unstable Markets 5. Deceiving the Diligent 6. On (Central Bank) Governors 7. Minsky Meets Mandelbrot 8. Beyond the Efficient Market Fallacy 9. Concluding Remarks},
	journal = {null},
	author = {Cooper, George and Cooper, George},
	year = {2008},
	pmid = {null},
	pmcid = {null},
}

@book{shiller_narrative_2019,
	title = {Narrative {Economics}: {How} {Stories} {Go} {Viral} and {Drive} {Major} {Economic} {Events}},
	isbn = {978-0-691-18229-2},
	language = {en},
	urldate = {2024-09-11},
	publisher = {Princeton University Press},
	author = {Shiller, Robert J.},
	month = oct,
	year = {2019},
}

@misc{snsf_snsf_2024,
	title = {{SNSF} {Narrative} {Digital} {Finance} - {EU} {COST} {Fin}-{AI}},
	url = {https://wiki.fin-ai.eu/index.php/SNSF_Narrative_Digital_Finance},
	urldate = {2024-09-05},
	author = {SNSF},
	month = sep,
	year = {2024},
}

@misc{msca_msca_2024,
	title = {{MSCA} {Digital} {Finance}},
	url = {https://www.digital-finance-msca.com/individual-research-projects},
	language = {en},
	urldate = {2024-09-05},
	journal = {Digital Finance MSCA},
	author = {MSCA},
	month = sep,
	year = {2024},
}

@article{phillips_testing_2015,
	title = {{TESTING} {FOR} {MULTIPLE} {BUBBLES}: {HISTORICAL} {EPISODES} {OF} {EXUBERANCE} {AND} {COLLAPSE} {IN} {THE} {S}\&{P} 500},
	volume = {56},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0020-6598, 1468-2354},
	shorttitle = {{TESTING} {FOR} {MULTIPLE} {BUBBLES}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/iere.12132},
	doi = {10.1111/iere.12132},
	abstract = {Recent work on econometric detection mechanisms has shown the effectiveness of recursive procedures in identifying and dating financial bubbles in real time. These procedures are useful as warning alerts in surveillance strategies conducted by central banks and fiscal regulators with real‐time data. Use of these methods over long historical periods presents a more serious econometric challenge due to the complexity of the nonlinear structure and break mechanisms that are inherent in multiple‐bubble phenomena within the same sample period. To meet this challenge, this article develops a new recursive flexible window method that is better suited for practical implementation with long historical time series. The method is a generalized version of the sup augmented Dickey–Fuller (ADF) test of Phillips et al. (“Explosive behavior in the 1990s NASDAQ: When did exuberance escalate asset values?”
              International Economic Review
              52 (2011), 201–26; PWY) and delivers a consistent real‐time date‐stamping strategy for the origination and termination of multiple bubbles. Simulations show that the test significantly improves discriminatory power and leads to distinct power gains when multiple bubbles occur. An empirical application of the methodology is conducted on S\&P 500 stock market data over a long historical period from January 1871 to December 2010. The new approach successfully identifies the well‐known historical episodes of exuberance and collapses over this period, whereas the strategy of PWY and a related cumulative sum (CUSUM) dating procedure locate far fewer episodes in the same sample range.},
	language = {en},
	number = {4},
	urldate = {2024-09-04},
	journal = {International Economic Review},
	author = {Phillips, Peter C. B. and Shi, Shuping and Yu, Jun},
	month = nov,
	year = {2015},
	pages = {1043--1078},
}

@article{phillips_testing_2015-1,
	title = {Testing for {Multiple} {Bubbles}: {Historical} {Episodes} of {Exuberance} and {Collapse} in the {S}\&p 500},
	volume = {56},
	issn = {1468-2354},
	shorttitle = {Testing for {Multiple} {Bubbles}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/iere.12132},
	doi = {10.1111/iere.12132},
	abstract = {Recent work on econometric detection mechanisms has shown the effectiveness of recursive procedures in identifying and dating financial bubbles in real time. These procedures are useful as warning alerts in surveillance strategies conducted by central banks and fiscal regulators with real-time data. Use of these methods over long historical periods presents a more serious econometric challenge due to the complexity of the nonlinear structure and break mechanisms that are inherent in multiple-bubble phenomena within the same sample period. To meet this challenge, this article develops a new recursive flexible window method that is better suited for practical implementation with long historical time series. The method is a generalized version of the sup augmented Dickey–Fuller (ADF) test of Phillips et al. (“Explosive behavior in the 1990s NASDAQ: When did exuberance escalate asset values?” International Economic Review 52 (2011), 201–26; PWY) and delivers a consistent real-time date-stamping strategy for the origination and termination of multiple bubbles. Simulations show that the test significantly improves discriminatory power and leads to distinct power gains when multiple bubbles occur. An empirical application of the methodology is conducted on S\&P 500 stock market data over a long historical period from January 1871 to December 2010. The new approach successfully identifies the well-known historical episodes of exuberance and collapses over this period, whereas the strategy of PWY and a related cumulative sum (CUSUM) dating procedure locate far fewer episodes in the same sample range.},
	language = {en},
	number = {4},
	urldate = {2024-09-04},
	journal = {International Economic Review},
	author = {Phillips, Peter C. B. and Shi, Shuping and Yu, Jun},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/iere.12132},
	pages = {1043--1078},
}

@article{jarrow_asset_2010,
	title = {{ASSET} {PRICE} {BUBBLES} {IN} {INCOMPLETE} {MARKETS}},
	volume = {20},
	copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
	issn = {09601627, 14679965},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9965.2010.00394.x},
	doi = {10.1111/j.1467-9965.2010.00394.x},
	abstract = {This paper studies asset price bubbles in a continuous time model using the local martingale framework. Providing careful deﬁnitions of the asset’s market and fundamental price, we characterize all possible price bubbles in an incomplete market satisfying the “no free lunch with vanishing risk (NFLVR)” and “no dominance” assumptions. We show that the two leading models for bubbles as either charges or as strict local martingales, respectively, are equivalent. We propose a new theory for bubble birth that involves a nontrivial modiﬁcation of the classical martingale pricing framework. This modiﬁcation involves the market exhibiting different local martingale measures across time—a possibility not previously explored within the classical theory. Finally, we investigate the pricing of derivative securities in the presence of asset price bubbles, and we show that: (i) European put options can have no bubbles; (ii) European call options and discounted forward prices have bubbles whose magnitudes are related to the asset’s price bubble; (iii) with no dividends, American call options are not exercised early; (iv) European put-call parity in market prices must always hold, regardless of bubbles; and (v) futures price bubbles can exist and they are independent of the underlying asset’s price bubble. Many of these results stand in contrast to those of the classical theory. We propose, but do not implement, some new tests for the existence of asset price bubbles using derivative securities.},
	language = {en},
	number = {2},
	urldate = {2024-09-04},
	journal = {Mathematical Finance},
	author = {Jarrow, Robert A. and Protter, Philip and Shimbo, Kazuhiro},
	month = apr,
	year = {2010},
	pages = {145--185},
}

@article{jarrow_asset_2010-1,
	title = {Asset {Price} {Bubbles} in {Incomplete} {Markets}},
	volume = {20},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9965.2010.00394.x},
	doi = {10.1111/j.1467-9965.2010.00394.x},
	abstract = {This paper studies asset price bubbles in a continuous time model using the local martingale framework. Providing careful definitions of the asset's market and fundamental price, we characterize all possible price bubbles in an incomplete market satisfying the “no free lunch with vanishing risk (NFLVR)” and “no dominance” assumptions. We show that the two leading models for bubbles as either charges or as strict local martingales, respectively, are equivalent. We propose a new theory for bubble birth that involves a nontrivial modification of the classical martingale pricing framework. This modification involves the market exhibiting different local martingale measures across time—a possibility not previously explored within the classical theory. Finally, we investigate the pricing of derivative securities in the presence of asset price bubbles, and we show that: (i) European put options can have no bubbles; (ii) European call options and discounted forward prices have bubbles whose magnitudes are related to the asset's price bubble; (iii) with no dividends, American call options are not exercised early; (iv) European put-call parity in market prices must always hold, regardless of bubbles; and (v) futures price bubbles can exist and they are independent of the underlying asset's price bubble. Many of these results stand in contrast to those of the classical theory. We propose, but do not implement, some new tests for the existence of asset price bubbles using derivative securities.},
	language = {en},
	number = {2},
	urldate = {2024-09-04},
	journal = {Mathematical Finance},
	author = {Jarrow, Robert A. and Protter, Philip and Shimbo, Kazuhiro},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9965.2010.00394.x},
	keywords = {NFLVR, local martingales, no dominance, price bubbles},
	pages = {145--185},
}

@article{biagini_detecting_2024,
	title = {Detecting asset price bubbles using deep learning},
	volume = {n/a},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12443},
	doi = {10.1111/mafi.12443},
	abstract = {In this paper, we employ deep learning techniques to detect financial asset bubbles by using observed call option prices. The proposed algorithm is widely applicable and model-independent. We test the accuracy of our methodology in numerical experiments within a wide range of models and apply it to market data of tech stocks in order to assess if asset price bubbles are present. Under a given condition on the pricing of call options under asset price bubbles, we are able to provide a theoretical foundation of our approach for positive and continuous stochastic asset price processes. When such a condition is not satisfied, we focus on local volatility models. To this purpose, we give a new necessary and sufficient condition for a process with time-dependent local volatility function to be a strict local martingale.},
	language = {en},
	number = {n/a},
	urldate = {2024-09-04},
	journal = {Mathematical Finance},
	author = {Biagini, Francesca and Gonon, Lukas and Mazzon, Andrea and Meyer-Brandis, Thilo},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12443},
}

@techreport{ke_predicting_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Predicting {Returns} with {Text} {Data}},
	url = {https://papers.ssrn.com/abstract=3389884},
	abstract = {We introduce a new text-mining methodology that extracts information from news articles to predict asset returns. Unlike more common sentiment scores used for stock return prediction (e.g., those sold by commercial vendors or built with dictionary-based methods), our supervised learning framework constructs a score that is specifically adapted to the problem of return prediction. Our method proceeds in three steps: 1) isolating a list of terms via predictive screening, 2) assigning prediction weights to these words via topic modeling, and 3) aggregating terms into an article-level predictive score via penalized likelihood. We derive theoretical guarantees on the accuracy of estimates from our model with minimal assumptions. In our empirical analysis, we study one of the most actively monitored streams of news articles in the financial system--the Dow Jones Newswires--and show that our supervised text model excels at extracting return-predictive signals in this context. Information in newswires is assimilated into prices with an ineffcient delay that is broadly consistent with limits-to-arbitrage (i.e., more severe for smaller and more volatile firms) yet can be exploited in a real-time trading strategy with reasonable turnover and net of transaction costs.},
	language = {en},
	number = {3389884},
	urldate = {2024-09-04},
	institution = {Social Science Research Network},
	author = {Ke, Zheng Tracy and Kelly, Bryan T. and Xiu, Dacheng},
	month = sep,
	year = {2020},
	doi = {10.2139/ssrn.3389884},
	keywords = {Machine Learning, Penalized Likelihood, Return Predictability, Screening, Sentiment Analysis, Text Mining, Topic Modeling},
}

@article{fusari_testing_2020,
	title = {Testing for {Asset} {Price} {Bubbles} using {Options} {Data}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3670999},
	doi = {10.2139/ssrn.3670999},
	abstract = {We present a new approach to identifying asset price bubbles based on options data. We estimate asset bubbles by exploiting the diﬀerential pricing between put and call options. We apply our methodology to two stock market indexes, the S\&P 500 and the Nasdaq-100, and two technology stocks, Amazon and Facebook, over the 2014-2018 sample period. We ﬁnd that, while indexes do not exhibit signiﬁcant bubbles, Amazon and Facebook show frequent and signiﬁcant bubbles. The estimated bubbles tend to be associated with large volatility, large trading volume, and earning announcement days. Since our approach can be implemented in real time, it is useful to both policy-makers and investors. As an illustration we consider two case studies: the Nasdaq dot-com bubble (between 1999 to 2002) and GameStop (between December 2020 and January 2021). In both cases we identify signiﬁcant and persistent bubbles.},
	language = {en},
	urldate = {2024-09-02},
	journal = {SSRN Electronic Journal},
	author = {Fusari, Nicola and Jarrow, Robert and Lamichhane, Sujan},
	year = {2020},
}

@article{bashchenko_deep_2020,
	title = {Deep {Learning} for {Asset} {Bubbles} {Detection}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3531154},
	doi = {10.2139/ssrn.3531154},
	abstract = {We develop a methodology for detecting asset bubbles using a neural network. We rely on the theory of local martingales in continuous-time and use a deep network to estimate the diffusion coefﬁcient of the price process more accurately than the current estimator, obtaining an improved detection of bubbles. We show the outperformance of our algorithm over the existing statistical method in a laboratory created with simulated data. We then apply the network classiﬁcation to real data and build a zero net exposure trading strategy that exploits the risky arbitrage emanating from the presence of bubbles in the US equity market from 2006 to 2008. The proﬁtability of the strategy provides an estimation of the economical magnitude of bubbles as well as support for the theoretical assumptions relied on.},
	language = {en},
	urldate = {2024-09-02},
	journal = {SSRN Electronic Journal},
	author = {Bashchenko, Oksana and Marchal, Alexis},
	year = {2020},
}

@article{jegadeesh_word_2013,
	title = {Word power: {A} new approach for content analysis},
	volume = {110},
	issn = {0304405X},
	shorttitle = {Word power},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304405X13002328},
	doi = {10.1016/j.jfineco.2013.08.018},
	abstract = {We present a new approach for content analysis to quantify document tone. We find a significant relation between our measure of the tone of 10-Ks and market reaction for both negative and positive words. We also find that the appropriate choice of term weighting in content analysis is at least as important as, and perhaps more important than, a complete and accurate compilation of the word list. Furthermore, we show that our approach circumvents the need to subjectively partition words into positive and negative word lists. Our approach reliably quantifies the tone of IPO prospectuses as well, and we find that the document score is negatively related to IPO underpricing.},
	language = {en},
	number = {3},
	urldate = {2024-08-29},
	journal = {Journal of Financial Economics},
	author = {Jegadeesh, Narasimhan and Wu, Di},
	month = dec,
	year = {2013},
	pages = {712--729},
}

@article{jegadeesh_word_2013-1,
	title = {Word power: {A} new approach for content analysis},
	volume = {110},
	issn = {0304-405X},
	shorttitle = {Word power},
	url = {https://www.sciencedirect.com/science/article/pii/S0304405X13002328},
	doi = {10.1016/j.jfineco.2013.08.018},
	abstract = {We present a new approach for content analysis to quantify document tone. We find a significant relation between our measure of the tone of 10-Ks and market reaction for both negative and positive words. We also find that the appropriate choice of term weighting in content analysis is at least as important as, and perhaps more important than, a complete and accurate compilation of the word list. Furthermore, we show that our approach circumvents the need to subjectively partition words into positive and negative word lists. Our approach reliably quantifies the tone of IPO prospectuses as well, and we find that the document score is negatively related to IPO underpricing.},
	number = {3},
	urldate = {2024-08-29},
	journal = {Journal of Financial Economics},
	author = {Jegadeesh, Narasimhan and Wu, Di},
	month = dec,
	year = {2013},
	keywords = {Content analysis, Lexicons, Term weighting},
	pages = {712--729},
}

@article{ke_recent_nodate,
	title = {Recent {Advances} in {Text} {Analysis}},
	abstract = {Text analysis is an interesting research area in data science and has various applications, such as in artificial intelligence, biomedical research, and engineering. We review popular methods for text analysis, ranging from topic modeling to the recent neural language models. In particular, we review Topic-SCORE, a statistical approach to topic modeling, and discuss how to use it to analyze the Multi-Attribute Data Set on Statisticians (MADStat), a data set on statistical publications that we collected and cleaned. The application of Topic-SCORE and other methods to MADStat leads to interesting findings. For example, we identified 11 representative topics in statistics. For each journal, the evolution of topic weights over time can be visualized, and these results are used to analyze the trends in statistical research. In particular, we propose a new statistical model for ranking the citation impacts of 11 topics, and we also build a cross-topic citation graph to illustrate how research results on different topics spread to one another. The results on MADStat provide a data-driven picture of the statistical research from 1975 to 2015, from a text analysis perspective.},
	language = {en},
	author = {Ke, Zheng Tracy and Ji, Pengsheng and Jin, Jiashun and Li, Wanshan},
}

@article{tetlock_giving_2007,
	title = {Giving {Content} to {Investor} {Sentiment}: {The} {Role} of {Media} in the {Stock} {Market}},
	volume = {62},
	copyright = {© 2007 the American Finance Association},
	issn = {1540-6261},
	shorttitle = {Giving {Content} to {Investor} {Sentiment}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2007.01232.x},
	doi = {10.1111/j.1540-6261.2007.01232.x},
	abstract = {I quantitatively measure the interactions between the media and the stock market using daily content from a popular Wall Street Journal column. I find that high media pessimism predicts downward pressure on market prices followed by a reversion to fundamentals, and unusually high or low pessimism predicts high market trading volume. These and similar results are consistent with theoretical models of noise and liquidity traders, and are inconsistent with theories of media content as a proxy for new information about fundamental asset values, as a proxy for market volatility, or as a sideshow with no relationship to asset markets.},
	language = {en},
	number = {3},
	urldate = {2024-08-29},
	journal = {The Journal of Finance},
	author = {Tetlock, Paul C.},
	year = {2007},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-6261.2007.01232.x},
	pages = {1139--1168},
}

@article{renault_sentiment_2020,
	title = {Sentiment analysis and machine learning in finance: a comparison of methods and models on one million messages},
	volume = {2},
	issn = {2524-6984, 2524-6186},
	shorttitle = {Sentiment analysis and machine learning in finance},
	url = {http://link.springer.com/10.1007/s42521-019-00014-x},
	doi = {10.1007/s42521-019-00014-x},
	abstract = {We use a large dataset of one million messages sent on the microblogging platform StockTwits to evaluate the performance of a wide range of preprocessing methods and machine learning algorithms for sentiment analysis in finance. We find that adding bigrams and emojis significantly improve sentiment classification performance. However, more complex and time-consuming machine learning methods, such as random forests or neural networks, do not improve the accuracy of the classification. We also provide empirical evidence that the preprocessing method and the size of the dataset have a strong impact on the correlation between investor sentiment and stock returns. While investor sentiment and stock returns are highly correlated, we do not find that investor sentiment derived from messages sent on social media helps in predicting large capitalization stocks return at a daily frequency.},
	language = {en},
	number = {1-2},
	urldate = {2024-08-27},
	journal = {Digital Finance},
	author = {Renault, Thomas},
	month = sep,
	year = {2020},
	pages = {1--13},
}

@article{renault_intraday_2017,
	title = {Intraday online investor sentiment and return patterns in the {U}.{S}. stock market},
	volume = {84},
	issn = {03784266},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378426617301589},
	doi = {10.1016/j.jbankfin.2017.07.002},
	language = {en},
	urldate = {2024-08-27},
	journal = {Journal of Banking \& Finance},
	author = {Renault, Thomas},
	month = nov,
	year = {2017},
	pages = {25--40},
}

@misc{httpshuggingfaceco_hugging_2024,
	title = {Hugging {Face} – {The} {AI} community building the future.},
	url = {https://huggingface.co/},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-08-26},
	author = {https://huggingface.co},
	month = aug,
	year = {2024},
}

@article{ghoshal_extracting_2016,
	title = {Extracting predictive information from heterogeneous data streams using {Gaussian} {Processes}},
	volume = {5},
	issn = {21585571, 21576203},
	url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/AF-160055},
	doi = {10.3233/AF-160055},
	abstract = {Financial markets are notoriously complex environments, presenting vast amounts of noisy, yet potentially informative data. We consider the problem of forecasting ﬁnancial time series from a wide range of information sources using online Gaussian Processes with Automatic Relevance Determination (ARD) kernels. We measure the performance gain, quantiﬁed in terms of Normalised Root Mean Square Error (NRMSE), Median Absolute Deviation (MAD) and Pearson correlation, from fusing each of four separate data domains: time series technicals, sentiment analysis, options market data and broker recommendations. We show evidence that ARD kernels produce meaningful feature rankings that help retain salient inputs and reduce input dimensionality, providing a framework for sifting through ﬁnancial complexity. We measure the performance gain from fusing each domain’s heterogeneous data streams into a single probabilistic model. In particular our ﬁndings highlight the critical value of options data in mapping out the curvature of price space and inspire an intuitive, novel direction for research in ﬁnancial prediction.},
	language = {en},
	number = {1-2},
	urldate = {2024-08-27},
	journal = {Algorithmic Finance},
	author = {Ghoshal, S. and Roberts, S.},
	month = jun,
	year = {2016},
	pages = {21--30},
}

@article{ke_predicting_2021,
	title = {Predicting {Returns} with {Text} {Data}},
	abstract = {We introduce a new text-mining methodology that extracts information from news articles to predict asset returns. Unlike more common sentiment scores used for stock return prediction (e.g., those sold by commercial vendors or built with dictionary-based methods), our supervised learning framework constructs a score that is speciﬁcally adapted to the problem of return prediction. Our method proceeds in three steps: 1) isolating a list of terms via predictive screening, 2) assigning prediction weights to these words via topic modeling, and 3) aggregating terms into an articlelevel predictive score via penalized likelihood. We derive theoretical guarantees on the accuracy of estimates from our model with minimal assumptions. In our empirical analysis, we study one of the most actively monitored streams of news articles in the ﬁnancial system—the Dow Jones Newswires—and show that our supervised text model excels at extracting return-predictive signals in this context. Information in newswires is assimilated into prices with an ineﬃcient delay that is broadly consistent with limits-to-arbitrage (i.e., more severe for smaller and more volatile ﬁrms) yet can be exploited in a real-time trading strategy with reasonable turnover and net of transaction costs.},
	language = {en},
	author = {Ke, Zheng Tracy and Kelly, Bryan and Xiu, Dacheng},
	year = {2021},
}

@article{divernois_stocktwits_2023,
	title = {{StockTwits} {Classiﬁed} {Sentiment} and {Stock} {Returns}},
	abstract = {We classify the sentiment of a large sample of StockTwits messages as bullish, bearish or neutral, and create a stock-aggregate daily sentiment polarity measure. Polarity is positively associated with contemporaneous stock returns. On average, polarity is not able to predict next-day stock returns. But when we condition on speciﬁc events, deﬁned as sudden peaks of message volume, polarity has predictive power on abnormal returns. Polarity-sorted portfolios illustrate the economic relevance of our sentiment measure.},
	language = {en},
	author = {Divernois, Marc-Aurele and Filipovic, Damir},
	year = {2023},
}

@article{blei_latent_2003,
	title = {Latent {Dirichlet} {Allocation}},
	abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
	language = {en},
	author = {Blei, David M},
	year = {2003},
}

@article{hansen_can_2023,
	title = {Can {ChatGPT} {Decipher} {Fedspeak}?},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4399406},
	doi = {10.2139/ssrn.4399406},
	abstract = {Abstract This paper examines the ability of large language models (LLMs) to decipher Fedspeak, the technical language used by the Federal Reserve to communicate on policy decisions. We evaluate the ability of the GPT-3.5 and GPT-4 models to correctly classify the policy stance of FOMC announcements relative to human assessment. We find that these models outperform traditional methods in classification accuracy and provide justifications akin to human rationale. Additionally, we show that the GPT-4 model can successfully perform the elaborate and non-trivial task of identifying macroeconomic shocks using the narrative approach of Romer and Romer (1989, 2023). Finally, we show preliminary evidence that market reactions to FOMC announcements have intensified following the introduction of the GPT-4 model.},
	language = {en},
	urldate = {2024-08-27},
	journal = {SSRN Electronic Journal},
	author = {Hansen, Anne Lundgaard and Kazinnik, Sophia},
	year = {2023},
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {https://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DOISource&SrcApp=WOS&KeyAID=10.1162%2Fneco.1997.9.8.1735&DestApp=DOI&SrcAppSID=EUW1ED0F842Fvh3przuas7IhGY70X&SrcJTitle=NEURAL+COMPUTATION&DestDOIRegistrantName=MIT+Press},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error now through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	language = {English},
	number = {8},
	urldate = {2024-08-26},
	journal = {NEURAL COMPUTATION},
	author = {Hochreiter, S. and Schmidhuber, J.},
	month = nov,
	year = {1997},
	note = {Num Pages: 46
Place: Cambridge
Publisher: Mit Press
Web of Science ID: WOS:A1997YA04500007},
	keywords = {DEPENDENCIES, RECURRENT NEURAL NETWORKS},
	pages = {1735--1780},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
	urldate = {2024-08-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Ł ukasz and Polosukhin, Illia},
	year = {2017},
}

@misc{amazon_web_services_what_nodate,
	title = {What are {Large} {Language} {Models}? - {LLM} {AI} {Explained} - {AWS}},
	shorttitle = {What are {Large} {Language} {Models}?},
	url = {https://aws.amazon.com/what-is/large-language-model/},
	abstract = {Learn what Large Language Models are and why LLMs are essential. Discover its benefits and how you can use it to create new content and ideas including text, conversations, images, video, and audio.},
	language = {en-US},
	urldate = {2024-08-26},
	journal = {Amazon Web Services, Inc.},
	author = {Amazon Web Services},
}

@article{greene_crisis_2020,
	title = {A {Crisis} of {Beliefs}: {Investor} {Psychology} and {Financial} {Fragility}, by {Nicola} {Gennaioli} and {Andrei} {Shleifer}. {Princeton}, {NJ}: {Princeton} {University} {Press}, 2018. 264 pp.},
	volume = {30},
	issn = {1052-150X, 2153-3326},
	shorttitle = {A {Crisis} of {Beliefs}},
	url = {https://www.cambridge.org/core/journals/business-ethics-quarterly/article/abs/crisis-of-beliefs-investor-psychology-and-financial-fragility-by-nicola-gennaioli-and-andrei-shleifer-princeton-nj-princeton-university-press-2018-264-pp/798037C98E29552B59799D4D8ED9AE5F},
	doi = {10.1017/beq.2020.35},
	abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS1052150X20000354/resource/name/firstPage-S1052150X20000354a.jpg},
	language = {en},
	number = {4},
	urldate = {2024-08-19},
	journal = {Business Ethics Quarterly},
	author = {Greene, Catherine},
	month = oct,
	year = {2020},
	note = {Publisher: Cambridge University Press},
	pages = {613--616},
}

@techreport{publications_monetary_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Monetary {Policy} and the {Management} of {Uncertainty}: {A} {Narrative} {Approach}},
	shorttitle = {Monetary {Policy} and the {Management} of {Uncertainty}},
	url = {https://papers.ssrn.com/abstract=3627721},
	abstract = {In this paper we explore how macroeconomic theory might be augmented, and the practice of monetary policy better understood, if approached through ideas from social and psychological science. A modern, inflation-targeting central bank faces ‘radical’ uncertainty both in understanding the economy and in knowing how best to communicate policy decisions to influence behaviour. We make use of narrative theory to explore these challenges, drawing on fieldwork with the Bank’s regional Agencies and conversations with staff and policy-makers. We find that the intelligence gathered from conversations with businesses is uniquely useful for both the analysis and communication of monetary policy. Such intelligence embodies knowledge about the plans which are making the future. It also provides insights into how economic agents understand the economy they are creating. These insights can help the Monetary Policy Committee to communicate its policy as a narrative the public understands and commits to. We propose further research to advance and test these ideas.},
	language = {en},
	number = {3627721},
	urldate = {2024-08-19},
	institution = {Social Science Research Network},
	author = {Publications, Bank of England and Tuckett, David and Holmes, Douglas and Pearson, Alice and Chaplin, Graeme},
	month = jun,
	year = {2020},
	doi = {10.2139/ssrn.3627721},
	keywords = {Monetary policy, central bank communication, economic knowledge, inflation-targeting, macroeconomic theory, narrative theory, uncertainty},
}

@article{nyman_news_2021,
	title = {News and narratives in financial systems: {Exploiting} big data for systemic risk assessment},
	volume = {127},
	issn = {0165-1889},
	shorttitle = {News and narratives in financial systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0165188921000543},
	doi = {10.1016/j.jedc.2021.104119},
	abstract = {This paper applies algorithmic analysis to financial market text-based data to assess how narratives and sentiment might drive financial system developments. We find changes in emotional content in narratives are highly correlated across data sources and show the formation (and subsequent collapse) of exuberance prior to the global financial crisis. Our metrics also have predictive power for other commonly used indicators of sentiment and appear to influence economic variables. A novel machine learning application also points towards increasing consensus around the strongly positive narrative prior to the crisis. Together, our metrics might help to warn about impending financial system distress.},
	urldate = {2024-08-19},
	journal = {Journal of Economic Dynamics and Control},
	author = {Nyman, Rickard and Kapadia, Sujit and Tuckett, David},
	month = jun,
	year = {2021},
	keywords = {Big data, Early warning indicators, Narratives, Sentiment, Systemic risk, Text mining, Uncertainty},
	pages = {104119},
}

@techreport{shiller_narrative_2017,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Narrative {Economics}},
	url = {https://papers.ssrn.com/abstract=2896857},
	abstract = {This address considers the epidemiology of narratives relevant to economic fluctuations. The human brain has always been highly tuned towards narratives, whether factual or not, to justify ongoing actions, even such basic actions as spending and investing. Stories motivate and connect activities to deeply felt values and needs. Narratives “go viral” and spread far, even worldwide, with economic impact. The 1920-21 Depression, the Great Depression of the 1930s, the so-called “Great Recession” of 2007-9 and the contentious political-economic situation of today, are considered as the results of the popular narratives of their respective times. Though these narratives are deeply human phenomena that are difficult to study in a scientific manner, quantitative analysis may help us gain a better understanding of these epidemics in the future.},
	language = {en},
	number = {2896857},
	urldate = {2024-08-19},
	institution = {Social Science Research Network},
	author = {Shiller, Robert J.},
	month = jan,
	year = {2017},
	doi = {10.2139/ssrn.2896857},
	keywords = {2008 Financial Crisis, Bubbles, Business Cycles, Depression of 1920, Economic Fluctuations, Epidemic, Great Depression, Kermack and McKendrick, Meme, Multipliers, Post-Truth, Profiteer, SIR Model, Stock Market Crash, Story},
}

@techreport{guilleminot_new_2014,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {A new financial stress indicator: properties and conditional asset price behavior},
	shorttitle = {A new financial stress indicator},
	url = {https://papers.ssrn.com/abstract=2317321},
	abstract = {The main goal of this paper is to introduce a new financial stress indicator, signaling regime transitions from stability to turbulence. This indicator is based on the combination of a wide range of market prices of risk, properly normalized to make them comparable across markets and time periods. After describing the construction and basic properties of the indicator, we discuss the conditional behavior of a basket of liquid assets. When the risk aversion signal breaches certain thresholds, risky assets dramatically correlate and their risk rewards deteriorate. Sharpe ratios decrease and drawdowns increase. Also, at the onset of chaotic phases, standard risk metrics fail to give an adequate representation of potential losses. These findings have significant implications for asset allocation and risk management purposes.},
	language = {en},
	number = {2317321},
	urldate = {2024-08-21},
	institution = {Social Science Research Network},
	author = {Guilleminot, Benoît and Ohana, Jean-Jacques and Ohana, Steve},
	month = jan,
	year = {2014},
	doi = {10.2139/ssrn.2317321},
	keywords = {Financial stress indicators, risk measures, risk premiums, systemic risk, tactical asset allocation},
}

@article{mackinlay_event_1997,
	title = {Event {Studies} in {Economics} and {Finance}},
	volume = {35},
	issn = {0022-0515},
	url = {https://www.jstor.org/stable/2729691},
	number = {1},
	urldate = {2024-08-21},
	journal = {Journal of Economic Literature},
	author = {MacKinlay, A. Craig},
	year = {1997},
	note = {Publisher: American Economic Association},
	pages = {13--39},
}

@article{manela_news_2017,
	title = {News implied volatility and disaster concerns},
	language = {en},
	journal = {Journal of Financial Economics},
	author = {Manela, Asaf},
	year = {2017},
}

@article{schmitt_non-stationarity_2013,
	title = {Non-stationarity in financial time series: {Generic} features and tail behavior},
	volume = {103},
	issn = {0295-5075},
	shorttitle = {Non-stationarity in financial time series},
	url = {https://dx.doi.org/10.1209/0295-5075/103/58003},
	doi = {10.1209/0295-5075/103/58003},
	abstract = {Financial markets are prominent examples for highly non-stationary systems. Sample averaged observables such as variances and correlation coefficients strongly depend on the time window in which they are evaluated. This implies severe limitations for approaches in the spirit of standard equilibrium statistical mechanics and thermodynamics. Nevertheless, we show that there are similar generic features which we uncover in the empirical multivariate return distributions for whole markets. We explain our findings by setting up a random matrix model.},
	language = {en},
	number = {5},
	urldate = {2024-08-19},
	journal = {Europhysics Letters},
	author = {Schmitt, Thilo A. and Chetalova, Desislava and Schäfer, Rudi and Guhr, Thomas},
	month = sep,
	year = {2013},
	note = {Publisher: EDP Sciences, IOP Publishing and Società Italiana di Fisica},
	pages = {58003},
}

@article{breitung_when_2013,
	title = {When bubbles burst: econometric tests based on structural breaks},
	volume = {54},
	issn = {0932-5026, 1613-9798},
	shorttitle = {When bubbles burst},
	url = {https://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DOISource&SrcApp=WOS&KeyAID=10.1007%2Fs00362-012-0497-3&DestApp=DOI&SrcAppSID=EUW1ED0BACJXetW1p5qxpkWBJycvM&SrcJTitle=STATISTICAL+PAPERS&DestDOIRegistrantName=Springer-Verlag},
	doi = {10.1007/s00362-012-0497-3},
	abstract = {Speculative bubbles have played an important role ever since in financial economics. During an ongoing bubble it is relevant for investors and policy-makers to know whether the bubble continues to grow or whether it is already collapsing. Prices are typically well approximated by a random walk in absence of bubbles, while periods of bubbles are characterised by explosive price paths. In this paper we first propose a conventional Chow-type testing procedure for a structural break from an explosive to a random walk regime. It is shown that under the null hypothesis of a mildly explosive process a suitably modified Chow-type statistic possesses a standard normal limiting distribution. Second, a monitoring procedure based on the CUSUM statistic is suggested. It timely indicates such a structural change. Asymptotic results are derived and small-sample properties are studied via Monte Carlo simulations. Finally, two empirical applications illustrate the merits and limitations of our suggested procedures.},
	language = {English},
	number = {4},
	urldate = {2024-08-19},
	journal = {STATISTICAL PAPERS},
	author = {Breitung, Joerg and Kruse, Robinson},
	month = nov,
	year = {2013},
	note = {Num Pages: 20
Place: New York
Publisher: Springer
Web of Science ID: WOS:000325476100002},
	keywords = {Mildly explosive processes, Monitoring, ROOT, Speculative bubbles, Structural breaks},
	pages = {911--930},
}

@article{huang_finbert_2023,
	title = {{FinBERT}: {A} {Large} {Language} {Model} for {Extracting} {Information} from {Financial} {Text}},
	volume = {40},
	issn = {1911-3846},
	shorttitle = {{FinBERT}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1911-3846.12832},
	doi = {10.1111/1911-3846.12832},
	abstract = {We develop FinBERT, a state-of-the-art large language model that adapts to the finance domain. We show that FinBERT incorporates finance knowledge and can better summarize contextual information in financial texts. Using a sample of researcher-labeled sentences from analyst reports, we document that FinBERT substantially outperforms the Loughran and McDonald dictionary and other machine learning algorithms, including naïve Bayes, support vector machine, random forest, convolutional neural network, and long short-term memory, in sentiment classification. Our results show that FinBERT excels in identifying the positive or negative sentiment of sentences that other algorithms mislabel as neutral, likely because it uses contextual information in financial text. We find that FinBERT's advantage over other algorithms, and Google's original bidirectional encoder representations from transformers model, is especially salient when the training sample size is small and in texts containing financial words not frequently used in general texts. FinBERT also outperforms other models in identifying discussions related to environment, social, and governance issues. Last, we show that other approaches underestimate the textual informativeness of earnings conference calls by at least 18\% compared to FinBERT. Our results have implications for academic researchers, investment professionals, and financial market regulators.},
	language = {en},
	number = {2},
	urldate = {2024-08-21},
	journal = {Contemporary Accounting Research},
	author = {Huang, Allen H. and Wang, Hui and Yang, Yi},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1911-3846.12832},
	keywords = {and governance (ESG), apprentissage automatique interprétable, apprentissage par transfert, apprentissage profond, classification des sentiments, deep learning, environment, environnement, grand modèle de langage, interpretable machine learning, large language model, sentiment classification, social, social et gouvernance (ESG), transfer learning},
	pages = {806--841},
}

@techreport{alain_understanding_2018,
	title = {Understanding intermediate layers using linear classifier probes},
	url = {http://arxiv.org/abs/1610.01644},
	abstract = {Neural network models have a reputation for being black boxes. We propose to monitor the features at every layer of a model and measure how suitable they are for classification. We use linear classifiers, which we refer to as "probes", trained entirely independently of the model itself. This helps us better understand the roles and dynamics of the intermediate layers. We demonstrate how this can be used to develop a better intuition about models and to diagnose potential problems. We apply this technique to the popular models Inception v3 and Resnet-50. Among other things, we observe experimentally that the linear separability of features increase monotonically along the depth of the model.},
	number = {arXiv:1610.01644},
	urldate = {2024-08-21},
	institution = {arXiv},
	author = {Alain, Guillaume and Bengio, Yoshua},
	month = nov,
	year = {2018},
	doi = {10.48550/arXiv.1610.01644},
	note = {arXiv:1610.01644 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{wolf_transformers_2020,
	address = {Online},
	title = {Transformers: {State}-of-the-{Art} {Natural} {Language} {Processing}},
	shorttitle = {Transformers},
	url = {https://aclanthology.org/2020.emnlp-demos.6},
	doi = {10.18653/v1/2020.emnlp-demos.6},
	abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.},
	urldate = {2024-08-21},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Remi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander},
	editor = {Liu, Qun and Schlangen, David},
	month = oct,
	year = {2020},
	pages = {38--45},
}

@article{shapiro_measuring_2022,
	title = {Measuring news sentiment✩},
	abstract = {This paper demonstrates state-of-the-art text sentiment analysis tools while developing a new time-series measure of economic sentiment derived from economic and financial newspaper articles from January 1980 to April 2015. We compare the predictive accuracy of a large set of sentiment analysis models using a sample of articles that have been rated by humans on a positivity/negativity scale. The results highlight the gains from combining existing lexicons and from accounting for negation. We also generate our own sentiment-scoring model, which includes a new lexicon built specifically to capture the sentiment in economic news articles. This model is shown to have better predictive accuracy than existing ‘‘off-the-shelf’’ models. Lastly, we provide two applications to the economic research on sentiment. First, we show that daily news sentiment is predictive of movements of survey-based measures of consumer sentiment. Second, motivated by Barsky and Sims (2012), we estimate the impulse responses of macroeconomic variables to sentiment shocks, finding that positive sentiment shocks increase consumption, output, and interest rates and dampen inflation.},
	language = {en},
	journal = {Journal of Econometrics},
	author = {Shapiro, Adam Hale and Sudhof, Moritz and Wilson, Daniel J},
	year = {2022},
}

@techreport{dong_fnspid_2024,
	title = {{FNSPID}: {A} {Comprehensive} {Financial} {News} {Dataset} in {Time} {Series}},
	shorttitle = {{FNSPID}},
	url = {http://arxiv.org/abs/2402.06698},
	abstract = {Financial market predictions utilize historical data to anticipate future stock prices and market trends. Traditionally, these predictions have focused on the statistical analysis of quantitative factors, such as stock prices, trading volumes, inflation rates, and changes in industrial production. Recent advancements in large language models motivate the integrated financial analysis of both sentiment data, particularly market news, and numerical factors. Nonetheless, this methodology frequently encounters constraints due to the paucity of extensive datasets that amalgamate both quantitative and qualitative sentiment analyses. To address this challenge, we introduce a large-scale financial dataset, namely, Financial News and Stock Price Integration Dataset (FNSPID). It comprises 29.7 million stock prices and 15.7 million time-aligned financial news records for 4,775 S\&P500 companies, covering the period from 1999 to 2023, sourced from 4 stock market news websites. We demonstrate that FNSPID excels existing stock market datasets in scale and diversity while uniquely incorporating sentiment information. Through financial analysis experiments on FNSPID, we propose: (1) the dataset's size and quality significantly boost market prediction accuracy; (2) adding sentiment scores modestly enhances performance on the transformer-based model; (3) a reproducible procedure that can update the dataset. Completed work, code, documentation, and examples are available at github.com/Zdong104/FNSPID. FNSPID offers unprecedented opportunities for the financial research community to advance predictive modeling and analysis.},
	number = {arXiv:2402.06698},
	urldate = {2024-08-20},
	institution = {arXiv},
	author = {Dong, Zihan and Fan, Xinyu and Peng, Zhiyuan},
	month = feb,
	year = {2024},
	doi = {10.48550/arXiv.2402.06698},
	note = {arXiv:2402.06698 [q-fin]
type: article},
	keywords = {Quantitative Finance - Statistical Finance},
}

@article{kraus_decision_2017,
	title = {Decision support from financial disclosures with deep neural networks and transfer learning},
	volume = {104},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923617301793},
	doi = {10.1016/j.dss.2017.10.001},
	abstract = {Company disclosures greatly aid in the process of ﬁnancial decision-making; therefore, they are consulted by ﬁnancial investors and automated traders before exercising ownership in stocks. While humans are usually able to correctly interpret the content, the same is rarely true of computerized decision support systems, which struggle with the complexity and ambiguity of natural language. A possible remedy is represented by deep learning, which overcomes several shortcomings of traditional methods of text mining. For instance, recurrent neural networks, such as long short-term memories, employ hierarchical structures, together with a large number of hidden layers, to automatically extract features from ordered sequences of words and capture highly non-linear relationships such as context-dependent meanings. However, deep learning has only recently started to receive traction, possibly because its performance is largely untested. Hence, this paper studies the use of deep neural networks for ﬁnancial decision support. We additionally experiment with transfer learning, in which we pre-train the network on a different corpus with a length of 139.1 million words. Our results reveal a higher directional accuracy as compared to traditional machine learning when predicting stock price movements in response to ﬁnancial disclosures. Our work thereby helps to highlight the business value of deep learning and provides recommendations to practitioners and executives.},
	language = {en},
	urldate = {2024-08-20},
	journal = {Decision Support Systems},
	author = {Kraus, Mathias and Feuerriegel, Stefan},
	month = dec,
	year = {2017},
	pages = {38--48},
}

@article{loughran_when_2011,
	title = {When {Is} a {Liability} {Not} a {Liability}? {Textual} {Analysis}, {Dictionaries}, and 10‐{Ks}},
	volume = {66},
	issn = {0022-1082, 1540-6261},
	shorttitle = {When {Is} a {Liability} {Not} a {Liability}?},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1540-6261.2010.01625.x},
	doi = {10.1111/j.1540-6261.2010.01625.x},
	abstract = {Previous research uses negative word counts to measure the tone of a text. We show that word lists developed for other disciplines misclassify common words in ﬁnancial text. In a large sample of 10-Ks during 1994 to 2008, almost three-fourths of the words identiﬁed as negative by the widely used Harvard Dictionary are words typically not considered negative in ﬁnancial contexts. We develop an alternative negative word list, along with ﬁve other word lists, that better reﬂect tone in ﬁnancial text. We link the word lists to 10-K ﬁling returns, trading volume, return volatility, fraud, material weakness, and unexpected earnings.},
	language = {en},
	number = {1},
	urldate = {2024-08-20},
	journal = {The Journal of Finance},
	author = {Loughran, Tim and Mcdonald, Bill},
	month = feb,
	year = {2011},
	pages = {35--65},
}

@article{malo_good_2014,
	title = {Good debt or bad debt: {Detecting} semantic orientations in economic texts},
	volume = {65},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {2330-1635, 2330-1643},
	shorttitle = {Good debt or bad debt},
	url = {https://asistdl.onlinelibrary.wiley.com/doi/10.1002/asi.23062},
	doi = {10.1002/asi.23062},
	abstract = {The use of robo‐readers to analyze news texts is an emerging technology trend in computational finance. Recent research has developed sophisticated financial polarity lexicons for investigating how financial sentiments relate to future company performance. However, based on experience from fields that commonly analyze sentiment, it is well known that the overall semantic orientation of a sentence may differ from that of individual words. This article investigates how semantic orientations can be better detected in financial and economic news by accommodating the overall phrase‐structure information and domain‐specific use of language. Our three main contributions are the following: (a) a human‐annotated finance phrase bank that can be used for training and evaluating alternative models; (b) a technique to enhance financial lexicons with attributes that help to identify expected direction of events that affect sentiment; and (c) a linearized phrase‐structure model for detecting contextual semantic orientations in economic texts. The relevance of the newly added lexicon features and the benefit of using the proposed learning algorithm are demonstrated in a comparative study against general sentiment models as well as the popular word frequency models used in recent financial studies. The proposed framework is parsimonious and avoids the explosion in feature space caused by the use of conventional n‐gram features.},
	language = {en},
	number = {4},
	urldate = {2024-08-20},
	journal = {Journal of the Association for Information Science and Technology},
	author = {Malo, Pekka and Sinha, Ankur and Korhonen, Pekka and Wallenius, Jyrki and Takala, Pyry},
	month = apr,
	year = {2014},
	pages = {782--796},
}

@article{kirtac_sentiment_2024,
	title = {Sentiment trading with large language models},
	volume = {62},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612324002575},
	doi = {10.1016/j.frl.2024.105227},
	abstract = {We analyse the performance of the large language models (LLMs) OPT, BERT, and FinBERT, alongside the traditional Loughran-McDonald dictionary, in the sentiment analysis of 965,375 U.S. financial news articles from 2010 to 2023. Our findings reveal that the GPT-3-based OPT model significantly outperforms the others, predicting stock market returns with an accuracy of 74.4\%. A long-short strategy based on OPT, accounting for 10 basis points (bps) in transaction costs, yields an exceptional Sharpe ratio of 3.05. From August 2021 to July 2023, this strategy produces an impressive 355\% gain, outperforming other strategies and traditional market portfolios. This underscores the transformative potential of LLMs in financial market prediction and portfolio management and the necessity of employing sophisticated language models to develop effective investment strategies based on news sentiment.},
	language = {en},
	urldate = {2024-08-20},
	journal = {Finance Research Letters},
	author = {Kirtac, Kemal and Germano, Guido},
	month = apr,
	year = {2024},
	pages = {105227},
}

@techreport{araci_finbert_2019,
	title = {{FinBERT}: {Financial} {Sentiment} {Analysis} with {Pre}-trained {Language} {Models}},
	shorttitle = {{FinBERT}},
	url = {http://arxiv.org/abs/1908.10063},
	abstract = {Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain. General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora. We introduce FinBERT, a language model based on BERT, to tackle NLP tasks in the financial domain. Our results show improvement in every measured metric on current state-of-the-art results for two financial sentiment analysis datasets. We find that even with a smaller training set and fine-tuning only a part of the model, FinBERT outperforms state-of-the-art machine learning methods.},
	number = {arXiv:1908.10063},
	urldate = {2024-08-20},
	institution = {arXiv},
	author = {Araci, Dogu},
	month = aug,
	year = {2019},
	doi = {10.48550/arXiv.1908.10063},
	note = {arXiv:1908.10063 [cs]
type: article},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{sohangir_big_2018,
	title = {Big {Data}: {Deep} {Learning} for financial sentiment analysis},
	volume = {5},
	issn = {2196-1115},
	shorttitle = {Big {Data}},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-017-0111-6},
	doi = {10.1186/s40537-017-0111-6},
	abstract = {Deep Learning and Big Data analytics are two focal points of data science. Deep Learning models have achieved remarkable results in speech recognition and computer vision in recent years. Big Data is important for organizations that need to collect a huge amount of data like a social network and one of the greatest assets to use Deep Learning is analyzing a massive amount of data (Big Data). This advantage makes Deep Learning as a valuable tool for Big Data. Deep Learning can be used to extract incredible information that buried in a Big Data. The modern stock market is an example of these social networks. They are a popular place to increase wealth and generate income, but the fundamental problem of when to buy or sell shares, or which stocks to buy has not been solved. It is very common among investors to have professional financial advisors, but what is the best resource to support the decisions these people make? Investment banks such as Goldman Sachs, Lehman Brothers, and Salomon Brothers dominated the world of financial advice for more than a decade. However, via the popularity of the Internet and financial social networks such as StockTwits and SeekingAlpha, investors around the world have new opportunity to gather and share their experiences. Individual experts can predict the movement of the stock market in financial social networks with the reasonable accuracy, but what is the sentiment of a mass group of these expert authors towards various stocks? In this paper, we seek to determine if Deep Learning models can be adapted to improve the performance of sentiment analysis for StockTwits. We applied several neural network models such as long short-term memory, doc2vec, and convolutional neural networks, to stock market opinions posted in StockTwits. Our results show that Deep Learning model can be used effectively for financial sentiment analysis and a convolutional neural network is the best model to predict sentiment of authors in StockTwits dataset.},
	language = {en},
	number = {1},
	urldate = {2024-08-20},
	journal = {Journal of Big Data},
	author = {Sohangir, Sahar and Wang, Dingding and Pomeranets, Anna and Khoshgoftaar, Taghi M.},
	month = dec,
	year = {2018},
	pages = {3},
}

@article{qorib_covid-19_2023,
	title = {Covid-19 vaccine hesitancy: {Text} mining, sentiment analysis and machine learning on {COVID}-19 vaccination {Twitter} dataset},
	volume = {212},
	issn = {0957-4174},
	shorttitle = {Covid-19 vaccine hesitancy},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417422017407},
	doi = {10.1016/j.eswa.2022.118715},
	abstract = {In 2019 there was an outbreak of coronavirus pandemic also known as COVID-19. Many scientists believe that the pandemic originated from Wuhan, China, before spreading to other parts of the globe. To reduce the spread of the disease, decision makers encouraged measures such as hand washing, face masking, and social distancing. In early 2021, some countries including the United States began administering COVID-19 vaccines. Vaccination brought a relief to the public; it also generated a lot of debates from anti-vaccine and pro-vaccine groups. The controversy and debate surrounding COVID-19 vaccine influenced the decision of several people in either to accept or reject vaccination. Because of data limitations, social media data, collected through live streaming public tweets using an Application Programming Interface (API) search, is considered a viable and reliable resource to study the opinion of the public on Covid-19 vaccine hesitancy. Thus, this study examines 3 sentiment computation methods (Azure Machine Learning, VADER, and TextBlob) to analyze COVID-19 vaccine hesitancy. Five learning algorithms (Random Forest, Logistics Regression, Decision Tree, LinearSVC, and Naïve Bayes) with different combination of three vectorization methods (Doc2Vec, CountVectorizer, and TF-IDF) were deployed. Vocabulary normalization was threefold; potter stemming, lemmatization, and potter stemming with lemmatization. For each vocabulary normalization strategy, we designed, developed, and evaluated 42 models. The study shows that Covid-19 vaccine hesitancy slowly decreases over time; suggesting that the public gradually feels warm and optimistic about COVID-19 vaccination. Moreover, combining potter stemming and lemmatization increased model performances. Finally, the result of our experiment shows that TextBlob + TF-IDF + LinearSVC has the best performance in classifying public sentiment into positive, neutral, or negative with an accuracy, precision, recall and F1 score of 0.96752, 0.96921, 0.92807 and 0.94702 respectively. It means that the best performance was achieved when using TextBlob sentiment score, with TF-IDF vectorization and LinearSVC classification model. We also found out that combining two vectorizations (CountVectorizer and TF-IDF) decreases model accuracy.},
	urldate = {2024-08-20},
	journal = {Expert Systems with Applications},
	author = {Qorib, Miftahul and Oladunni, Timothy and Denis, Max and Ososanya, Esther and Cotae, Paul},
	month = feb,
	year = {2023},
	keywords = {Covid-19, Machine Learning, Sentiment Analysis, Twitter, Vaccine Hesitancy},
	pages = {118715},
}

@article{agaian_financial_2017,
	title = {Financial {Sentiment} {Analysis} {Using} {Machine} {Learning} {Techniques}},
	abstract = {The rise of web content has presented a great opportunity to extract indicators of investor moods directly from news and social media. Gauging this sentiment or general prevailing attitude of investors may simplify the analysis of large, unstructured textual datasets and help anticipate price developments in the market. There are several challenges in developing a scalable and effective framework for financial sentiment analysis, including: identifying useful information content, representing unstructured text in a structured format under a scalable framework, and quantifying this structured sentiment data. To address these questions, a corpus of positive and negative financial news is introduced. Various supervised machine learning algorithms are applied to gage article sentiment and empirically evaluate the performance of the proposed framework on introduced media content.},
	language = {en},
	author = {Agaian, Sarkis and Kolm, Petter},
	year = {2017},
}

@techreport{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	number = {arXiv:1907.11692},
	urldate = {2024-08-20},
	institution = {arXiv},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	doi = {10.48550/arXiv.1907.11692},
	note = {arXiv:1907.11692 [cs]
type: article},
	keywords = {Computer Science - Computation and Language},
}

@article{loughran_textual_2016,
	title = {Textual {Analysis} in {Accounting} and {Finance}: {A} {Survey}},
	volume = {54},
	issn = {0021-8456, 1475-679X},
	shorttitle = {Textual {Analysis} in {Accounting} and {Finance}},
	url = {https://www.webofscience.com/api/gateway?GWVersion=2&SrcAuth=DOISource&SrcApp=WOS&KeyAID=10.1111%2F1475-679X.12123&DestApp=DOI&SrcAppSID=EUW1ED0BACJXetW1p5qxpkWBJycvM&SrcJTitle=JOURNAL+OF+ACCOUNTING+RESEARCH&DestDOIRegistrantName=Wiley+%28Blackwell+Publishing%29},
	doi = {10.1111/1475-679X.12123},
	abstract = {Relative to quantitative methods traditionally used in accounting and finance, textual analysis is substantially less precise. Thus, understanding the art is of equal importance to understanding the science. In this survey, we describe the nuances of the method and, as users of textual analysis, some of the tripwires in implementation. We also review the contemporary textual analysis literature and highlight areas of future research.},
	language = {English},
	number = {4},
	urldate = {2024-08-19},
	journal = {JOURNAL OF ACCOUNTING RESEARCH},
	author = {Loughran, Tim and Mcdonald, Bill},
	month = sep,
	year = {2016},
	note = {Num Pages: 44
Place: Hoboken
Publisher: Wiley
Web of Science ID: WOS:000380964000007},
	keywords = {ANNUAL-REPORT READABILITY, CONFERENCE CALLS, CURRENT EARNINGS, DISCLOSURE, INFORMATION-CONTENT, MEDIA SLANT, Naive Bayes, PRESS RELEASES, SENTIMENT, TONE, VOLATILITY, Zipf's law, bag of words, cosine similarity, readability, sentiment analysis, textual analysis, word lists},
	pages = {1187--1230},
}

@inproceedings{pui_cheong_fung_stock_2003,
	title = {Stock prediction: {Integrating} text mining approach using real-time news},
	shorttitle = {Stock prediction},
	url = {https://ieeexplore.ieee.org/document/1196287},
	doi = {10.1109/CIFER.2003.1196287},
	abstract = {Mining textual documents and time series concurrently, such as predicting the movements of stock prices based on news articles, is an emerging topic in data mining society nowadays. Previous research has already suggested that the relationship between news articles and stock prices do exist. However, all of the existing approaches are concerning in mining single time series only. The interrelationships among different stocks are not well-addressed. Mining multiple time series concurrently is not only more informative but also far more challenging. Research in such a direction is lacking. In this paper, we try to explore such an opportunity and propose a systematic framework for mining multiple time series based on Efficient Market Hypothesis.},
	urldate = {2024-08-19},
	booktitle = {2003 {IEEE} {International} {Conference} on {Computational} {Intelligence} for {Financial} {Engineering}, 2003. {Proceedings}.},
	author = {Pui Cheong Fung, G. and Xu Yu, J. and Lam, Wai},
	month = mar,
	year = {2003},
	keywords = {Broadcasting, Data engineering, Data mining, Fluctuations, Frequency, Humans, Research and development management, Stock markets, Systems engineering and theory, Text mining},
	pages = {395--402},
}

@article{carta_event_2021,
	title = {Event {Detection} in {Finance} {Using} {Hierarchical} {Clustering} {Algorithms} on {News} and {Tweets}},
	volume = {7},
	doi = {10.7717/peerj-cs.438},
	abstract = {In the current age of overwhelming information and massive production of textual data on the Web, Event Detection has become an increasingly important task in various application domains. Several research branches have been developed to tackle the problem from different perspectives, including Natural Language Processing and Big Data analysis, with the goal of providing valuable resources to support decision-making in a wide variety of fields. In this paper, we propose a real-time domain-specific clustering-based event-detection approach that integrates textual information coming, on one hand, from traditional newswires and, on the other hand, from microblogging platforms. The goal of the implemented pipeline is twofold: (i) providing insights to the user about the relevant events that are reported in the press on a daily basis; (ii) alerting the user about potentially important and impactful events, referred to as hot events, for some specific tasks or domains of interest. The algorithm identifies clusters of related news stories published by globally renowned press sources, which guarantee authoritative, noise-free information about current affairs; subsequently, the content extracted from microblogs is associated to the clusters in order to gain an assessment of the relevance of the event in the public opinion. To identify the events of a day d, the algorithm dynamically builds a lexicon by looking at news articles and stock data of previous days up to d − 1. Although the approach can be extended to a variety of domains (e.g. politics, economy, sports), we hereby present a specific implementation in the financial sector. We validated our solution through a qualitative and quantitative evaluation, performed on the Dow Jones' Data, News and Analytics dataset, on a stream of messages extracted from the microblogging platform Stocktwits, and on the Standard \& Poor's 500 index time-series. The experiments demonstrate the effectiveness of our proposal in extracting meaningful information from real-world events and in spotting hot events in the financial sphere. An added value of the evaluation is given by the visual inspection of a selected number of significant real-world events, starting from the Brexit Referendum and reaching until the recent outbreak of the Covid-19 pandemic in early 2020.},
	journal = {PeerJ Computer Science},
	author = {Carta, Salvatore and Consoli, Sergio and Piras, Luca and Podda, Alessandro and Reforgiato Recupero, Diego},
	month = may,
	year = {2021},
}

@article{wang_fuzzy_2023,
	title = {Fuzzy inference-based {LSTM} for long-term time series prediction},
	volume = {13},
	copyright = {2023 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-47812-3},
	doi = {10.1038/s41598-023-47812-3},
	abstract = {Long short-term memory (LSTM) based time series forecasting methods suffer from multiple limitations, such as accumulated error, diminishing temporal correlation, and lacking interpretability, which compromises the prediction performance. To overcome these shortcomings, a fuzzy inference-based LSTM with the embedding of a fuzzy system is proposed to enhance the accuracy and interpretability of LSTM for long-term time series prediction. Firstly, a fast and complete fuzzy rule construction method based on Wang–Mendel (WM) is proposed, which can enhance the computational efficiency and completeness of the WM model by fuzzy rules simplification and complement strategies. Then, the fuzzy prediction model is constructed to capture the fuzzy logic in data. Finally, the fuzzy inference-based LSTM is proposed by integrating the fuzzy prediction fusion, the strengthening memory layer, and the parameter segmentation sharing strategy into the LSTM network. Fuzzy prediction fusion increases the network reasoning capability and interpretability, the strengthening memory layer strengthens the long-term memory and alleviates the gradient dispersion problem, and the parameter segmentation sharing strategy balances processing efficiency and architecture discrimination. Experiments on publicly available time series demonstrate that the proposed method can achieve better performance than existing models for long-term time series prediction.},
	language = {en},
	number = {1},
	urldate = {2024-08-14},
	journal = {Scientific Reports},
	author = {Wang, Weina and Shao, Jiapeng and Jumahong, Huxidan},
	month = nov,
	year = {2023},
	note = {Publisher: Nature Publishing Group},
	keywords = {Energy science and technology, Environmental sciences, Mathematics and computing},
	pages = {20359},
}

@article{fischer_deep_2018,
	title = {Deep learning with long short-term memory networks for financial market predictions},
	volume = {270},
	issn = {03772217},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377221717310652},
	doi = {10.1016/j.ejor.2017.11.054},
	language = {en},
	number = {2},
	urldate = {2024-08-15},
	journal = {European Journal of Operational Research},
	author = {Fischer, Thomas and Krauss, Christopher},
	month = oct,
	year = {2018},
	pages = {654--669},
}

@article{bollen_twitter_2011,
	title = {Twitter mood predicts the stock market},
	volume = {2},
	issn = {18777503},
	url = {http://arxiv.org/abs/1010.3003},
	doi = {10.1016/j.jocs.2010.12.007},
	abstract = {Behavioral economics tells us that emotions can profoundly affect individual behavior and decision-making. Does this also apply to societies at large, i.e. can societies experience mood states that affect their collective decision making? By extension is the public mood correlated or even predictive of economic indicators? Here we investigate whether measurements of collective mood states derived from large-scale Twitter feeds are correlated to the value of the Dow Jones Industrial Average (DJIA) over time. We analyze the text content of daily Twitter feeds by two mood tracking tools, namely OpinionFinder that measures positive vs. negative mood and Google-Proﬁle of Mood States (GPOMS) that measures mood in terms of 6 dimensions (Calm, Alert, Sure, Vital, Kind, and Happy). We cross-validate the resulting mood time series by comparing their ability to detect the public’s response to the presidential election and Thanksgiving day in 2008. A Granger causality analysis and a Self-Organizing Fuzzy Neural Network are then used to investigate the hypothesis that public mood states, as measured by the OpinionFinder and GPOMS mood time series, are predictive of changes in DJIA closing values. Our results indicate that the accuracy of DJIA predictions can be signiﬁcantly improved by the inclusion of speciﬁc public mood dimensions but not others. We ﬁnd an accuracy of 87.6\% in predicting the daily up and down changes in the closing values of the DJIA and a reduction of the Mean Average Percentage Error by more than 6\%.},
	language = {en},
	number = {1},
	urldate = {2024-08-14},
	journal = {Journal of Computational Science},
	author = {Bollen, Johan and Mao, Huina and Zeng, Xiao-Jun},
	month = mar,
	year = {2011},
	note = {arXiv:1010.3003 [physics]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Social and Information Networks, Physics - Physics and Society},
	pages = {1--8},
}

@article{lefort_mixing_2024,
	title = {Mixing {Financial} {Stress} with {GPT}-4 {News} {Sentiment} {Analysis} for {Optimal} {Risk}-{On}/{Risk}-{Off} {Decisions}},
	abstract = {This paper introduces a new risk-on risk-off strategy for the stock market, which combines a financial stress indicator with a sentiment analysis done by ChatGPT reading and interpreting Bloomberg daily market summaries. Forecasts of market stress derived from volatility and credit spreads are enhanced when combined with the financial news sentiment derived from GPT4. As a result, the strategy shows improved performance, evidenced by higher Sharpe ratio and reduced maximum drawdowns. The improved performance is consistent across the NASDAQ, the S\&P 500 and the six major equity markets, indicating that the method generalizes across equities markets.},
	language = {en},
	author = {Lefort, Baptiste and Benhamou, Eric and Ohana, Jean-Jacques and Saltiel, David and Guez, Beatrice and Jacquot, Thomas},
	year = {2024},
}

@article{kumbure_machine_2022,
	title = {Machine learning techniques and data for stock market forecasting: {A} literature review},
	volume = {197},
	issn = {09574174},
	shorttitle = {Machine learning techniques and data for stock market forecasting},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417422001452},
	doi = {10.1016/j.eswa.2022.116659},
	abstract = {In this literature review, we investigate machine learning techniques that are applied for stock market prediction. A focus area in this literature review is the stock markets investigated in the literature as well as the types of variables used as input in the machine learning techniques used for predicting these markets. We examined 138 journal articles published between 2000 and 2019. The main contributions of this review are: (1) an extensive examination of the data, in particular, the markets and stock indices covered in the predictions, as well as the 2173 unique variables used for stock market predictions, including technical indicators, macroeconomic variables, and fundamental indicators, and (2) an in-depth review of the machine learning techniques and their variants deployed for the predictions. In addition, we provide a bibliometric analysis of these journal articles, highlighting the most influential works and articles.},
	language = {en},
	urldate = {2024-08-13},
	journal = {Expert Systems with Applications},
	author = {Kumbure, Mahinda Mailagaha and Lohrmann, Christoph and Luukka, Pasi and Porras, Jari},
	month = jul,
	year = {2022},
	pages = {116659},
}

@article{mokhtari_effectiveness_2021,
	title = {Effectiveness of {Artificial} {Intelligence} in {Stock} {Market} {Prediction} based on {Machine} {Learning}},
	volume = {183},
	issn = {09758887},
	url = {http://www.ijcaonline.org/archives/volume183/number7/mokhtari-2021-ijca-921347.pdf},
	doi = {10.5120/ijca2021921347},
	abstract = {This paper tries to address the problem of stock market prediction leveraging artificial intelligence (AI) strategies. The stock market prediction can be modeled based on two principal analyses called technical and fundamental. In the technical analysis approach, the regression machine learning (ML) algorithms are employed to predict the stock price trend at the end of a business day based on the historical price data. In contrast, in the fundamental analysis, the classification ML algorithms are applied to classify the public sentiment based on news and social media. In the technical analysis, the historical price data is exploited from Yahoo Finance, and in fundamental analysis, public tweets on Twitter associated with the stock market are investigated to assess the impact of sentiments on the stock market’s forecast. The results show a median performance, implying that with the current technology of AI, it is too soon to claim AI can beat the stock markets.},
	language = {en},
	number = {7},
	urldate = {2024-08-13},
	journal = {International Journal of Computer Applications},
	author = {Mokhtari, Sohrab and Yen, Kang K. and Liu, Jin},
	month = jun,
	year = {2021},
	pages = {1--8},
}

@article{copyright_how_2024,
	title = {How can we use {ChatGPT} better: {A} research of {API}-{Enhanced} {ChatGPT} in stock prediction},
	abstract = {In this study, we propose an API-enhanced ChatGPT structure that incorporates stock price and news data to improve stock price movement predictions. By integrating external data sources and prompt engineering techniques, our approach demonstrates a significant improvement in predictive performance compared to using only stock price data. The inclusion of news data alongside stock prices results in an approximately 10\% increase in accuracy and F1 scores, as well as a 20\% improvement in risk-adjusted returns, as measured by Sharpe ratios and information ratios. Our findings highlight the potential of leveraging conversational AI and large language models for stock market analysis, while also identifying areas for further research and optimization, such as addressing stock-specific challenges and developing cost-effective strategies for implementation. This study contributes to the limited body of literature on the application of large language models in finance and paves the way for future research in enhancing the capabilities of AI-driven investment decision-making tools.},
	language = {en},
	author = {Copyright, Qichang Zheng},
	year = {2024},
}
