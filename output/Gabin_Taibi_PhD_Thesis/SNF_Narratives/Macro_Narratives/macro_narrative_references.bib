
@article{rogot_dimensionality_2023,
	title = {Dimensionality {Reduction} {Techniques} in {Macroeconomic} {Analysis}},
	abstract = {Over the past several decades, rapid innovation in data collection methods and technology has led to the development of dimensionality reduction techniques when dealing with a large number of predictors and time series observations. Especially relevant to the ﬁeld of economics, many macroeconomic indicators rely on processing vast sets of data, often dealing with variables of diﬀerent frequencies. Broadly, monetary policy is inﬂuenced by real-time evaluations of current and future economic conditions, meaning that lags in releases produce incomplete datasets. This paper closely examines the development and applications of two popular dimensionality reduction techniques: Principal Component Analysis (PCA) and Dynamic Factor Analysis (DFA). We give PCA a rigorous mathematical treatment to prove that the set of principal directions of a centered dataset is equivalent to the set of orthonormal eigenbases of the covariance matrix. The paper concludes with the construction of a Nowcasting model for United States Gross Domestic Product using data from Haver Analytics.},
	language = {en},
	author = {Rogot, Abigail},
	year = {2023},
}

@article{bruno_integrating_2024,
	title = {Integrating word embedding and topic modeling for sentiment analysis: {A} case study on the social mood on economy},
	volume = {40},
	issn = {1874-7655},
	shorttitle = {Integrating word embedding and topic modeling for sentiment analysis},
	url = {https://doi.org/10.3233/SJI-240017},
	doi = {10.3233/SJI-240017},
	abstract = {In recent years, textual analysis and embedding spaces have become essential and complementary tools for sentiment analysis in National Statistics Institutes’ research, owing to their ability to summarize discussed topics effectively. Istat has developed an innovative tool, wordembox, which allows external users to explore the outputs of popular word embedding algorithms, such as Word2Vec and FastText. This tool enriches the analysis with a novel graph functionality, enabling users to discover clusters of words and facilitating implicit topic modeling.This article focuses on Social Mood on Economy (SME) posts over a period in which the index recorded a strong downward trend: the first month of the Russia-Ukraine conflict at the beginning of 2022. We compare findings from wordembox with standard topic modeling techniques, including Bayesian Latent Dirichlet Allocation (LDA), Top2Vec, and BERTopic, recent methods that extract clusters from word embedding spaces. These techniques show coherent results, and their combined use in textual analysis may create a synergy that enhances the informative content of synthetic indexes such as ‘Social Mood on Economy Index (SMEI)’.},
	language = {EN},
	number = {3},
	urldate = {2025-05-14},
	journal = {Statistical Journal of the IAOS},
	author = {Bruno, Mauro and Catanese, Elena and De Cubellis, Massimo},
	month = aug,
	year = {2024},
	note = {Publisher: SAGE Publications},
	pages = {535--548},
}

@inproceedings{pei_dynamic_2025,
	title = {Dynamic {Graph} {Representation} with {Contrastive} {Learning} for {Financial} {Market} {Prediction}: {Integrating} {Temporal} {Evolution} and {Static} {Relations}},
	shorttitle = {Dynamic {Graph} {Representation} with {Contrastive} {Learning} for {Financial} {Market} {Prediction}},
	url = {http://arxiv.org/abs/2412.04034},
	doi = {10.5220/0013154700003890},
	abstract = {Temporal Graph Learning (TGL) is crucial for capturing the evolving nature of stock markets. Traditional methods often ignore the interplay between dynamic temporal changes and static relational structures between stocks. To address this issue, we propose the Dynamic Graph Representation with Contrastive Learning (DGRCL) framework, which integrates dynamic and static graph relations to improve the accuracy of stock trend prediction. Our framework introduces two key components: the Embedding Enhancement (EE) module and the Contrastive Constrained Training (CCT) module. The EE module focuses on dynamically capturing the temporal evolution of stock data, while the CCT module enforces static constraints based on stock relations, refined within contrastive learning. This dual-relation approach allows for a more comprehensive understanding of stock market dynamics. Our experiments on two major U.S. stock market datasets, NASDAQ and NYSE, demonstrate that DGRCL significantly outperforms state-of-the-art TGL baselines. Ablation studies indicate the importance of both modules. Overall, DGRCL not only enhances prediction ability but also provides a robust framework for integrating temporal and relational data in dynamic graphs. Code and data are available for public access.},
	urldate = {2025-05-09},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Agents} and {Artificial} {Intelligence}},
	author = {Pei, Yunhua and Zheng, Jin and Cartlidge, John},
	year = {2025},
	note = {arXiv:2412.04034 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Quantitative Finance - Computational Finance},
	pages = {298--309},
}

@article{huang_less_2023,
	title = {Less {Is} {More}: {Volatility} {Forecasting} with {Contrastive} {Representation} {Learning} ({Student} {Abstract})},
	volume = {37},
	copyright = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {Less {Is} {More}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26977},
	doi = {10.1609/aaai.v37i13.26977},
	abstract = {Earnings conference calls are indicative information events for volatility forecasting, which is essential for financial risk management and asset pricing. Although recent volatility forecasting models have explored the textual content of conference calls for prediction, they suffer from modeling the long-text and representing the risk-relevant information. This work proposes to identify key sentences for robust and interpretable transcript representation learning based on the cognitive theory. Specifically, we introduce TextRank to find key sentences and leverage attention mechanism to screen out the candidates by modeling the semantic correlations. Upon on the structural information of earning conference calls, we propose a structure-based contrastive learning method to facilitate the effective transcript representation. Empirical results on the benchmark dataset demonstrate the superiority of our model over competitive baselines in volatility forecasting.},
	language = {en},
	number = {13},
	urldate = {2025-05-09},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Huang, Yanlong and Tai, Wenxin and Zhong, Ting and Zhang, Kunpeng},
	year = {2023},
	note = {Number: 13},
	keywords = {Earnings Call Transcript},
	pages = {16234--16235},
}

@article{vinden_contrasim_2024,
	title = {{ContraSim}: {Contrastive} {Similarity} {Space} {Learning} for {Financial} {Market} {Predictions}},
	shorttitle = {{ContraSim}},
	url = {https://openreview.net/forum?id=GfuJR76Sfo},
	abstract = {We introduce the Contrastive Similarity Space Embedding Algorithm (ContraSim), a novel framework for uncovering the global semantic relationships between daily financial headlines and market movements. ContraSim operates in two key stages: (i) Weighted Headline Augmentation, which generates augmented financial headlines along with a semantic fine-grained similarity score, and (ii) Weighted Self-Supervised Contrastive Learning (WSSCL), an extended version of classical self-supervised contrastive learning that uses the similarity metric to create a refined weighted embedding space. This embedding space clusters semantically similar headlines together, facilitating deeper market insights. Empirical results demonstrate that integrating ContraSim features into financial forecasting tasks improves classification accuracy from WSJ headlines by 7\%. Moreover, leveraging an information density analysis, we find that the similarity spaces constructed by ContraSim intrinsically cluster days with homogeneous market movement directions, indicating that ContraSim captures market dynamics independent of ground truth labels. Additionally, ContraSim enables the identification of historical news days that closely resemble the headlines of the current day, providing analysts with actionable insights to predict market trends by referencing analogous past events.},
	language = {en},
	urldate = {2025-05-09},
	author = {Vinden, Nicholas and Saqur, Raeid and Zhu, Zining and Rudzicz, Frank},
	month = oct,
	year = {2024},
}

@misc{meng_text_2024,
	title = {Text {Injection} for {Neural} {Contextual} {Biasing}},
	url = {http://arxiv.org/abs/2406.02921},
	doi = {10.48550/arXiv.2406.02921},
	abstract = {Neural contextual biasing effectively improves automatic speech recognition (ASR) for crucial phrases within a speaker's context, particularly those that are infrequent in the training data. This work proposes contextual text injection (CTI) to enhance contextual ASR. CTI leverages not only the paired speech-text data, but also a much larger corpus of unpaired text to optimize the ASR model and its biasing component. Unpaired text is converted into speech-like representations and used to guide the model's attention towards relevant bias phrases. Moreover, we introduce a contextual text-injected (CTI) minimum word error rate (MWER) training, which minimizes the expected WER caused by contextual biasing when unpaired text is injected into the model. Experiments show that CTI with 100 billion text sentences can achieve up to 43.3\% relative WER reduction from a strong neural biasing model. CTI-MWER provides a further relative improvement of 23.5\%.},
	urldate = {2025-05-06},
	publisher = {arXiv},
	author = {Meng, Zhong and Wu, Zelin and Prabhavalkar, Rohit and Peyser, Cal and Wang, Weiran and Chen, Nanxin and Sainath, Tara N. and Ramabhadran, Bhuvana},
	month = jun,
	year = {2024},
	note = {arXiv:2406.02921 [cs]
version: 2},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@article{cho_change-point_2016,
	title = {Change-point detection in panel data via double {CUSUM} statistic},
	volume = {10},
	issn = {1935-7524},
	url = {http://arxiv.org/abs/1611.08631},
	doi = {10.1214/16-EJS1155},
	abstract = {In this paper, we consider the problem of (multiple) change-point detection in panel data. We propose the double CUSUM statistic which utilises the cross-sectional change-point structure by examining the cumulative sums of ordered CUSUMs at each point. The efficiency of the proposed change-point test is studied, which is reflected on the rate at which the cross-sectional size of a change is permitted to converge to zero while it is still detectable. Also, the consistency of the proposed change-point detection procedure based on the binary segmentation algorithm, is established in terms of both the total number and locations (in time) of the estimated change-points. Motivated by the representation properties of the Generalised Dynamic Factor Model, we propose a bootstrap procedure for test criterion selection, which accounts for both cross-sectional and within-series correlations in high-dimensional data. The empirical performance of the double CUSUM statistics, equipped with the proposed bootstrap scheme, is investigated in a comparative simulation study with the state-of-the-art. As an application, we analyse the log returns of S\&P 100 component stock prices over a period of one year.},
	number = {2},
	urldate = {2025-05-06},
	journal = {Electronic Journal of Statistics},
	author = {Cho, Haeran},
	month = jan,
	year = {2016},
	note = {arXiv:1611.08631 [stat]},
	keywords = {Statistics - Methodology},
}

@article{feldkircher_suerf_nodate,
	title = {{SUERF} {Policy} {Briefs} {No} 153, {August} 202},
	abstract = {Collecting thousands of speeches, we analyze their content by means of statistical learning techniques. Our focus is on speeches made by central bankers in Europe. Four topics are identified: structural economic policies, economic growth, monetary and economic integration; inflation, inflation expectations, price stability; speeches that deal with financial stability, risk, banks and regulation; finally, outside the box topics related to issues not directly associated with the remit of central banks. The analysis reveals that the ECB, other non-euro area central banks and central banks from Central- East and Southeastern Europe (CESEE) devote much of their communication to issues related directly to monetary policy and price stability. Moreover, the monetary authorities in CESEE countries are seen as covering a wider array of topics than their counterparts in the euro area as a means perhaps of educating policy makers and the general population about the role and influence of monetary policy.},
	language = {en},
	author = {Feldkircher, Martin and Hofmarcher, Paul and Siklos, Pierre},
}

@article{ahrens_mind_2024,
	title = {Mind your language: {Market} responses to central bank speeches},
	issn = {03044076},
	shorttitle = {Mind your language},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304407624002720},
	doi = {10.1016/j.jeconom.2024.105921},
	abstract = {Central bank communication between meetings often moves markets, but researchers have traditionally paid less attention to it. Using a dataset of U.S. Federal Reserve speeches, we develop supervised multimodal natural language processing methods to identify how monetary policy news affect bond and stock market volatility and tail risk through implied changes in forecasts of GDP, inflation, and unemployment. We find that forecast revisions derived from FOMC-member speech can help explain volatility and tail risk in both equity and bond markets. Speeches from Chairs tend to produce larger forecast revisions and unconditionally raise volatility and tail risk, but their economic signals can calm markets (reduce volatility and tail risk). There is some evidence that a speaker’s monetary policy views may affect the impact of implied forecast revisions after conditioning on GDP growth.},
	language = {en},
	urldate = {2025-05-06},
	journal = {Journal of Econometrics},
	author = {Ahrens, Maximilian and Erdemlioglu, Deniz and McMahon, Michael and Neely, Christopher J. and Yang, Xiye},
	month = dec,
	year = {2024},
	pages = {105921},
}

@misc{hu_dynamic_2022,
	title = {Dynamic {Principal} {Component} {Analysis} in {High} {Dimensions}},
	url = {http://arxiv.org/abs/2104.03087},
	doi = {10.48550/arXiv.2104.03087},
	abstract = {Principal component analysis is a versatile tool to reduce dimensionality which has wide applications in statistics and machine learning. It is particularly useful for modeling data in high-dimensional scenarios where the number of variables \$p\$ is comparable to, or much larger than the sample size \$n\$. Despite an extensive literature on this topic, researchers have focused on modeling static principal eigenvectors, which are not suitable for stochastic processes that are dynamic in nature. To characterize the change in the entire course of high-dimensional data collection, we propose a unified framework to directly estimate dynamic eigenvectors of covariance matrices. Specifically, we formulate an optimization problem by combining the local linear smoothing and regularization penalty together with the orthogonality constraint, which can be effectively solved by manifold optimization algorithms. We show that our method is suitable for high-dimensional data observed under both common and irregular designs, and theoretical properties of the estimators are investigated under \$l\_q (0 {\textbackslash}leq q {\textbackslash}leq 1)\$ sparsity. Extensive experiments demonstrate the effectiveness of the proposed method in both simulated and real data examples.},
	urldate = {2025-05-05},
	publisher = {arXiv},
	author = {Hu, Xiaoyu and Yao, Fang},
	month = aug,
	year = {2022},
	note = {arXiv:2104.03087 [stat]},
	keywords = {Statistics - Methodology},
}

@article{ma_financial_nodate,
	title = {Financial and {Business} {Cycle} {Risk} {Premia}},
	abstract = {I estimate financial and business cycles using a regime-switching state-space model, applied respectively to cross-sectional financial variables and macroeconomic aggregates. Analyzing U.S. equity excess returns with OLS regressions and a structural vector autoregression (SVAR) framework, I uncover two key insights. First, financial cycle risk premia diverge fundamentally from business cycle risk premia. While the business cycle premia are countercyclical, financial cycle shocks drive persistent repricing effects. Favorable financial conditions consistently forecast higher subsequent quarter returns. In contrast, the predictability of macro conditions emerges primarily in adverse states. Second, the “financial accelerator mechanism” appears asymmetric. Positive macro shocks lead to higher financial stress in subsequent quarters, whereas favorable financial shocks generate sustained improvements in macroeconomic performance. My results challenge the notion that financial cycles are merely secondary reflections of business cycles, highlighting instead endogenous financial dynamics and consistent pricing effects.},
	language = {en},
	author = {Ma, Yifan},
}

@article{dai_global_2021,
	title = {A global economic policy uncertainty index from principal component analysis},
	volume = {40},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612319310542},
	doi = {10.1016/j.frl.2020.101686},
	abstract = {This paper constructs a global economic policy uncertainty index through the principal component analysis of the economic policy uncertainty indices for twenty primary economies around the world. We find that the PCA-based global economic policy uncertainty index is a good proxy for the economic policy uncertainty on the global scale, which is quite consistent with the GDPweighted global economic policy uncertainty index. The PCA-based economic policy uncertainty index is found to be positively related with the volatility and correlation of the global financial market, which indicates that the stock markets are more volatile and correlated when the global economic policy uncertainty is higher. The PCA-based global economic policy uncertainty index (T=24) performs slightly better because the relationships between the PCA-based uncertainty and market volatility and between the PCA-based uncertainty and market correlation are more significant.},
	language = {en},
	urldate = {2025-05-05},
	journal = {Finance Research Letters},
	author = {Dai, Peng-Fei and Xiong, Xiong and Zhou, Wei-Xing},
	month = may,
	year = {2021},
	pages = {101686},
}

@article{brave_new_2019,
	title = {A new “big data” index of {U}.{S}. economic activity},
	issn = {0164-0682},
	url = {https://www.chicagofed.org/~/media/publications/economic-perspectives/2019/ep2019-1-pdf.pdf},
	doi = {10.21033/ep-2019-1},
	language = {en},
	urldate = {2025-05-05},
	journal = {Economic Perspectives},
	author = {Brave, Scott A. and Butters, R. Andrew and Kelley, David},
	year = {2019},
}

@article{liu_macroeconomic_2023,
	title = {Macroeconomic attention and oil futures volatility prediction},
	volume = {57},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612323005391},
	doi = {10.1016/j.frl.2023.104167},
	abstract = {This paper mainly checks whether the macroeconomic attention indices have valuable information to predict the oil futures volatility. Results show that macroeconomic attention indices are able to predict the oil futures volatility. In addition, based on several dimensionality reduction methods, we find that the scaled principal component analysis (SPCA) model has better predictive performances than other dimensionality reduction methods. Especially, the least absolute shrinkage and selection operator method (LASSO) has the best predictive performance. During the COVID-19 period, LASSO model with the macroeconomic attention indices can still have superior performances. This paper tries to show new evidence based on macroeconomic attention indices for oil market volatility.},
	language = {en},
	urldate = {2025-05-05},
	journal = {Finance Research Letters},
	author = {Liu, Shan and Li, Ziwei},
	month = nov,
	year = {2023},
	pages = {104167},
}

@article{hong_forecasting_2025,
	title = {Forecasting {Inflation} {Using} {Economic} {Narratives}},
	volume = {43},
	issn = {0735-0015},
	url = {https://doi.org/10.1080/07350015.2024.2347619},
	doi = {10.1080/07350015.2024.2347619},
	abstract = {We use economic narratives to forecast inflation with a large news corpus and machine learning algorithms. The economic narratives from the full text content of over 880,000 Wall Street Journal articles are decomposed into multiple time series representing interpretable news topics, which are then used to predict inflation. The results indicate that narrative-based forecasts are more accurate than the benchmarks, especially during recession periods. Narrative-based forecasts perform better in long-run forecasting and provide incremental predictive information even after controlling macroeconomic big data. In particular, information about inflation expectations and prices of specific goods embedded in narratives contributes to their predictive power. Overall, we provide a novel representation of economic narratives and document the important role of economic narratives in inflation forecasting.},
	number = {1},
	urldate = {2025-04-07},
	journal = {Journal of Business \& Economic Statistics},
	author = {Hong, Yongmiao and Fuwei, Jiang and Lingchao, Meng and Xue, Bowen},
	month = jan,
	year = {2025},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/07350015.2024.2347619},
	keywords = {Economic narratives, Inflation forecasting, Machine learning, Textual analysis},
	pages = {216--231},
}

@article{taffler_narrative_2024,
	title = {Narrative {Emotions} and {Market} {Crises}},
	volume = {0},
	issn = {1542-7560},
	url = {https://doi.org/10.1080/15427560.2024.2365723},
	doi = {10.1080/15427560.2024.2365723},
	abstract = {Robert Shiller highlights the role popular stories play in driving economic behavior and argues the need to analyze these scientifically. However, their impacts are difficult to measure directly and often conflict. We show the strength of such stories resides in the emotions they generate, and that the tenor and persuasiveness of financial narratives and their association with the market can be empirically quantified. Specifically, we textually analyze financial media reports to identify the different powerful investor emotions manifest during three recent extreme market periods, dot.com mania, the Global Financial Crisis and the COVID-19 pandemic, constructing original context-specific emotion word dictionaries for this purpose. We find investor emotions are associated with up to 52\% of market returns and 67\% of market uncertainty during these market crises, and provide general evidence that investor emotional dynamics may be time and context invariant.},
	number = {0},
	urldate = {2025-04-07},
	journal = {Journal of Behavioral Finance},
	author = {Taffler, Richard J. and Agarwal, Vineet and Obring, Maximilian},
	month = jun,
	year = {2024},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15427560.2024.2365723},
	keywords = {A12, B41, COVID-19 pandemic, G01, G12, G41, Global Financial Crisis, internet bubble, investor emotions, market pricing, media stories},
	pages = {1--21},
}

@inproceedings{la_quatra_end--end_2020,
	address = {Barcelona, Spain (Online)},
	title = {End-to-end {Training} {For} {Financial} {Report} {Summarization}},
	url = {https://aclanthology.org/2020.fnp-1.20/},
	abstract = {Quoted companies are requested to periodically publish financial reports in textual form. The annual financial reports typically include detailed financial and business information, thus giving relevant insights into company outlooks. However, a manual exploration of these financial reports could be very time consuming since most of the available information can be deemed as non-informative or redundant by expert readers. Hence, an increasing research interest has been devoted to automatically extracting domain-specific summaries, which include only the most relevant information. This paper describes the SumTO system architecture, which addresses the Shared Task of the Financial Narrative Summarisation (FNS) 2020 contest. The main task objective is to automatically extract the most informative, domain-specific textual content from financial, English-written documents. The aim is to create a summary of each company report covering all the business-relevant key points. To address the above-mentioned goal, we propose an end-to-end training method relying on Deep NLP techniques. The idea behind the system is to exploit the syntactic overlap between input sentences and ground-truth summaries to fine-tune pre-trained BERT embedding models, thus making such models tailored to the specific context. The achieved results confirm the effectiveness of the proposed method, especially when the goal is to select relatively long text snippets.},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the 1st {Joint} {Workshop} on {Financial} {Narrative} {Processing} and {MultiLing} {Financial} {Summarisation}},
	publisher = {COLING},
	author = {La Quatra, Moreno and Cagliero, Luca},
	editor = {El-Haj, Dr Mahmoud and Athanasakou, Dr Vasiliki and Ferradans, Dr Sira and Salzedo, Dr Catherine and Elhag, Dr Ans and Bouamor, Dr Houda and Litvak, Dr Marina and Rayson, Dr Paul and Giannakopoulos, Dr George and Pittaras, Nikiforos},
	month = dec,
	year = {2020},
	pages = {118--123},
}

@inproceedings{zmandar_cofif_2022,
	address = {Marseille, France},
	title = {{CoFiF} {Plus}: {A} {French} {Financial} {Narrative} {Summarisation} {Corpus}},
	shorttitle = {{CoFiF} {Plus}},
	url = {https://aclanthology.org/2022.lrec-1.174/},
	abstract = {Natural Language Processing is increasingly being applied in the finance and business industry to analyse the text of many different types of financial documents. Given the increasing growth of firms around the world, the volume of financial disclosures and financial texts in different languages and forms is increasing sharply and therefore the study of language technology methods that automatically summarise content has grown rapidly into a major research area. Corpora for financial narrative summarisation exists in English, but there is a significant lack of financial text resources in the French language. To remedy this, we present CoFiF Plus, the first French financial narrative summarisation dataset providing a comprehensive set of financial text written in French. The dataset has been extracted from French financial reports published in PDF file format. It is composed of 1,703 reports from the most capitalised companies in France (Euronext Paris) covering a time frame from 1995 to 2021. This paper describes the collection, annotation and validation of the financial reports and their summaries. It also describes the dataset and gives the results of some baseline summarisers. Our datasets will be openly available upon the acceptance of the paper.},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the {Thirteenth} {Language} {Resources} and {Evaluation} {Conference}},
	publisher = {European Language Resources Association},
	author = {Zmandar, Nadhem and Daudert, Tobias and Ahmadi, Sina and El-Haj, Mahmoud and Rayson, Paul},
	editor = {Calzolari, Nicoletta and Béchet, Frédéric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, Hélène and Odijk, Jan and Piperidis, Stelios},
	month = jun,
	year = {2022},
	pages = {1622--1639},
}

@article{tuckett_tracking_2014,
	title = {Tracking phantastic objects: {A} computer algorithmic investigation of narrative evolution in unstructured data sources},
	volume = {38},
	issn = {03788733},
	shorttitle = {Tracking phantastic objects},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S037887331400015X},
	doi = {10.1016/j.socnet.2014.03.001},
	abstract = {We develop social network and “relative sentiment shift” analysis techniques to study how ﬁnancial narratives inﬂuence ﬁnancial markets. First, we analyze Reuters News articles focusing on narratives about Fannie Mae. Second, we analyze Broadband and Energy narratives in the Enron Corporation email database. Combining datasets we show that phantastic object narratives can be detected and tracked as they develop and spread through networks to lead to a disconnect between narrative and underlying “reality”. The methods may be applicable to other text datasets to create early warnings.},
	language = {en},
	urldate = {2025-04-07},
	journal = {Social Networks},
	author = {Tuckett, David and Smith, Robert Elliot and Nyman, Rickard},
	month = jul,
	year = {2014},
	pages = {121--133},
}

@article{riley_managing_2015,
	title = {Managing {Investors}' {Perception} {Through} {Strategic} {Word} {Choices} in {Financial} {Narratives}},
	volume = {26},
	copyright = {© 2015 Wiley Periodicals, Inc.},
	issn = {1097-0053},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcaf.22064},
	doi = {10.1002/jcaf.22064},
	abstract = {Corporate managers have been shown to successfully use narrative impression management techniques to influence investors' perceptions of company performance. Examples of these techniques include using complex language to disguise bad news, attributing bad news to external forces, altering the tone of the narratives to sound more positive, and writing with more verbs than adjectives to convey the context as concrete. We provide an overview of the research examining managers' impression management techniques through word choice, along with evidence that suggests how investors respond. Based on this information, managers may wish to consider strategically choosing their language to ensure that their message is interpreted as intended. © 2015 Wiley Periodicals, Inc.},
	language = {en},
	number = {5},
	urldate = {2025-04-07},
	journal = {Journal of Corporate Accounting \& Finance},
	author = {Riley, Tracey J. and Luippold, Benjamin L.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcaf.22064},
	pages = {57--62},
}

@book{el-haj_proceedings_2020,
	address = {Barcelona, Spain (Online)},
	title = {Proceedings of the 1st {Joint} {Workshop} on {Financial} {Narrative} {Processing} and {MultiLing} {Financial} {Summarisation}},
	url = {https://aclanthology.org/2020.fnp-1.0/},
	urldate = {2025-04-07},
	publisher = {COLING},
	editor = {El-Haj, Dr Mahmoud and Athanasakou, Dr Vasiliki and Ferradans, Dr Sira and Salzedo, Dr Catherine and Elhag, Dr Ans and Bouamor, Dr Houda and Litvak, Dr Marina and Rayson, Dr Paul and Giannakopoulos, Dr George and Pittaras, Nikiforos},
	month = dec,
	year = {2020},
}

@inproceedings{hu_annotation_2021,
	address = {Lancaster, United Kingdom},
	title = {Annotation model and corpus for opinionated economy and finance narrative detection},
	url = {https://aclanthology.org/2021.fnp-1.11/},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the 3rd {Financial} {Narrative} {Processing} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Hu, Jiahui and Paroubek, Patrick and Schumacher, Dirk},
	editor = {El-Haj, Mahmoud and Rayson, Paul and Zmandar, Nadhem},
	year = {2021},
	pages = {61--66},
}

@book{el-haj_proceedings_2021,
	address = {Lancaster, United Kingdom},
	title = {Proceedings of the 3rd {Financial} {Narrative} {Processing} {Workshop}},
	url = {https://aclanthology.org/2021.fnp-1.0/},
	urldate = {2025-04-07},
	publisher = {Association for Computational Linguistics},
	editor = {El-Haj, Mahmoud and Rayson, Paul and Zmandar, Nadhem},
	year = {2021},
}

@book{hahn_proceedings_2021,
	address = {Punta Cana, Dominican Republic},
	title = {Proceedings of the {Third} {Workshop} on {Economics} and {Natural} {Language} {Processing}},
	url = {https://aclanthology.org/2021.econlp-1.0/},
	urldate = {2025-04-07},
	publisher = {Association for Computational Linguistics},
	editor = {Hahn, Udo and Hoste, Veronique and Stent, Amanda},
	month = nov,
	year = {2021},
}

@book{chen_proceedings_2025,
	address = {Abu Dhabi, UAE},
	title = {Proceedings of the {Joint} {Workshop} of the 9th {Financial} {Technology} and {Natural} {Language} {Processing} ({FinNLP}), the 6th {Financial} {Narrative} {Processing} ({FNP}), and the 1st {Workshop} on {Large} {Language} {Models} for {Finance} and {Legal} ({LLMFinLegal})},
	url = {https://aclanthology.org/2025.finnlp-1.0/},
	urldate = {2025-04-07},
	publisher = {Association for Computational Linguistics},
	editor = {Chen, Chung-Chi and Moreno-Sandoval, Antonio and Huang, Jimin and Xie, Qianqian and Ananiadou, Sophia and Chen, Hsin-Hsi},
	month = jan,
	year = {2025},
}

@book{el-haj_proceedings_2022,
	address = {Marseille, France},
	title = {Proceedings of the 4th {Financial} {Narrative} {Processing} {Workshop} @{LREC2022}},
	url = {https://aclanthology.org/2022.fnp-1.0/},
	urldate = {2025-04-07},
	publisher = {European Language Resources Association},
	editor = {El-Haj, Mahmoud and Rayson, Paul and Zmandar, Nadhem},
	month = jun,
	year = {2022},
}

@inproceedings{sy_fine-grained_2023,
	address = {Taipei City, Taiwan},
	title = {Fine-{Grained} {Argument} {Understanding} with {BERT} {Ensemble} {Techniques}: {A} {Deep} {Dive} into {Financial} {Sentiment} {Analysis}},
	shorttitle = {Fine-{Grained} {Argument} {Understanding} with {BERT} {Ensemble} {Techniques}},
	url = {https://aclanthology.org/2023.rocling-1.30/},
	urldate = {2025-04-07},
	booktitle = {Proceedings of the 35th {Conference} on {Computational} {Linguistics} and {Speech} {Processing} ({ROCLING} 2023)},
	publisher = {The Association for Computational Linguistics and Chinese Language Processing (ACLCLP)},
	author = {Sy, Eugene and Peng, Tzu-Cheng and Huang, Shih-Hsuan and Lin, Heng-Yu and Chang, Yung-Chun},
	editor = {Wu, Jheng-Long and Su, Ming-Hsiang},
	month = oct,
	year = {2023},
	pages = {242--249},
}

@misc{liu_beyond_2024,
	title = {Beyond {Surface} {Similarity}: {Detecting} {Subtle} {Semantic} {Shifts} in {Financial} {Narratives}},
	shorttitle = {Beyond {Surface} {Similarity}},
	url = {http://arxiv.org/abs/2403.14341},
	doi = {10.48550/arXiv.2403.14341},
	abstract = {In this paper, we introduce the Financial-STS task, a financial domain-specific NLP task designed to measure the nuanced semantic similarity between pairs of financial narratives. These narratives originate from the financial statements of the same company but correspond to different periods, such as year-over-year comparisons. Measuring the subtle semantic differences between these paired narratives enables market stakeholders to gauge changes over time in the company's financial and operational situations, which is critical for financial decision-making. We find that existing pretrained embedding models and LLM embeddings fall short in discerning these subtle financial narrative shifts. To address this gap, we propose an LLM-augmented pipeline specifically designed for the Financial-STS task. Evaluation on a human-annotated dataset demonstrates that our proposed method outperforms existing methods trained on classic STS tasks and generic LLM embeddings.},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Liu, Jiaxin and Yang, Yi and Tam, Kar Yan},
	month = mar,
	year = {2024},
	note = {arXiv:2403.14341 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{ash_relatio_2024,
	title = {Relatio: {Text} {Semantics} {Capture} {Political} and {Economic} {Narratives}},
	volume = {32},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Relatio},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/relatio-text-semantics-capture-political-and-economic-narratives/E72C0482A44C9A817E381B394A73E2D6},
	doi = {10.1017/pan.2023.8},
	abstract = {Social scientists have become increasingly interested in how narratives—the stories in fiction, politics, and life—shape beliefs, behavior, and government policies. This paper provides an unsupervised method to quantify latent narrative structures in text documents. Our new software package relatio identifies coherent entity groups and maps explicit relations between them in the text. We provide an application to the U.S. Congressional Record to analyze political and economic narratives in recent decades. Our analysis highlights the dynamics, sentiment, polarization, and interconnectedness of narratives in political discourse.},
	language = {en},
	number = {1},
	urldate = {2025-04-07},
	journal = {Political Analysis},
	author = {Ash, Elliott and Gauthier, Germain and Widmer, Philine},
	month = jan,
	year = {2024},
	keywords = {memes, narratives, natural language processing},
	pages = {115--132},
}

@article{hao_finflier_2024,
	title = {{FinFlier}: {Automating} {Graphical} {Overlays} for {Financial} {Visualizations} {With} {Knowledge}-{Grounding} {Large} {Language} {Model}},
	issn = {1941-0506},
	shorttitle = {{FinFlier}},
	url = {https://ieeexplore.ieee.org/document/10787087},
	doi = {10.1109/TVCG.2024.3514138},
	abstract = {Graphical overlays that layer visual elements onto charts, are effective to convey insights and context in financial narrative visualizations. However, automating graphical overlays is challenging due to complex narrative structures and limited understanding of effective overlays. To address the challenge, we first summarize the commonly used graphical overlays and narrative structures, and the proper correspondence between them in financial narrative visualizations, elected by a survey of 1752 layered charts with corresponding narratives. We then design FinFlier, a two-stage innovative system leveraging a knowledge-grounding large language model to automate graphical overlays for financial visualizations. The text-data binding module enhances the connection between financial vocabulary and tabular data through advanced prompt engineering, and the graphics overlaying module generates effective overlays with narrative sequencing. We demonstrate the feasibility and expressiveness of FinFlier through a gallery of graphical overlays covering diverse financial narrative visualizations. Performance evaluations and user studies further confirm system's effectiveness and the quality of generated layered charts.},
	urldate = {2025-04-07},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Hao, Jianing and Yang, Manling and Shi, Qing and Jiang, Yuzhe and Zhang, Guang and Zeng, Wei},
	year = {2024},
	keywords = {Financial narrative, LLM, graphical overlay},
	pages = {1--17},
}

@article{stander_news_2024,
	title = {A {News} {Sentiment} {Index} to {Inform} {International} {Financial} {Reporting} {Standard} 9 {Impairments}},
	volume = {17},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1911-8074},
	url = {https://www.mdpi.com/1911-8074/17/7/282},
	doi = {10.3390/jrfm17070282},
	abstract = {Economic and financial narratives inform market sentiment through the emotions that are triggered and the subjectivity that gets evoked. There is an important connection between narrative, sentiment, and human decision making. In this study, natural language processing is used to extract market sentiment from the narratives using FinBERT, a Python library that has been pretrained on a large financial corpus. A news sentiment index is constructed and shown to be a leading indicator of systemic risk. A rolling regression shows how the impact of news sentiment on systemic risk changes over time, with the importance of news sentiment increasing in more recent years. Monitoring systemic risk is an important tool used by central banks to proactively identify and manage emerging risks to the financial system; it is also a key input into the credit loss provision quantification at banks. Credit loss provision is a key focus area for auditors because of the risk of material misstatement, but finding appropriate sources of audit evidence is challenging. The causal relationship between news sentiment and systemic risk suggests that news sentiment could serve as an early warning signal of increasing credit risk and an effective indicator of the state of the economic cycle. The news sentiment index is shown to be useful as audit evidence when benchmarking trends in accounting provisions, thus informing financial disclosures and serving as an exogenous variable in econometric forecast models.},
	language = {en},
	number = {7},
	urldate = {2025-04-07},
	journal = {Journal of Risk and Financial Management},
	author = {Stander, Yolanda S.},
	month = jul,
	year = {2024},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {AI, IFRS 9, natural language processing, news sentiment index, rolling regression, systemic risk},
	pages = {282},
}

@article{agarwal_investor_2025,
	title = {Investor emotions and market bubbles},
	volume = {64},
	issn = {1573-7179},
	url = {https://doi.org/10.1007/s11156-024-01309-w},
	doi = {10.1007/s11156-024-01309-w},
	abstract = {Asset pricing bubbles are highly emotional market episodes. Despite this, investor emotions are not part of traditional bubble models. We measure the powerful affects influencing investor decisions during speculative market bubbles directly employing textual analysis of media narratives and domain-specific emotion keyword dictionaries and show how understanding investor emotional dynamics helps explain market behavior. Specifically, we focus on the two Chinese stock market bubbles of 2005–2008 and 2014–2016; there is no evidence of investor learning from experience. Despite Chinese media being censored we show it still has strong explanatory power although the independent English language media can provide an additional perspective. Deeper emotions dominate more superficial feelings in information content.},
	language = {en},
	number = {1},
	urldate = {2025-04-07},
	journal = {Review of Quantitative Finance and Accounting},
	author = {Agarwal, Vineet and Taffler, Richard J. and Wang, Chenyang},
	month = jan,
	year = {2025},
	keywords = {Asset pricing bubbles, Chinese stock market, Economic narratives, G12, G15, G41, Investor emotions, Textual analysis},
	pages = {339--369},
}

@misc{wang_multilingual_2024,
	title = {Multilingual {E5} {Text} {Embeddings}: {A} {Technical} {Report}},
	shorttitle = {Multilingual {E5} {Text} {Embeddings}},
	url = {http://arxiv.org/abs/2402.05672},
	doi = {10.48550/arXiv.2402.05672},
	abstract = {This technical report presents the training methodology and evaluation results of the open-source multilingual E5 text embedding models, released in mid-2023. Three embedding models of different sizes (small / base / large) are provided, offering a balance between the inference efficiency and embedding quality. The training procedure adheres to the English E5 model recipe, involving contrastive pre-training on 1 billion multilingual text pairs, followed by fine-tuning on a combination of labeled datasets. Additionally, we introduce a new instruction-tuned embedding model, whose performance is on par with state-of-the-art, English-only models of similar sizes. Information regarding the model release can be found at https://github.com/microsoft/unilm/tree/master/e5 .},
	urldate = {2025-04-07},
	publisher = {arXiv},
	author = {Wang, Liang and Yang, Nan and Huang, Xiaolong and Yang, Linjun and Majumder, Rangan and Wei, Furu},
	month = feb,
	year = {2024},
	note = {arXiv:2402.05672 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval},
}

@article{eliaz_model_2020,
	title = {A {Model} of {Competing} {Narratives}},
	volume = {110},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.20191099},
	doi = {10.1257/aer.20191099},
	abstract = {We formalize the argument that political disagreements can be traced to a "clash of narratives." Drawing on the "Bayesian Networks" literature, we represent a narrative by a causal model that maps actions into consequences, weaving a selection of other random variables into the story. Narratives generate beliefs by interpreting long-run correlations between these variables. An equilibrium is defined as a probability distribution over narrative-policy pairs that maximize a representative agent's anticipatory utility, capturing the idea that people are drawn to hopeful narratives. Our equilibrium analysis sheds light on the structure of prevailing narratives, the variables they involve, the policies they sustain, and their contribution to political polarization.},
	language = {en},
	number = {12},
	urldate = {2025-04-04},
	journal = {American Economic Review},
	author = {Eliaz, Kfir and Spiegler, Ran},
	month = dec,
	year = {2020},
	keywords = {Belief, Communication, Economic Nationalism, Information and Knowledge, Learning, Political Processes: Rent-seeking, Lobbying, Elections, Legislatures, and Voting Behavior, Search, Unawareness, Network Formation and Analysis: Theory, National Security},
	pages = {3786--3816},
}

@article{shiller_narrative_2017,
	title = {Narrative {Economics}},
	volume = {107},
	issn = {0002-8282},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.107.4.967},
	doi = {10.1257/aer.107.4.967},
	abstract = {This address considers the epidemiology of narratives relevant to economic fluctuations. The human brain has always been highly tuned toward narratives, whether factual or not, to justify ongoing actions, even such basic actions as spending and investing. Stories motivate and connect activities to deeply felt values and needs. Narratives "go viral" and spread far, even worldwide, with economic impact. The 1920-1921 Depression, the Great Depression of the 1930s, the so-called Great Recession of 2007-2009, and the contentious political-economic situation of today are considered as the results of the popular narratives of their respective times. Though these narratives are deeply human phenomena that are difficult to study in a scientific manner, quantitative analysis may help us gain a better understanding of these epidemics in the future.},
	language = {en},
	number = {4},
	urldate = {2025-04-04},
	journal = {American Economic Review},
	author = {Shiller, Robert J.},
	month = apr,
	year = {2017},
	keywords = {Cycles, Financial Crises, Economic History: Macroeconomics and Monetary Economics, Fluctuations: General, International, or Comparative, Growth, Industrial Structure, Political Processes: Rent-Seeking, Lobbying, Elections, Legislatures, and Voting Behavior, Business Fluctuations},
	pages = {967--1004},
}

@article{shiller_popular_2020,
	title = {Popular economic narratives advancing the longest {U}.{S}. expansion 2009–2019},
	volume = {42},
	issn = {01618938},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0161893820300399},
	doi = {10.1016/j.jpolmod.2020.03.005},
	abstract = {The U.S. economic expansion since 2009 is the longest on record since 1854, according to the National Bureau of Economic Research Business Cycle Dating Committee. This paper seeks to understand this phenomenon better by looking at the time paths of popular narratives over this interval, of stories that people have been telling that offer clues into their economic behavior. Six constellations of narratives are studied, identiﬁed by keywords “Great Depression,” “secular stagnation,” “sustainability,” “housing bubble,” “strong economy,” and “save more.” © 2020 Published by Elsevier Inc. on behalf of The Society for Policy Modeling.},
	language = {en},
	number = {4},
	urldate = {2025-04-04},
	journal = {Journal of Policy Modeling},
	author = {Shiller, Robert J.},
	month = jul,
	year = {2020},
	pages = {791--798},
}

@article{chu_global_2020,
	title = {A global supply chain risk management framework: {An} application of text-mining to identify region-specific supply chain risks},
	volume = {45},
	issn = {14740346},
	shorttitle = {A global supply chain risk management framework},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474034620300227},
	doi = {10.1016/j.aei.2020.101053},
	abstract = {Nowadays global supply chains enable companies to enhance competitive advantages, increase manufacturing flexibility and reduce costs through a broader selection of suppliers. Despite these benefits, however, insufficient understanding of uncertain regional differences and changes often increases risks in supply chain operations and even leads to a complete disruption of a supply chain. This paper addresses this issue by proposing a text-mining based global supply chain risk management framework involving two phases. First, the extant literature about global supply chain risks was collected and analyzed using a text-based approaches, including term frequency, correlation, and bi-gram analysis. The results of these analyses revealed whether the term-related content is important in the studied literature, and correlated topic model clustering further assisted in defining potential supply chain risk factors. A risk categorization (hierarchy) containing a total of seven global supply chain risk types and underlying risk factors was developed based on the results. In the second phase, utilizing these risk factors, sentiment analysis was conducted on online news articles, selected according to the specific type of risk, to recognize the pattern of risk variation. The risk hierarchy and sentiment analysis results can improve the understanding of regional global supply chain risks and provide guidance in supplier selection.},
	language = {en},
	urldate = {2025-03-31},
	journal = {Advanced Engineering Informatics},
	author = {Chu, Chih-Yuan and Park, Kijung and Kremer, Gül E.},
	month = aug,
	year = {2020},
	pages = {101053},
}

@article{liu_intellectual_2022,
	title = {Intellectual {Structure} in {Supply} {Chain} {Risk} {Management} from 2000 to 2022: {A} {Review} {Based} on {Text} {Mining} {Approach}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	shorttitle = {Intellectual {Structure} in {Supply} {Chain} {Risk} {Management} from 2000 to 2022},
	url = {https://www.mdpi.com/2071-1050/14/23/16245},
	doi = {10.3390/su142316245},
	abstract = {This study illustrates the intellectual structure of research in the domain of supply chain risk management (SCRM) from the year 2000 to the year 2022. This paper employs a bibliometric analysis to investigate the foundations of the discipline and a quantitative approach to uncover the evolution of research in SCRM. Firstly, CiteSpace is used to evaluate and show the intellectual structure of this sector. With its help, we establish cooperation networks of institutions and countries, networks of different terms and keywords, and cooperation relations among writers. The process involves the extraction of certain useful information, such as core terms, leading authors, and major institutions. Secondly, with the help of the latent Dirichlet allocation technology, we look at the progression of the subject matter about the management of risks associated with supply chains. The outcome of this review provides a foundation for understanding developing patterns and new changes in the industry, and it is significant for future research on supply chain risk management. Our study not only updates the review of SCRM but also illustrates the possibility to objectively review literature with the support of text mining technology, using our newly developed framework. This framework can also be easily applied to other research fields.},
	language = {en},
	number = {23},
	urldate = {2025-03-31},
	journal = {Sustainability},
	author = {Liu, Xiaoyang and Zhou, Yuanyuan and Gao, Song},
	month = jan,
	year = {2022},
	note = {Number: 23
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bibliometric analysis, intellectual structure, latent Dirichlet allocation, supply chain risk management},
	pages = {16245},
}

@article{olson_incorporating_2023,
	title = {Incorporating an {Unsupervised} {Text} {Mining} {Approach} into {Studying} {Logistics} {Risk} {Management}: {Insights} from {Corporate} {Annual} {Reports} and {Topic} {Modeling}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	shorttitle = {Incorporating an {Unsupervised} {Text} {Mining} {Approach} into {Studying} {Logistics} {Risk} {Management}},
	url = {https://www.mdpi.com/2078-2489/14/7/395},
	doi = {10.3390/info14070395},
	abstract = {This study examined the Security and Exchange Commission (SEC) annual reports of selected logistics firms over the period from 2006 through 2021 for risk management terms. The purpose was to identify which risks are considered most important in supply chain logistics operations. Section 1A of the SEC reports includes risk factors. The COVID-19 pandemic has had a heavy impact on global supply chains. We also know that trucking firms have long had difficulties recruiting drivers. Fuel price has always been a major risk for airlines but also can impact shipping, trucking, and railroads. We were especially interested in pandemic, personnel, and fuel risks. We applied topic modeling, enabling us to identify some of the capabilities of unsupervised text mining as applied to SEC reports. We demonstrate the identification of terms, the time dimension, and correlation across topics by the topic model. Our analysis confirmed expectations about COVID-19’s impact, personnel shortages, and fuel. It also revealed common themes regarding the risks involved in international trade and perceived regulatory risks. We conclude with the supply chain management risks identified and discuss means of mitigation.},
	language = {en},
	number = {7},
	urldate = {2025-03-31},
	journal = {Information},
	author = {Olson, David and Chae, Bongsug (Kevin)},
	month = jul,
	year = {2023},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {logistics, risk management, supply chains, topic modeling, unsupervised text mining},
	pages = {395},
}

@article{tingelhoff_guide_2025,
	title = {A guide for structured literature reviews in business research: {The} state-of-the-art and how to integrate generative artificial intelligence},
	volume = {40},
	issn = {0268-3962},
	shorttitle = {A guide for structured literature reviews in business research},
	url = {https://doi.org/10.1177/02683962241304105},
	doi = {10.1177/02683962241304105},
	abstract = {Generative artificial intelligence (Gen.AI) is capable of significantly improving the breadth and depth of structured literature reviews (SLRs). However, its inclusion raises essential questions regarding the review’s methodology, quality, and ethical implications. Previous research predominantly focused on the capabilities and limitations of Gen.AI to establish guidelines for research practices. However, the rapid evolution of Gen.AI often outpaces the publication of methodological papers. In response, our study adopts a criteria-centric approach, scrutinizing the scientific quality standards that Gen.AI must meet. In other words, instead of discussing what Gen.AI can and cannot do, we discuss what we should allow Gen.AI to do, irrespective of its capabilities. Our study informs researchers in the art and science of SLRs. First, we analyze the established state-of-the-art processes and associated quality standards in SLRs. From this, we synthesize a unified process and criterion set, not only underpinning a comprehensive understanding of the extant SLR methodologies but also serving as the foundational framework for integrating Gen.AI. Second, we delineate the specific scenarios conducive to incorporating Gen.AI into this fundamental framework, as well as situations where its integration may not be suitable. Our contribution is further solidified by providing a detailed, step-by-step guide—akin to a “cooking recipe”—to effectively integrate Gen.AI in SLRs, ensuring adherence to established quality criteria.},
	language = {EN},
	number = {1},
	urldate = {2025-03-28},
	journal = {Journal of Information Technology},
	author = {Tingelhoff, Fabian and Brugger, Micha and Leimeister, Jan Marco},
	month = mar,
	year = {2025},
	note = {Publisher: SAGE Publications Ltd},
	pages = {77--99},
}

@article{s_how_2024,
	title = {How to {Undertake} an {Impactful} {Literature} {Review}: {Understanding} {Review} {Approaches} and {Guidelines} for {High}-impact {Systematic} {Literature} {Reviews}},
	volume = {13},
	issn = {2277-9779},
	shorttitle = {How to {Undertake} an {Impactful} {Literature} {Review}},
	url = {https://doi.org/10.1177/22779779241227654},
	doi = {10.1177/22779779241227654},
	abstract = {Literature reviews lay the foundation for academic investigations, especially for early career researchers. However, in the planning phase, we generally lack clarity on approaches, due to which a lot of review articles are rejected or fail to create a significant impact. The systematic literature review (SLR) is one of the important review methodologies which is increasingly becoming popular to synthesize literature in any discipline in general and management in particular. In this article, we explain the SLR methodology and provide guidelines for performing and documenting these studies. Through systematic processes, these reviews offer suggestions to synthesize literature to identify research gaps and indicate research directions. Lastly, this article serves as a guide for researchers and academics in conducting an extensive literature review.},
	language = {EN},
	number = {1},
	urldate = {2025-03-28},
	journal = {South Asian Journal of Business and Management Cases},
	author = {S, Varsha P. and Chakraborty, Amrita and Kar, Arpan Kumar},
	month = apr,
	year = {2024},
	note = {Publisher: SAGE Publications India},
	pages = {18--35},
}

@article{somers_narrative_1994,
	title = {The narrative constitution of identity: {A} relational and network approach},
	volume = {23},
	issn = {1573-7853},
	shorttitle = {The narrative constitution of identity},
	url = {https://doi.org/10.1007/BF00992905},
	doi = {10.1007/BF00992905},
	language = {en},
	number = {5},
	urldate = {2025-03-27},
	journal = {Theory and Society},
	author = {Somers, Margaret R.},
	month = oct,
	year = {1994},
	keywords = {Narrative Constitution, Network Approach},
	pages = {605--649},
}

@misc{grossman_impossibility_1980,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {On the {Impossibility} of {Informationally} {Efficient} {Markets}},
	url = {https://papers.ssrn.com/abstract=228054},
	abstract = {If competitive equilibrium is defined as a situation in which prices are such that all arbitrage profits are eliminated, is it possible that a competitive economy always be in equilibrium?  Clearly not, for then those who arbitrage make no (private) return from their (privately) costly activity.  Hence the assumptions that all markets, including that for information, are always in equilibrium and always perfectly arbitraged are inconsistent when arbitrage is costly.},
	language = {en},
	urldate = {2025-03-27},
	publisher = {Social Science Research Network},
	author = {Grossman, Sanford J.},
	month = dec,
	year = {1980},
	keywords = {On the Impossibility of Informationally Efficient Markets, SSRN, Sanford J. Grossman},
}

@misc{grootendorst_bertopic_2022,
	title = {{BERTopic}: {Neural} topic modeling with a class-based {TF}-{IDF} procedure},
	shorttitle = {{BERTopic}},
	url = {http://arxiv.org/abs/2203.05794},
	doi = {10.48550/arXiv.2203.05794},
	abstract = {Topic models can be useful tools to discover latent topics in collections of documents. Recent studies have shown the feasibility of approach topic modeling as a clustering task. We present BERTopic, a topic model that extends this process by extracting coherent topic representation through the development of a class-based variation of TF-IDF. More specifically, BERTopic generates document embedding with pre-trained transformer-based language models, clusters these embeddings, and finally, generates topic representations with the class-based TF-IDF procedure. BERTopic generates coherent topics and remains competitive across a variety of benchmarks involving classical models and those that follow the more recent clustering approach of topic modeling.},
	urldate = {2025-03-24},
	publisher = {arXiv},
	author = {Grootendorst, Maarten},
	month = mar,
	year = {2022},
	note = {arXiv:2203.05794 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2025-03-20},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{myskova_renata_predicting_2018,
	title = {Predicting {Abnormal} {Stock} {Return} {Volatility} {Using} {Textual} {Analysis} of {News} ? {A} {Meta}-{Learning} {Approach}},
	volume = {20},
	issn = {15829146, 22479104},
	shorttitle = {Predicting {Abnormal} {Stock} {Return} {Volatility} {Using} {Textual} {Analysis} of {News} ?},
	url = {http://www.amfiteatrueconomic.ro/temp/Article_2703.pdf},
	doi = {10.24818/EA/2018/47/185},
	abstract = {Textual analysis of news articles is increasingly important in predicting stock prices. Previous research has intensively utilized the textual analysis of news and other firmrelated documents in volatility prediction models. It has been demonstrated that the news may be related to abnormal stock price behavior subsequent to their dissemination. However, previous studies to date have tended to focus on linear regression methods in predicting volatility. Here, we show that non-linear models can be effectively employed to explain the residual variance of the stock price. Moreover, we use meta-learning approach to simulate the decision-making process of various investors. The results suggest that this approach significantly improves the prediction accuracy of abnormal stock return volatility. The fact that the length of news articles is more important than news sentiment in predicting stock return volatility is another important finding. Notably, we show that Rotation forest performs particularly well in terms of both the accuracy of abnormal stock return volatility and the performance on imbalanced volatility data.},
	language = {en},
	number = {47},
	urldate = {2025-02-24},
	journal = {www.amfiteatrueconomic.ro},
	author = {Myšková, Renáta and Hġjek, Petr and {Olej, Vladimír}},
	month = feb,
	year = {2018},
	pages = {185},
}

@article{hutto_vader_2014,
	title = {{VADER}: {A} {Parsimonious} {Rule}-{Based} {Model} for {Sentiment} {Analysis} of {Social} {Media} {Text}},
	volume = {8},
	copyright = {Copyright (c) 2021 Proceedings of the International AAAI Conference on Web and Social Media},
	issn = {2334-0770},
	shorttitle = {{VADER}},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/14550},
	doi = {10.1609/icwsm.v8i1.14550},
	abstract = {The inherent nature of social media content poses serious challenges to practical applications of sentiment analysis. We present VADER, a simple rule-based model for general sentiment analysis, and compare its effectiveness to eleven typical state-of-practice benchmarks including LIWC, ANEW, the General Inquirer, SentiWordNet, and machine learning oriented techniques relying on Naive Bayes, Maximum Entropy, and Support Vector Machine (SVM) algorithms. Using a combination of qualitative and quantitative methods, we first construct and empirically validate a gold-standard list of lexical features (along with their associated sentiment intensity measures) which are specifically attuned to sentiment in microblog-like contexts. We then combine these lexical features with consideration for five general rules that embody grammatical and syntactical conventions for expressing and emphasizing sentiment intensity. Interestingly, using our parsimonious rule-based model to assess the sentiment of tweets, we find that VADER outperforms individual human raters (F1 Classification Accuracy = 0.96 and 0.84, respectively), and generalizes more favorably across contexts than any of our benchmarks.},
	language = {en},
	number = {1},
	urldate = {2025-03-20},
	journal = {Proceedings of the International AAAI Conference on Web and Social Media},
	author = {Hutto, C. and Gilbert, Eric},
	month = may,
	year = {2014},
	note = {Number: 1},
	keywords = {Human Centered Computing},
	pages = {216--225},
}

@article{bhargava_quantifying_nodate,
	title = {Quantifying {Narratives} and their {Impact} on {Financial} {Markets}},
	abstract = {This paper introduces a media-coverage-based approach to quantify narratives and develops methodologies to explain the extent to which narratives drive financial markets and returns of investment portfolios. We show that media-derived narratives may contain predictive information for market returns beyond traditional macro indicators. Finally, we demonstrate that narrative indicators can be used to enhance asset allocation strategies and to gain or hedge exposure to narratives by constructing portfolios of narrative-sensitive assets.},
	language = {en},
	author = {Bhargava, Rajeev and Lou, Xiaoxia and Ozik, Gideon and Sadka, Ronnie and Whitmore, Travis},
}

@article{bodnaruk_using_nodate,
	title = {Using 10-{K} {Text} to {Gauge} {Financial} {Constraints}},
	abstract = {Measuring the extent to which a firm is financially constrained is critical in assessing capital structure. Extant measures of financial constraints focus on macro firm characteristics such as age and size – variables highly correlated with other firm attributes. We parse 10-K disclosures filed with the SEC using a unique lexicon based on constraining words. We find that the frequency of constraining words exhibits very low correlation with traditional measures of financial constraints and predicts subsequent liquidity events—like dividend omissions or increases, equity recycling, and underfunded pensions—better than widely-used financial constraint indexes.},
	language = {en},
	author = {Bodnaruk, Andriy and Loughran, Tim and McDonald, Bill},
}

@article{loughran_when_nodate,
	title = {When is a {Liability} not a {Liability}? {Textual} {Analysis}, {Dictionaries}, and 10-{Ks}},
	abstract = {Previous research uses negative word counts to measure the tone of a text. We show that word lists developed for other disciplines misclassify common words in financial text. In a large sample of 10-Ks during 1994 to 2008, almost three-fourths of the words identified as negative by the widely used Harvard Dictionary are words typically not considered negative in financial contexts. We develop an alternative negative word list, along with five other word lists, that better reflect tone in financial text. We link the word lists to 10-K filing returns, trading volume, return volatility, fraud, material weakness, and unexpected earnings.},
	language = {en},
	author = {Loughran, Tim and Mcdonald, Bill},
}

@article{shiller_narrative_2018,
	title = {{NARRATIVE} {ECONOMICS} {AND} {NEUROECONOMICS}},
	volume = {22},
	copyright = {The authors publishing in this journal agree with the following:   Authors reserve copyright and grant the right of the first publication to the journal on the terms of the  Creative Commons Attribution License  which allows others to distribute with obligatory affiliation (an indication of links to authors and the original publication in this journal).  Authors keep the right to conclude separate contracts concerning the non-exclusive distribution of the article published here (for example, its placement in institute storage, the publication in the book), with reference to its original publication in this journal.  Authors have the right to put their article on the Internet (for example in a university storage or personal website) before and during the process of consideration by this journal as it can lead to productive discussion and a higher number of links to this article (See  The Effect of Open Access ).},
	issn = {2587-7089},
	url = {https://financetp.fa.ru/jour/article/view/616},
	doi = {10.26794/2587-5671-2018-22-1-64-91},
	abstract = {This article is a reworked lecture I have given at theFinancialUniversityunder the Government of theRussian FederationinMoscow. This lecture has considered the epidemiology of narratives relevant to economic fluctuations (outcomes), allowing them to “go viral” and spread far away, even worldwide, and thereby influencing economic outcomes. However, I had to accommodate my talk to the Russian audience adding some illustrative examples for better understanding. My basic goal in this paper is to describe what we know about narratives and the penchant of the human mind to be engaged by them, to consider reasons to expect that narratives might well be thought of as important, largely exogenous shocks to the aggregate economy. Thus, the main focus was on narratives going viral, affecting the economy in an age of neuroimaging, big data. This is because the human brain has always been highly tuned towards narratives, whether factual or not, to justify ongoing actions — even in such basic actions as spending and investing. Though these narratives are deeply human phenomena that are difficult to study in a scientific manner, quantitative analysis may help us gain a better understanding of these epidemics in the future. Many examples are seen as revealing the importance of the linkage of human brains and now computers through narratives associated with popular models of the economy and offering new research opportunities for both economics and neuroscience.},
	language = {ru},
	number = {1},
	urldate = {2025-03-12},
	journal = {Finance: Theory and Practice},
	author = {Shiller, R. I.},
	month = mar,
	year = {2018},
	note = {Number: 1
Section: ACTUAL TOPIC},
	pages = {64--91},
}

@inproceedings{vazhentsev_uncertainty_2022,
	address = {Dublin, Ireland},
	title = {Uncertainty {Estimation} of {Transformer} {Predictions} for {Misclassification} {Detection}},
	url = {https://aclanthology.org/2022.acl-long.566/},
	doi = {10.18653/v1/2022.acl-long.566},
	abstract = {Uncertainty estimation (UE) of model predictions is a crucial step for a variety of tasks such as active learning, misclassification detection, adversarial attack detection, out-of-distribution detection, etc. Most of the works on modeling the uncertainty of deep neural networks evaluate these methods on image classification tasks. Little attention has been paid to UE in natural language processing. To fill this gap, we perform a vast empirical investigation of state-of-the-art UE methods for Transformer models on misclassification detection in named entity recognition and text classification tasks and propose two computationally efficient modifications, one of which approaches or even outperforms computationally intensive methods.},
	urldate = {2025-03-04},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Vazhentsev, Artem and Kuzmin, Gleb and Shelmanov, Artem and Tsvigun, Akim and Tsymbalov, Evgenii and Fedyanin, Kirill and Panov, Maxim and Panchenko, Alexander and Gusev, Gleb and Burtsev, Mikhail and Avetisian, Manvel and Zhukov, Leonid},
	editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
	month = may,
	year = {2022},
	pages = {8237--8252},
}

@inproceedings{jean_uncertainty_2016,
	address = {Nîmes France},
	title = {Uncertainty detection in natural language: a probabilistic model},
	isbn = {978-1-4503-4056-4},
	shorttitle = {Uncertainty detection in natural language},
	url = {https://dl.acm.org/doi/10.1145/2912845.2912873},
	doi = {10.1145/2912845.2912873},
	language = {en},
	urldate = {2025-03-04},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Web} {Intelligence}, {Mining} and {Semantics}},
	publisher = {ACM},
	author = {Jean, Pierre-Antoine and Harispe, Sébastien and Ranwez, Sylvie and Bellot, Patrice and Montmain, Jacky},
	month = jun,
	year = {2016},
	pages = {1--10},
}

@phdthesis{vincze_uncertainty_2015,
	address = {Szeged, Hungary},
	type = {{PhD}},
	title = {Uncertainty {Detection} in {Natural} {Language} {Texts}},
	url = {http://doktori.bibl.u-szeged.hu/2291/},
	language = {en},
	urldate = {2025-03-04},
	school = {Szegedi Tudományegyetem},
	author = {Vincze, Veronika},
	month = jun,
	year = {2015},
	doi = {10.14232/phd.2291},
	note = {Pages: 2291},
}

@inproceedings{hu_uncertainty-aware_2021,
	title = {Uncertainty-{Aware} {Reliable} {Text} {Classification}},
	url = {http://arxiv.org/abs/2107.07114},
	doi = {10.1145/3447548.3467382},
	abstract = {Deep neural networks have significantly contributed to the success in predictive accuracy for classification tasks. However, they tend to make over-confident predictions in real-world settings, where domain shifting and out-of-distribution (OOD) examples exist. Most research on uncertainty estimation focuses on computer vision because it provides visual validation on uncertainty quality. However, few have been presented in the natural language process domain. Unlike Bayesian methods that indirectly infer uncertainty through weight uncertainties, current evidential uncertainty-based methods explicitly model the uncertainty of class probabilities through subjective opinions. They further consider inherent uncertainty in data with different root causes, vacuity (i.e., uncertainty due to a lack of evidence) and dissonance (i.e., uncertainty due to conflicting evidence). In our paper, we firstly apply evidential uncertainty in OOD detection for text classification tasks. We propose an inexpensive framework that adopts both auxiliary outliers and pseudo off-manifold samples to train the model with prior knowledge of a certain class, which has high vacuity for OOD samples. Extensive empirical experiments demonstrate that our model based on evidential uncertainty outperforms other counterparts for detecting OOD examples. Our approach can be easily deployed to traditional recurrent neural networks and fine-tuned pre-trained transformers.},
	urldate = {2025-03-04},
	booktitle = {Proceedings of the 27th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	author = {Hu, Yibo and Khan, Latifur},
	month = aug,
	year = {2021},
	note = {arXiv:2107.07114 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	pages = {628--636},
}

@inproceedings{sinha_relation_2020,
	address = {Virtual Event China},
	title = {Relation {Aware} {Attention} {Model} for {Uncertainty} {Detection} in {Text}},
	isbn = {978-1-4503-7585-6},
	url = {https://dl.acm.org/doi/10.1145/3383583.3398613},
	doi = {10.1145/3383583.3398613},
	language = {en},
	urldate = {2025-03-04},
	booktitle = {Proceedings of the {ACM}/{IEEE} {Joint} {Conference} on {Digital} {Libraries} in 2020},
	publisher = {ACM},
	author = {Sinha, Manjira and Agarwal, Nilesh and Dasgupta, Tirthankar},
	month = aug,
	year = {2020},
	pages = {437--440},
}

@article{huang_construction_2024,
	title = {Construction and {Optimization} of {Financial} {Risk} {Management} {Model} {Based} on {Financial} {Data} and {Text} {Data} {Influencing} {Information} {System}},
	volume = {9},
	issn = {2468-4376},
	url = {https://www.jisem-journal.com/article/construction-and-optimization-of-financial-risk-management-model-based-on-financial-data-and-text-14767},
	doi = {10.55267/iadt.07.14767},
	abstract = {A-share companies must manage financial risk to succeed. Textual data insights can greatly impact risk assessment results, although most risk management systems focus on quantitative financial assessments. This research constructs and enhances information system financial risk management models employing financial and textual data, including MD\&A narratives, to fill this gap. We study how textual data aids financial risk management algorithms' risk prediction. Textual and financial research on 2001–2022 Shenzhen and Shanghai Stock Exchange companies is used. This study found financial and non-financial data models more predictive. Qualitative textual information is used in financial risk assessment to improve risk prediction algorithms. MD\&A texts, sentiment analysis, and readability signal risk. Internet forum discussions are linked to financial risk, but media coverage is not. These unconventional data sources evaluate financial risk. The research shows that A-share corporations manage financial risk. The study advises merging qualitative textual data with financial metrics to solve literature gaps and improve risk management. Shenzhen and Shanghai Stock Exchange statistics suggest MD\&A storylines might strengthen financial risk management models. Study shows readability and sentiment analysis increase risk model prediction. The study found that textual material affects financial risk, therefore risk assessment should include non-financial information. This complete risk management technique may assist A-share listed companies navigate financial markets and make smarter decisions using quantitative financial data and qualitative textual insights. This study implies textual data may help financial risk algorithms. MD\&As help companies identify and manage financial risk. More study is needed to discover new textual elements and strengthen context-specific risk management frameworks.},
	language = {en},
	number = {2},
	urldate = {2025-02-26},
	journal = {Journal of Information Systems Engineering and Management},
	author = {Huang, Hui and Lim, Thien Sang},
	month = apr,
	year = {2024},
	pages = {24534},
}

@article{fedorova_impact_2021,
	title = {Impact of news sentiment and topics on {IPO} underpricing: {US} evidence},
	volume = {30},
	issn = {1834-7649},
	shorttitle = {Impact of news sentiment and topics on {IPO} underpricing},
	url = {https://doi.org/10.1108/IJAIM-06-2021-0117},
	doi = {10.1108/IJAIM-06-2021-0117},
	abstract = {Purpose The goal of the study is to examine the effects of news sentiment and topics dominating in the news field prior to the initial public offering (IPO) on the IPO underpricing. Design/methodology/approach The authors’ approach has several steps. The first is textual analysis. To detect the dominating topics in the news, the authors use Latent Dirichlet allocation. The authors use bidirectional encoder representations from transformers (BERT) pretrained on financial news corpus to evaluate the tonality of articles. The second is evaluation of feature importance. To this end, a linear regression with robust estimators and Classification and Regression Tree and Random Forest are used. The third is data. The text data consists of 345,731 news articles from Thomson Reuters related to the USA in the date range from 1 January 2011 to 31 May 2018. The data contains all the possible topics from the website, excluding anything related to sports. The sample of 386 initial public offerings completed in the USA from 1 January 2011 to 31 May 2018 was collected from Bloomberg Database. Findings The authors found that sentiment of the media regarding the companies going public influences IPO underpricing. Some topics, namely, the climate change and environmental policies and the trade war between the US and China, have influence on IPO underpricing if they appear in the media prior to the IPO day. Originality/value The puzzle of IPO underpricing is studied from the point of Narrative Economics theory for the first time. While most of the works cover only some specific news segment, we use Thomson Reuters news aggregator, which uses such sources The New York Post, CNN, Fox, Atlantic, The Washington Post ? Buzzfeed. To evaluate the sentiment of the articles, a state-of-the-art approach BERT is used. The hypothesis that some common narratives or topics in the public discussion may impose influence on such example of biased behaviour like IPO underpricing has also found confirmation.},
	number = {1},
	urldate = {2025-02-24},
	journal = {International Journal of Accounting \& Information Management},
	author = {Fedorova, Elena and Druchok, Sergei and Drogovoz, Pavel},
	month = jan,
	year = {2021},
	note = {Publisher: Emerald Publishing Limited},
	keywords = {BERT, CART, IPO underpricing, Narrative economics, News sentiment, News topics, Textual analysis, USA market},
	pages = {73--94},
}

@article{alan_impact_2023,
	title = {Impact of {Language} {Complexity} on {Volatility} in {Financial} {Markets}: {Evidence} from {Textual} {Analysis} of {Earnings} {Calls}},
	volume = {50},
	issn = {0095-4918, 2168-8656},
	shorttitle = {Impact of {Language} {Complexity} on {Volatility} in {Financial} {Markets}},
	url = {http://pm-research.com/lookup/doi/10.3905/jpm.2023.1.558},
	doi = {10.3905/jpm.2023.1.558},
	language = {en},
	number = {2},
	urldate = {2025-02-24},
	journal = {The Journal of Portfolio Management},
	author = {Alan, Nazli Sila and Engle, Robert F. and Karagozoglu, Ahmet K.},
	month = nov,
	year = {2023},
	pages = {27--57},
}

@article{gilliam_frameworks_2017,
	title = {Frameworks for consumers’ narratives in a changing marketplace: {Banking} and the financial crisis},
	volume = {35},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0263-4503},
	shorttitle = {Frameworks for consumers’ narratives in a changing marketplace},
	url = {https://www.emerald.com/insight/content/doi/10.1108/MIP-01-2017-0005/full/html},
	doi = {10.1108/MIP-01-2017-0005},
	abstract = {Purpose – Narratives are central to consumers’ understanding of brands especially during change. The financial crisis that began in 2008 offered a changing marketplace from which to develop two managerially useful frameworks of consumer narratives. The paper aims to discuss these issues.},
	language = {en},
	number = {7},
	urldate = {2025-02-24},
	journal = {Marketing Intelligence \& Planning},
	author = {Gilliam, David A. and Preston, Teresa and Hall, John R.},
	month = sep,
	year = {2017},
	pages = {892--906},
}

@article{ying_application_2020,
	title = {Application of text mining in identifying the factors of supply chain financing risk management},
	volume = {121},
	copyright = {https://www.emerald.com/insight/site-policies},
	issn = {0263-5577},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IMDS-06-2020-0325/full/html},
	doi = {10.1108/IMDS-06-2020-0325},
	abstract = {Purpose – This study aims to clarify the risk management practices of banks as supply chain finance (SCF) service providers. Design/methodology/approach – Using 4,014 evaluation and approval reports, this study constructed five risk management factors and examined their functions with secondary data. Two text-mining techniques (i.e. word sense induction, TF–IDF) were used to equip the classic routine of dictionary-based content analysis.},
	language = {en},
	number = {2},
	urldate = {2025-02-24},
	journal = {Industrial Management \& Data Systems},
	author = {Ying, Hao and Chen, Lujie and Zhao, Xiande},
	month = nov,
	year = {2020},
	pages = {498--518},
}

@article{groth_intraday_2011,
	title = {An intraday market risk management approach based on textual analysis},
	volume = {50},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923610001430},
	doi = {10.1016/j.dss.2010.08.019},
	language = {en},
	number = {4},
	urldate = {2025-02-24},
	journal = {Decision Support Systems},
	author = {Groth, Sven S. and Muntermann, Jan},
	month = mar,
	year = {2011},
	pages = {680--691},
}

@article{chong_constructing_2015,
	title = {Constructing conviction through action and narrative: how money managers manage uncertainty and the consequence for financial market functioning},
	volume = {13},
	issn = {1475-1461},
	shorttitle = {Constructing conviction through action and narrative},
	url = {https://doi.org/10.1093/ser/mwu020},
	doi = {10.1093/ser/mwu020},
	abstract = {Financial assets are abstract entities. Their value depends on beliefs which are inherently social and, we argue, emotional. Recent events have revealed profound uncertainty at the heart of financial markets, the manifest existence of emotion and the way confidence is crucial to orderly market functioning. Using findings from two interview studies, supported by ethnographic observation, we elaborate on the irreducible cognitive and emotional conflicts which face actors engaged in financial markets and threaten their daily operations. We introduce the term conviction narrative to analyse how they manage these conflicts on a day-to-day basis, and with what collective consequences. Our thesis is that expertise and conviction in financial markets have constantly to be created and renewed through a combination of psychological and social action with the implication at the macro level that while financial markets can be orderly they are so in an intrinsically fragile way.},
	number = {2},
	urldate = {2025-02-24},
	journal = {Socio-Economic Review},
	author = {Chong, Kimberly and Tuckett, David},
	month = apr,
	year = {2015},
	pages = {309--330},
}

@article{wisniewski_stock_2015,
	title = {Stock market returns and the content of annual report narratives},
	volume = {39},
	issn = {0155-9982},
	url = {https://doi.org/10.1016/j.accfor.2015.09.001},
	doi = {10.1016/j.accfor.2015.09.001},
	abstract = {This paper uses the tools of computational linguistics to analyze the qualitative part of annual reports of UK listed companies. More specifically, the frequency of words associated with different language indicators is used to forecast future stock returns. We find that two of these indicators, capturing ‘activity’ and ‘realism’, predict subsequent price increases, even after controlling for a wide range of factors. Elevated values of these two linguistic variables, however, are not symptomatic of exacerbated risk. Consequently, investors are advised to peruse annual report narratives, as they contain valuable information that may not yet have been discounted in the prices.},
	number = {4},
	urldate = {2025-02-24},
	journal = {Accounting Forum},
	author = {Wisniewski, Tomasz Piotr and Yekini, Liafisu Sina},
	month = dec,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1016/j.accfor.2015.09.001},
	keywords = {Annual reports, Content analysis, G12, G14, M41, Stock market returns},
	pages = {281--294},
}

@article{caporin_building_2017,
	title = {Building {News} {Measures} from {Textual} {Data} and an {Application} to {Volatility} {Forecasting}},
	volume = {5},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2225-1146},
	url = {https://www.mdpi.com/2225-1146/5/3/35},
	doi = {10.3390/econometrics5030035},
	abstract = {We retrieve news stories and earnings announcements of the S\&P 100 constituents from two professional news providers, along with ten macroeconomic indicators. We also gather data from Google Trends about these firms’ assets as an index of retail investors’ attention. Thus, we create an extensive and innovative database that contains precise information with which to analyze the link between news and asset price dynamics. We detect the sentiment of news stories using a dictionary of sentiment-related words and negations and propose a set of more than five thousand information-based variables that provide natural proxies for the information used by heterogeneous market players. We first shed light on the impact of information measures on daily realized volatility and select them by penalized regression. Then, we perform a forecasting exercise and show that the model augmented with news-related variables provides superior forecasts.},
	language = {en},
	number = {3},
	urldate = {2025-02-24},
	journal = {Econometrics},
	author = {Caporin, Massimiliano and Poli, Francesco},
	month = sep,
	year = {2017},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Google Trends, big data, lasso, news, regularization, sentiment analysis, volatility},
	pages = {35},
}

@article{zhao_forecasting_2019,
	title = {Forecasting {Oil} {Price} {Volatility} in the {Era} of {Big} {Data}: {A} {Text} {Mining} for {VaR} {Approach}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2071-1050},
	shorttitle = {Forecasting {Oil} {Price} {Volatility} in the {Era} of {Big} {Data}},
	url = {https://www.mdpi.com/2071-1050/11/14/3892},
	doi = {10.3390/su11143892},
	abstract = {The rapid fluctuations in global crude oil prices are one of the important factors affecting both the sustainable development and the green transformation of the global economy. To accurately measure the risks of crude oil prices, in the context of big data, this study introduces the two-layer non-negative matrix factorization model, a kind of natural language processing, to extract the dynamic risk factors from online news and assign them as weighted factors to historical data. Finally, this study proposes a giant information history simulation (GIHS) method which is used to forecast the value-at-risk (VaR) of crude oil. In conclusion, this paper shows that considering the impact of dynamic risk factors from online news on the VaR can improve the accuracy of crude oil VaR measurement, providing an effective tool for analyzing crude oil price risks in oil market, providing risk management support for international oil market investors, and providing the country with a sense of risk analysis to achieve sustainable and green transformation.},
	language = {en},
	number = {14},
	urldate = {2025-02-24},
	journal = {Sustainability},
	author = {Zhao, Lu-Tao and Liu, Li-Na and Wang, Zi-Jie and He, Ling-Yun},
	month = jan,
	year = {2019},
	note = {Number: 14
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {VaR, big data, natural language processing, oil price volatility, risk identification, two-layer non-negative matrix factorization},
	pages = {3892},
}

@article{li_credit_2021,
	title = {Credit risk management of scientific and technological enterprises based on text mining},
	volume = {15},
	issn = {1751-7575},
	url = {https://doi.org/10.1080/17517575.2020.1802514},
	doi = {10.1080/17517575.2020.1802514},
	abstract = {The purpose of this paper is to verify the impact of financial news on corporate credit risk. Web crawler technology is used to obtain the financial news text from Sina Financial News. The text mining technology is utilized to quantify the financial news text. The quantified financial news text combined with financial indicators is used to build the Logistic regression model. The assessment results show that the risk early warning accuracy of the Logistic regression model incorporating both the quantified financial news text and financial indicators is higher than the Logistic regression model only with pure financial indicators.},
	number = {6},
	urldate = {2025-02-24},
	journal = {Enterprise Information Systems},
	author = {Li, Chenggang and Liu, Qing and Huang, Lei},
	month = jul,
	year = {2021},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/17517575.2020.1802514},
	keywords = {Scientific and technological enterprises, credit risk, logistic regression model, text mining, web crawler},
	pages = {851--867},
}

@article{bertsch_narrative_2021,
	title = {Narrative fragmentation and the business cycle},
	volume = {201},
	issn = {01651765},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176521000604},
	doi = {10.1016/j.econlet.2021.109783},
	abstract = {According to Shiller (2017), economic and financial narratives often emerge as a consequence of their virality, rather than their veracity, and constitute an important, but understudied driver of aggregate fluctuations. Using a unique dataset of newspaper articles over the 1950–2019 period and state-ofthe-art methods from natural language processing, we characterize the properties of business cycle narratives. Our main finding is that narratives tend to consolidate around a dominant explanation during expansions and fragment into competing explanations during contractions. We also show that the existence of past reference events is strongly associated with increased narrative consolidation.},
	language = {en},
	urldate = {2025-02-24},
	journal = {Economics Letters},
	author = {Bertsch, Christoph and Hull, Isaiah and Zhang, Xin},
	month = apr,
	year = {2021},
	pages = {109783},
}

@article{ackert_homeownership_2021,
	title = {Homeownership for {All}: {An} {American} {Narrative}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1911-8074},
	shorttitle = {Homeownership for {All}},
	url = {https://www.mdpi.com/1911-8074/14/6/240},
	doi = {10.3390/jrfm14060240},
	abstract = {The narrative of homeownership for all citizens is a uniquely American story. Narrative economics is a field that studies the spread of stories to explain economic fluctuations. We quantitatively examine the relationship between the American housing narrative and the run-up in home prices experienced since the Great Recession in the United States. We rely on a natural language processing (NLP) framework to measure the sentiment associated with the narrative. We then use a panel vector autoregression to empirically model the relationship between home prices and homeownership sentiment in the United States. We find that sentiment related to the American homeownership narrative is an important factor in explaining movements in home prices even after taking into account the economic factors typically thought to explain home price fluctuations. Though others have examined the role of sentiment in markets, our study is the first to empirically measure the American homeownership narrative. While this is a narrative promoted at the national level, future research might examine whether sentiment related to homeownership varies across this diverse nation.},
	language = {en},
	number = {6},
	urldate = {2025-02-24},
	journal = {Journal of Risk and Financial Management},
	author = {Ackert, Lucy F. and Mazzotta, Stefano},
	month = jun,
	year = {2021},
	note = {Number: 6
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {home prices, homeownership, narrative economics, sentiment},
	pages = {240},
}

@article{paugam_deploying_2021,
	title = {Deploying {Narrative} {Economics} to {Understand} {Financial} {Market} {Dynamics}: {An} {Analysis} of {Activist} {Short} {Sellers}' {Rhetoric}},
	volume = {38},
	copyright = {© CAAA},
	issn = {1911-3846},
	shorttitle = {Deploying {Narrative} {Economics} to {Understand} {Financial} {Market} {Dynamics}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1911-3846.12660},
	doi = {10.1111/1911-3846.12660},
	abstract = {We investigate how activist short sellers (AShSs) expose publicly listed firms in an increasingly popular form of “research reports” openly denouncing alleged frauds, flawed business models, accounting irregularities, and wrongdoings. We focus on six AShSs that issued research reports that often led to a strong negative market reaction. Our empirical analysis exploits both qualitative and quantitative methods for a comprehensive data set of 383 research reports targeting 171 unique firms, and 3 firsthand interviews with AShSs. Drawing on Aristotle's rhetoric, we first examine how AShSs use narratives in striving to convince other investors that the target firms are overvalued. Specifically, we search the documents produced by AShSs for stylized narratives related to credibility-based (ethos), emotions-based (pathos), and logic-based (logos) rhetorical strategies. To assess the impact of these strategies, we examine the extent to which the AShSs' rhetorical strategies resonate in 3,665 press articles. As expected, the press often refers to logos-based arguments. Interestingly, the press also frequently brings up pathos-based and ethos-based statements. Considering the importance of the press in shaping investors' opinions, our study points to AShSs' narratives playing a major role in policing financial markets. Theoretically, we show that AShSs, as dissenting market participants, produce narratives that go beyond the language of formal rationality—as they strive to reveal new information and frame it persuasively, in order to destabilize the extent of trustworthiness surrounding target firms.},
	language = {en},
	number = {3},
	urldate = {2025-02-24},
	journal = {Contemporary Accounting Research},
	author = {Paugam, Luc and Stolowy, Hervé and Gendron, Yves},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1911-3846.12660},
	keywords = {activist short sellers, credibility, crédibilité, narrative economics, persuasion, rhetorical strategies, stratégies rhétoriques, vendeurs à découvert activistes, économie des récits},
	pages = {1809--1848},
}

@article{hsu_narrative_2021,
	title = {Narrative economics using textual analysis of newspaper data: new insights into the {U}.{S}. {Silver} {Purchase} {Act} and {Chinese} price level in 1928–1936},
	volume = {4},
	issn = {2432-2725},
	shorttitle = {Narrative economics using textual analysis of newspaper data},
	url = {https://doi.org/10.1007/s42001-021-00104-0},
	doi = {10.1007/s42001-021-00104-0},
	abstract = {In light of the recent advancement in economic narrative analysis, we develop a computational textual analysis method to study economic history. In this method, we collect narrative data from newspapers to measure economic trends. In particular, the popularity (frequency) of a narrative (keyword) on the newspapers is used as the proxy of the amount of economic activities associated with the narrative term; a high frequency indicates that there is a high volume of economic activities associated with the narrative term and vice versa. Regularized regression algorithms are then applied on the narrative frequency data to identify narrative terms whose associated microeconomic activities have macroeconomic impact. We apply the method to study a classic topic in Chinese economic history research: U.S. Silver Purchase Act and the Chinese price level in 1928–1936. Our results provide new insights into this controversial subject. For example, we find that the economic activity associated with the narrative term silver stock had no impact on the Chinese price level, which is contrary to previous research on the topic by Friedman and Schwartz [10]. Meanwhile, economic activities associated with the narrative terms U.S. silver purchase act and silver export are found to have a negative impact on the Chinese price level. This suggests the concerns at that time about the effects of U.S. Silver Purchase Act on the Chinese economy were not misplaced.},
	language = {en},
	number = {2},
	urldate = {2025-02-24},
	journal = {Journal of Computational Social Science},
	author = {Hsu, Ching and Yu, Tina and Chen, Shu-Heng},
	month = nov,
	year = {2021},
	keywords = {Chinese monetary policy, Economic history, Narrative economics, Regularized regression algorithms, Textual analysis, U.S. silver purchase act},
	pages = {761--785},
}

@article{lei_stock_2021,
	title = {On stock volatility forecasting based on text mining and deep learning under high-frequency data},
	volume = {40},
	copyright = {© 2021 John Wiley \& Sons, Ltd.},
	issn = {1099-131X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.2794},
	doi = {10.1002/for.2794},
	abstract = {Few existing literatures used the text information of the public opinions as the input index for volatility forecasting. This paper uses the text comment information of stockholders to construct a text sentiment factor that integrates the influence of comments and then combines other transaction information on volatility forecasting based on high-frequency finance data with the deep learning model long short-term memory (LSTM). The study finds that under the framework of the LSTM model, the forecasting accuracy for the volatility with the sentiment index is better than that of the LSTM model without the sentiment index and 10 traditional econometric models under the six loss functions. When compared with the traditional econometric model for multistep forecasting, the LSTM model is robust. With the addition of the public opinion index, the accuracy of LSTM is improved by 9.3\%, 4.7\%, 6.2\%, 9.2\%, 7.9\%, and 16.9\%, respectively, under the six evaluation criteria. The research in this article provides a more accurate, robust, and sustainable method for volatility forecasting in the context of big data.},
	language = {en},
	number = {8},
	urldate = {2025-02-24},
	journal = {Journal of Forecasting},
	author = {Lei, Bolin and Liu, Zhengdi and Song, Yuping},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.2794},
	keywords = {LSTM model, high-frequency financial data, realized volatility, sentiment factor, text information},
	pages = {1596--1610},
}

@article{chen_covid_2022,
	title = {{COVID} risk narratives: a computational linguistic approach to the econometric identification of narrative risk during a pandemic},
	volume = {4},
	issn = {2524-6186},
	shorttitle = {{COVID} risk narratives},
	url = {https://doi.org/10.1007/s42521-021-00045-3},
	doi = {10.1007/s42521-021-00045-3},
	abstract = {In this paper, we study the role of narratives in stock markets with a particular focus on the relationship with the ongoing COVID-19 pandemic. The pandemic represents a natural setting for the development of viral financial market narratives. We thus treat the pandemic as a natural experiment on the relation between prevailing narratives and financial markets. We adopt natural language processing (NLP) on financial news to characterize the evolution of important narratives. Doing so, we reduce the high-dimensional narrative information to few interpretable and important features while avoiding over-fitting. In addition to the common features, we consider virality as a novel feature of narratives, inspired by Shiller (Am Econ Rev 107:967–1004, 2017). Our aim is to establish whether the prevailing narratives drive or are driven by stock market conditions. Focusing on the coronavirus narratives, we document some stylized facts about its evolution around a severe event-driven stock market decline. We find the pandemic-relevant narratives are influenced by stock market conditions and act as a cellar for brewing a perennial economic narrative. We successfully identified a perennial risk narrative, whose shock is followed by a severe market drop and a long-term increase of market volatility. In the out-of-sample test, this narrative went viral since the start of the global COVID-19 pandemic, when the pandemic-relevant narratives dominate news media, show negative sentiment and were more linked to “crisis” context. Our findings encourage the use of narratives to evaluate long-term market conditions and to early warn event-driven severe market declines.},
	language = {en},
	number = {1},
	urldate = {2025-02-24},
	journal = {Digital Finance},
	author = {Chen, Yuting and Bredin, Don and Potì, Valerio and Matkovskyy, Roman},
	month = mar,
	year = {2022},
	keywords = {C53, COVID-19, D81, E37, E71, Early warning indicator, G17, G41, Narrative economics, Natural language processing, Tone analysis},
	pages = {17--61},
}

@article{mazzotta_immigration_2022,
	title = {Immigration narrative sentiment from {TV} news and the stock market},
	volume = {34},
	issn = {22146350},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214635022000259},
	doi = {10.1016/j.jbef.2022.100666},
	abstract = {Often debated in the media, immigration is a contentious topic in the U.S. Shiller (2017), and Shiller (2019) posit that narratives can drive economics events. This paper investigates the relationship between the immigration narrative sentiment and the stock market using the sentiment extracted from of 1.3 million TV news transcripts. Results from Panel Vector Auto Regression (PVAR) estimations show that the immigration narrative sentiment is related to stock market indicators. A positive shock to the immigration narrative sentiment Granger-causes a statistically significant and economically meaningful increase in the stock prices, a decrease in implied volatility, and a statistically significant but economically small increase in trade volume. However, stock market variation does not affect the immigration narrative sentiment. The effect of the immigration narrative sentiment shock to market indicators is long lasting suggesting that the immigration narrative likely contains fundamental information about equities that has not been priced.},
	language = {en},
	urldate = {2025-02-24},
	journal = {Journal of Behavioral and Experimental Finance},
	author = {Mazzotta, Stefano},
	month = jun,
	year = {2022},
	pages = {100666},
}

@article{stolowy_competing_2022,
	title = {Competing for narrative authority in capital markets: {Activist} short sellers vs. financial analysts},
	volume = {100},
	issn = {03613682},
	shorttitle = {Competing for narrative authority in capital markets},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0361368222000010},
	doi = {10.1016/j.aos.2022.101334},
	abstract = {Activist short sellers (AShSs) and ﬁnancial analysts are information intermediaries who analyze ﬁrm disclosures as well as produce and disseminate inﬂuential investment narratives. This study aims to better understand narrative challenges surrounding the legitimate expertise of ﬁnancial analysts. Speciﬁcally, we examine how AShSs challenge sell-side ﬁnancial analysts' narrative authority (i.e., the perception that they produce expert knowledge) in interpreting ﬁrms' performance and future prospects. We investigate how analysts respond (or do not respond) to this challenge. We use 442 AShS reports, 12 interviews with AShSs and analysts, and analysts' stock recommendations and target prices. In their criticisms of analysts (found in one-third of reports), AShSs frequently frame analysts as lacking market expertise and critical thinking e two core dimensions of analysts' narrative authority. Sixty-six percent of analysts, although explicitly criticized in AShS reports, do not engage in written responses in their equity research reports because they reportedly either adopt a renunciation attitude to the challenge or they engage in off-the-record discussions with certain market participants. However, 34\% of analysts respond overtly by counter-framing AShSs as lacking market expertise and objectivity. After the dissemination of AShS reports, analysts, on average, do not revise their highly visible stock recommendations but they revise target prices downward. Theoretically, this study extends our understanding of the construction of narrative authority in capital markets as we examine a challenge to the expertise of inﬂuential information intermediaries.},
	language = {en},
	urldate = {2025-02-24},
	journal = {Accounting, Organizations and Society},
	author = {Stolowy, Hervé and Paugam, Luc and Gendron, Yves},
	month = jul,
	year = {2022},
	pages = {101334},
}

@article{ferguson-cradler_narrative_2023,
	title = {Narrative and computational text analysis in business and economic history},
	volume = {71},
	issn = {0358-5522},
	url = {https://www.tandfonline.com/doi/full/10.1080/03585522.2021.1984299},
	doi = {10.1080/03585522.2021.1984299},
	number = {2},
	urldate = {2025-02-24},
	journal = {Scandinavian Economic History Review},
	author = {Ferguson-Cradler, Gregory},
	month = may,
	year = {2023},
	note = {Publisher: Routledge},
	keywords = {Narrative, digital humanities, machine learning, natural language processing, topic models},
	pages = {103--127},
}

@article{zhu_sentiment_2023,
	title = {A {Sentiment} {Index} of the {Housing} {Market} in {China}: {Text} {Mining} of {Narratives} on {Social} {Media}},
	volume = {66},
	issn = {1573-045X},
	shorttitle = {A {Sentiment} {Index} of the {Housing} {Market} in {China}},
	url = {https://doi.org/10.1007/s11146-022-09900-5},
	doi = {10.1007/s11146-022-09900-5},
	abstract = {Many efforts have been made to investigate the sentiment in financial and commercial real estate markets, but only a few studies focus on residential markets because of the lack of appropriate sentiment measuring approaches. In this study, we utilize social media narratives to build sentiment indexes for the housing market in China, where house-price-related narratives are abundantly documented on social media. With the help of the latest text analysis technologies from the deep learning and natural language processing fields, our indexes are built on a solid basis for understanding the semantic meanings of textual data. Highlighting the semantic temporality of text, we build separate future and past sentiment indexes to capture people’s prior beliefs and posterior feelings about price movements, respectively. The future sentiment index could serve as an alternative to survey-based expectations, measure the impacts of policies on people’s beliefs, and have remarkable power in predicting the future movements of both listed developers’ stock prices and house prices.},
	language = {en},
	number = {1},
	urldate = {2025-02-24},
	journal = {The Journal of Real Estate Finance and Economics},
	author = {Zhu, Enwei and Wu, Jing and Liu, Hongyu and Li, Keyang},
	month = jan,
	year = {2023},
	keywords = {Deep learning, Housing market, Market sentiment, Narrative economics, Social media, Text mining},
	pages = {77--118},
}

@article{borup_quantifying_2023,
	title = {Quantifying investor narratives and their role during {COVID}-19},
	volume = {38},
	copyright = {© 2023 John Wiley \& Sons, Ltd.},
	issn = {1099-1255},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.2964},
	doi = {10.1002/jae.2964},
	abstract = {This paper elicits and quantifies narratives from open-ended surveys sent daily to US stockholders during the first wave of the COVID-19 pandemic. Using textual analysis, we extract 13 narratives and measure their prevalence over time. A validation analysis confirms the behavioral and economic relevance of the retrieved narratives. Moreover, we find that the narratives contain predictive information for future excess stock and bond returns, and this predictability remains when controlling for contemporaneous information stemming from news and social media. Finally, we find evidence that political identity is reflected in the narrative tone.},
	language = {en},
	number = {4},
	urldate = {2025-02-24},
	journal = {Journal of Applied Econometrics},
	author = {Borup, Daniel and Hansen, Jorge Wolfgang and Liengaard, Benjamin Dybro and Montes Schütte, Erik Christian},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jae.2964},
	keywords = {COVID-19, latent Dirichlet allocation, narrative economics, textual analysis},
	pages = {512--532},
}

@article{tarim_american_2023,
	title = {The {American} spirit: {The} performativity of folk economics in global financial markets},
	volume = {55},
	issn = {0308-518X},
	shorttitle = {The {American} spirit},
	url = {https://doi.org/10.1177/0308518X231169738},
	doi = {10.1177/0308518X231169738},
	abstract = {Inspired by Austin's conceptualisation of utterances as performative, that is, they do things rather than merely represent, research has shown how scientific theories can become performative in financial markets. Research also shows that brokerage and investment work is as much about using everyday knowledge of markets as it is about performing scientific theories. We investigate whether and how this knowledge or what Swedberg calls ‘folk economics’ can also be performative. We focus on Borsa Istanbul, an emerging market where market actors perform what we call ‘the American Spirit’ – a ubiquitous folk theory that frames and plots the Turkish market as one that moves in tandem with American and other developed markets – and in the process become better market forecasters. Our findings have implications for the study of folk economics and performativity in global economy and finance.},
	language = {en},
	number = {8},
	urldate = {2025-02-24},
	journal = {Environment and Planning A: Economy and Space},
	author = {Tarim, Emre and Gozluklu, Arie and Muradoglu, Gulnur},
	month = nov,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd},
	pages = {1906--1927},
}

@article{miori_narratives_2024,
	title = {Narratives from {GPT}-derived networks of news and a link to financial markets dislocations},
	issn = {2364-4168},
	url = {https://doi.org/10.1007/s41060-024-00516-x},
	doi = {10.1007/s41060-024-00516-x},
	abstract = {We introduce a novel framework to study the dynamics of news narratives, by leveraging GPT3.5 advanced text analysis capabilities and graph theory. In particular, we focus on a corpus of economic articles from The Wall Street Journal and dynamically extract the main topics of discussion over time, in a completely systematic and scalable fashion. As a simple application of the suggested approach, we show how the structure of such topics of discussion has a statistically significant relationship with the contemporaneous state of financial markets, which can be used to construct an investment strategy or monitor financial risks. Our work is based on the intrinsic ability of GPT models to track the context of sentences within a document, thanks to which we can accurately extract a ranking of the most important entities discussed within each article, and evaluate their entity-specific sentiments. Then, we create a graph for each week of data, in which nodes are the entities retrieved and edges are built from the co-occurrence of such entities within articles. Graph centrality measures are computed over time to track the most representative keywords of topics of discussion, which result in an accurate summary view of the evolution of economic narratives. Fuzzy community detection is finally used to cluster linked entities into a more detailed representation of topics. Such groups of entities are mapped to the related journal articles, which are in turn summarised to reach a highly nuanced and interpretable view of the topics discussed within each week. Linking the features of these topics to the relevant financial market time series, we find that high fragmentation within our networks’ communities relates to moments of financial markets dislocations (i.e. dates with unusually high volatility across asset classes). This result should thus motivate stronger effort within financial research to move beyond ubiquitous sentiment analysis of news and delve deeper into broader and more holistic studies of textual data.},
	language = {en},
	urldate = {2025-02-24},
	journal = {International Journal of Data Science and Analytics},
	author = {Miori, Deborah and Petrov, Constantin},
	month = mar,
	year = {2024},
	keywords = {Artificial Intelligence, Large Language Models, Market dislocations, Network analysis},
}

@article{roos_narratives_2024,
	title = {Narratives in economics},
	volume = {38},
	copyright = {© 2023 The Authors. Journal of Economic Surveys published by John Wiley \& Sons Ltd.},
	issn = {1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12576},
	doi = {10.1111/joes.12576},
	abstract = {There is growing awareness within the economics profession of the important role narratives play in the economy. Even though empirical approaches that try to quantify economic narratives are getting increasingly popular, there is no theory or even a universally accepted definition of economic narratives underlying this research. First, we review and categorize the economic literature concerned with narratives and work out the different paradigms at play. Only a subset of the literature considers narratives to be active drivers of economic activity. To solidify the foundation of narrative economics, we propose a definition of collective economic narratives, isolating five important characteristics. We argue that, for a narrative to be economically relevant, it must be a sense-making story that emerges in a social context and suggests action to a social group. We also systematize how a collective economic narrative differs from a topic and from other kinds of narratives that are likely to have less impact on the economy. With regard to the popular use of topic modeling, we suggest that the complementary use of other methods from the natural language processing (NLP) toolkit and the development of new methods is inevitable to go beyond identifying topics and move towards true empirical narrative economics.},
	language = {en},
	number = {2},
	urldate = {2025-02-24},
	journal = {Journal of Economic Surveys},
	author = {Roos, Michael and Reccius, Matthias},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12576},
	keywords = {NLP, complexity economics, narrative economics, narrative turn, text as data},
	pages = {303--341},
}

@article{ma_stock_2024,
	title = {Stock return predictability using economic narrative: {Evidence} from energy sectors},
	volume = {35},
	issn = {24058513},
	shorttitle = {Stock return predictability using economic narrative},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405851324000370},
	doi = {10.1016/j.jcomm.2024.100418},
	abstract = {This paper applies the Narrative-based Energy General Index (NEG) to forecast stock returns in the energy industry. The index is constructed using natural language processing (NLP) techniques applied to news topics from The Wall Street Journal. The results indicate that NEG outperforms in predicting future returns of the energy industry in both in-sample and out-of-sample, and the predictive power surpasses that of other macroeconomic variables. The asset allocation exercise demonstrates the substantial economic value of NEG. Furthermore, we document that NEG not only exhibits superior predictive power for energy sector returns but also provides valuable insights for the whole stock market.},
	language = {en},
	urldate = {2025-02-24},
	journal = {Journal of Commodity Markets},
	author = {Ma, Tian and Li, Ganghui and Zhang, Huajing},
	month = sep,
	year = {2024},
	pages = {100418},
}

@article{mazzotta_immigration_2024,
	title = {Immigration {Narrative} and {Home} {Prices}},
	volume = {43},
	issn = {22146350},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2214635024000741},
	doi = {10.1016/j.jbef.2024.100959},
	abstract = {This study characterizes the relationship between U.S. National Home Prices and Immigration Narrative as portrayed on TV news. Integrating Narrative Economics and Natural Language Processing (NLP) sentiment analysis, I analyze a large dataset of 1.96 million TV news transcripts spanning July 2009 to December 2023 to capture the sentiment of the Immigration Narrative. Immigration Narrative Sentiment and U.S. Home Prices are associated. One standard deviation orthogonalized shock to the sentiment Granger-causes a statistically significant and economically meaningful increase in the Case–Shiller U.S. National Home Price. The cumulative increase is equivalent to about 26 percent of the average monthly change during the sample period. Moreover, the effect of a shock to the Immigration Narrative Sentiment on Home Prices is permanent, suggesting that the Immigration Narrative contains fundamental information about Home Prices not captured by standard economic variables. Conversely, there is no evidence that Home Price variation affects Immigration Narrative.},
	language = {en},
	urldate = {2025-02-24},
	journal = {Journal of Behavioral and Experimental Finance},
	author = {Mazzotta, Stefano},
	month = sep,
	year = {2024},
	pages = {100959},
}

@article{amato_how_2024,
	title = {How can artificial intelligence help customer intelligence for credit portfolio management? {A} systematic literature review},
	volume = {4},
	issn = {26670968},
	shorttitle = {How can artificial intelligence help customer intelligence for credit portfolio management?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2667096824000235},
	doi = {10.1016/j.jjimei.2024.100234},
	language = {en},
	number = {2},
	urldate = {2025-02-14},
	journal = {International Journal of Information Management Data Insights},
	author = {Amato, Alessandra and Osterrieder, Joerg R. and Machado, Marcos R.},
	month = nov,
	year = {2024},
	pages = {100234},
}

@article{gan_sensitivity_2020,
	title = {Sensitivity to sentiment: {News} vs social media},
	volume = {67},
	issn = {10575219},
	shorttitle = {Sensitivity to sentiment},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S105752191930273X},
	doi = {10.1016/j.irfa.2019.101390},
	abstract = {We explore the rapidly changing social and news media landscape that is responsible for the dissemination of information vital to the eﬃcient functioning of the ﬁnancial markets. Using the sheer volume of social and news media activity, commonly known as buzz, we document three distinct regimes. We ﬁnd that between 2011 and 2013 the news media coverage stimulates activity in social media. This is followed by a transition period of two-way causality. From 2016, however, changes in levels of social media activity seem to lead and generate news coverage volumes. We uncover similar evolution of lead-lag pattern between sentiment measures constructed from the tonality contained in textual data from social and news media posts. We discover that market variables exert stronger impact on investor sentiment than the other way around. We also ﬁnd that return responses to social media sentiment almost doubled after the transition period, while return responses to news-based sentiment almost halved to its pre-transition level. The linkage between volatility and sentiment is much more persistent than that between returns and sentiment. Overall, our results suggest that social media is becoming the dominant media source.},
	language = {en},
	urldate = {2025-02-14},
	journal = {International Review of Financial Analysis},
	author = {Gan, Baoqing and Alexeev, Vitali and Bird, Ron and Yeung, Danny},
	month = jan,
	year = {2020},
	pages = {101390},
}

@misc{sornette_financial_2014,
	title = {Financial bubbles: mechanisms and diagnostics},
	shorttitle = {Financial bubbles},
	url = {http://arxiv.org/abs/1404.2140},
	doi = {10.48550/arXiv.1404.2140},
	abstract = {We define a financial bubble as a period of unsustainable growth, when the price of an asset increases ever more quickly, in a series of accelerating phases of corrections and rebounds. More technically, during a bubble phase, the price follows a faster-than-exponential power law growth process, often accompanied by log-periodic oscillations. This dynamic ends abruptly in a change of regime that may be a crash or a substantial correction. Because they leave such specific traces, bubbles may be recognised in advance, that is, before they burst. In this paper, we will explain the mechanism behind financial bubbles in an intuitive way. We will show how the log-periodic power law emerges spontaneously from the complex system that financial markets are, as a consequence of feedback mechanisms, hierarchical structure and specific trading dynamics and investment styles. We argue that the risk of a major correction, or even a crash, becomes substantial when a bubble develops towards maturity, and that it is therefore very important to find evidence of bubbles and to follow their development from as early a stage as possible. The tools that are explained in this paper actually serve that purpose. They are at the core of the Financial Crisis Observatory at the ETH Zurich, where tens of thousands of assets are monitored on a daily basis. This allow us to have a continuous overview of emerging bubbles in the global financial markets. The companion report available as part of the Notenstein white paper series (2014) with the title ``Financial bubbles: mechanism, diagnostic and state of the World (Feb. 2014)'' presents a practical application of the methodology outlines in this article and describes our view of the status concerning positive and negative bubbles in the financial markets, as of the end of January 2014.},
	urldate = {2025-01-26},
	publisher = {arXiv},
	author = {Sornette, Didier and Cauwels, Peter},
	month = apr,
	year = {2014},
	note = {arXiv:1404.2140 [q-fin]},
	keywords = {Quantitative Finance - General Finance, Quantitative Finance - Risk Management},
}

@misc{malevergne_model_2021,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {A {Model} of {Financial} {Bubbles} and {Drawdowns} with {Non}-local {Behavioral} {Self}-{Referencing}},
	url = {https://papers.ssrn.com/abstract=3995532},
	doi = {10.2139/ssrn.3995532},
	abstract = {We propose a novel class of models in which the crash hazard rate is determined by a function of a non-local estimation of mispricing. Rooted in behavioral finance, the non-local estimation embodies in particular the characteristic of "anchoring" on past price levels and the "probability judgment" about the likelihood of a crash as a function of the self-referential mispricing, enabling us to disentangle the risk-return relationship from its instantaneous connection. By describing drawdowns and crashes as market regimes with correlated negative jumps clustering over a finite period of time, our model provides a solution to the problem plaguing most crash jump models, which are in general rejected in calibrations of real financial time series because they assume that crashes occur in a single large negative jump, which is counterfactual. The model estimation is implemented on synthetic time series and real markets, shedding light on the estimation of the "true" expected return, which is usually confounded by the entanglement between volatility and jump risks. Estimated from the daily time series of three stock indexes, the hidden expected return exhibits a secular increase over time and tends to be larger than the realized return, suggesting that financial markets have been overall underpriced.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Malevergne, Yannick and Sornette, Didier and Wei, Ran},
	month = dec,
	year = {2021},
	keywords = {behavioral price anchoring, bubbles, crashes, drawdowns, expected return, faster-than-exponential growth, financial markets, mispricing},
}

@misc{sornette_non-normal_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Non-{Normal} {Interactions} {Create} {Socio}-{Economic} {Bubbles}},
	url = {https://papers.ssrn.com/abstract=4118595},
	doi = {10.2139/ssrn.4118595},
	abstract = {In social networks, bursts of activity often result from the imitative behavior between interacting agents. The Ising model, along with its variants in the social sciences, serves as a foundational framework to explain these phenomena through its critical properties. We propose an alternative generic mechanism for the emergence of collective exuberance within a broad class of agent-based models. We show that our model does not require the fine-tuning to a critical point, as is commonly done to explain bursts of activity using the Ising model and its variants. Instead, our approach hinges on the intrinsic non-symmetric and hierarchical organization of socio-economic networks. These non-normal networks exhibit transient and unsustainable surges in herd behavior across a wide range of control parameters even in the subcritical regime, thereby eliminating the need for the - arguably artificial - fine-tuning proximity to a critical point. To empirically validate our framework, we examine the behavior of meme stocks and establish a direct linkage between the size of financial bubbles and the degree of non-normality in the network, as quantified by the Kreiss constant. Our proposed mechanism presents an alternative that is more general than prevailing conceptions of instabilities in diverse social systems.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Sornette, Didier and Lera, Sandro Claudio and Lin, Jianhong and Wu, Ke},
	month = may,
	year = {2022},
	keywords = {anticipating tipping points, financial bubbles, hierarchical networks, non-normal matrices, social networks, sub-criticality},
}

@misc{nielsen_deep_2024,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Deep {LPPLS}: {Forecasting} of temporal critical points in natural, engineering and financial systems},
	shorttitle = {Deep {LPPLS}},
	url = {https://papers.ssrn.com/abstract=4839066},
	doi = {10.2139/ssrn.4839066},
	abstract = {The Log-Periodic Power Law Singularity (LPPLS) model offers a general framework for capturing dynamics and predicting transition points in diverse natural and social systems. In this work, we present two calibration techniques for the LPPLS model using deep learning. First, we introduce the Mono-LPPLS-NN (M-LNN) model; for any given empirical time series, a unique M-LNN model is trained and shown to outperform state-of-the-art techniques in estimating the nonlinear parameters (tc; m; !) of the LPPLS model as evidenced by the comprehensive distribution of parameter errors. Second, we extend the M-LNN model to a more general model architecture, the Poly-LPPLS-NN (P-LNN), which is able to quickly estimate the nonlinear parameters of the LPPLS model for any given time-series of a fixed length, including previously unseen time-series during training. The Poly class of models train on many synthetic LPPLS time-series augmented with various noise structures in a supervised manner. Given enough training examples, the P-LNN models also outperform state-of-the-art techniques for estimating the parameters of the LPPLS model as evidenced by the comprehensive distribution of parameter errors. Additionally, this class of models is shown to substantially reduce the time to obtain parameter estimates. Finally, we present applications to the diagnostic and prediction of two financial bubble peaks (followed by their crash) and of a famous rockslide. These contributions provide a bridge between deep learning and the study of the prediction of transition times in complex time series.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Nielsen, Joshua and Sornette, Didier and Raissi, Maziar},
	month = may,
	year = {2024},
	keywords = {change of regime, deep learning, financial bubbles, finite-time singularity, landslides, log-periodicity, prediction},
}

@article{foltas_inefficient_2024,
	title = {Inefficient forecast narratives: {A} {BERT}-based approach},
	shorttitle = {Inefficient forecast narratives},
	url = {http://edoc.hu-berlin.de/18452/29758},
	doi = {10.18452/29133},
	abstract = {I contribute to previous research on the efficient integration of forecasters’ narratives into business cycle forecasts. Using a Bidirectional Encoder Representations from Transformers (BERT) model, I quantify 19,300 paragraphs from German business cycle reports (1998-2021) and classify the signs of institutes’ consumption forecast errors. The correlation is strong for 12.8\% of paragraphs with a predicted class probability of 85\% or higher. Reviewing 150 of such high-probability paragraphs reveals recurring narratives. Underestimations of consumption growth often mention rising employment, increasing wages and transfer payments, low inflation, decreasing taxes, crisis-related fiscal support, and reduced relevance of marginal employment. Conversely, overestimated consumption forecasts present opposing narratives. Forecasters appear to particularly underestimate these factors when they disproportionately affect low-income households.},
	language = {eng},
	urldate = {2025-01-25},
	author = {Foltas, Alexander},
	month = jul,
	year = {2024},
	note = {Publisher: Philosophische Fakultät},
}

@inproceedings{armbrust_computational_2020,
	address = {Barcelona, Spain (Online)},
	title = {A {Computational} {Analysis} of {Financial} and {Environmental} {Narratives} within {Financial} {Reports} and its {Value} for {Investors}},
	url = {https://aclanthology.org/2020.fnp-1.31/},
	abstract = {Public companies are obliged to include financial and non-financial information within their cor- porate filings under Regulation S-K, in the United States (SEC, 2010). However, the requirements still allow for manager`s discretion. This raises the question to which extent the information is actually included and if this information is at all relevant for investors. We answer this question by training and evaluating an end-to-end deep learning approach (based on BERT and GloVe embeddings) to predict the financial and environmental performance of the company from the “Management`s Discussion and Analysis of Financial Conditions and Results of Operations” (MD\&A) section of 10-K (yearly) and 10-Q (quarterly) filings. We further analyse the mediating effect of the environmental performance on the relationship between the company`s disclosures and financial performance. Hereby, we address the results of previous studies regarding environ- mental performance. We find that the textual information contained within the MD\&A section does not allow for conclusions about the future (corporate) financial performance. However, there is evidence that the environmental performance can be extracted by natural language processing methods.},
	urldate = {2025-01-25},
	booktitle = {Proceedings of the 1st {Joint} {Workshop} on {Financial} {Narrative} {Processing} and {MultiLing} {Financial} {Summarisation}},
	publisher = {COLING},
	author = {Armbrust, Felix and Schäfer, Henry and Klinger, Roman},
	editor = {El-Haj, Dr Mahmoud and Athanasakou, Dr Vasiliki and Ferradans, Dr Sira and Salzedo, Dr Catherine and Elhag, Dr Ans and Bouamor, Dr Houda and Litvak, Dr Marina and Rayson, Dr Paul and Giannakopoulos, Dr George and Pittaras, Nikiforos},
	month = dec,
	year = {2020},
	pages = {181--194},
}

@misc{gurgul_deep_2024,
	title = {Deep {Learning} and {NLP} in {Cryptocurrency} {Forecasting}: {Integrating} {Financial}, {Blockchain}, and {Social} {Media} {Data}},
	shorttitle = {Deep {Learning} and {NLP} in {Cryptocurrency} {Forecasting}},
	url = {http://arxiv.org/abs/2311.14759},
	doi = {10.48550/arXiv.2311.14759},
	abstract = {We introduce novel approaches to cryptocurrency price forecasting, leveraging Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a focus on Bitcoin and Ethereum. By analysing news and social media content, primarily from Twitter and Reddit, we assess the impact of public sentiment on cryptocurrency markets. A distinctive feature of our methodology is the application of the BART MNLI zero-shot classification model to detect bullish and bearish trends, significantly advancing beyond traditional sentiment analysis. Additionally, we systematically compare a range of pre-trained and fine-tuned deep learning NLP models against conventional dictionary-based sentiment analysis methods. Another key contribution of our work is the adoption of local extrema alongside daily price movements as predictive targets, reducing trading frequency and portfolio volatility. Our findings demonstrate that integrating textual data into cryptocurrency price forecasting not only improves forecasting accuracy but also consistently enhances the profitability and Sharpe ratio across various validation scenarios, particularly when applying deep learning NLP techniques. The entire codebase of our experiments is made available via an online repository: https://anonymous.4open.science/r/crypto-forecasting-public},
	urldate = {2025-01-25},
	publisher = {arXiv},
	author = {Gurgul, Vincent and Lessmann, Stefan and Härdle, Wolfgang Karl},
	month = oct,
	year = {2024},
	note = {arXiv:2311.14759 [q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance, Statistics - Machine Learning},
}

@article{ma_detecting_2024,
	title = {Detecting market bubbles: {A} generalized {LPPLS} neural network model},
	volume = {244},
	issn = {01651765},
	shorttitle = {Detecting market bubbles},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176524004877},
	doi = {10.1016/j.econlet.2024.112003},
	abstract = {To enhance bubble detection capabilities, we introduce two significant improvements to the Log-Periodic Power Law Singularity (LPPLS) model: (1) a novel fitting approach, which yields more accurate predictions of critical price distributions within a single sample window; (2) a restructured neural network approach further enhances the estimations of the probability distributions of the critical points across both time and price dimensions, and it can be fine-tuned with real-world data. The simulation and practical applications to typical asset price bubbles in cryptocurrencies, commodities, and equity indices demonstrate that our refined model, the Generalized-LPPLS Neural Network (G-LPPLS-NN), outperforms all other models we examined in terms of predictive accuracy for critical point distributions.},
	language = {en},
	urldate = {2025-01-25},
	journal = {Economics Letters},
	author = {Ma, Juntao and Li, Chenchen},
	month = nov,
	year = {2024},
	pages = {112003},
}

@article{shu_real-time_2020,
	title = {Real-time {Prediction} of {Bitcoin} {Bubble} {Crashes}},
	volume = {548},
	issn = {03784371},
	url = {http://arxiv.org/abs/1905.09647},
	doi = {10.1016/j.physa.2020.124477},
	abstract = {In the past decade, Bitcoin as an emerging asset class has gained widespread public attention because of their extraordinary returns in phases of extreme price growth and their unpredictable massive crashes. We apply the log-periodic power law singularity (LPPLS) confidence indicator as a diagnostic tool for identifying bubbles using the daily data on Bitcoin price in the past two years. We find that the LPPLS confidence indicator based on the daily Bitcoin price data fails to provide effective warnings for detecting the bubbles when the Bitcoin price suffers from a large fluctuation in a short time, especially for positive bubbles. In order to diagnose the existence of bubbles and accurately predict the bubble crashes in the cryptocurrency market, this study proposes an adaptive multilevel time series detection methodology based on the LPPLS model and finer (than daily) timescale for the Bitcoin price data. We adopt two levels of time series, 1 hour and 30 minutes, to demonstrate the adaptive multilevel time series detection methodology. The results show that the LPPLS confidence indicator based on this new method is an outstanding instrument to effectively detect the bubbles and accurately forecast the bubble crashes, even if a bubble exists in a short time. In addition, we discover that the short-term LPPLS confidence indicator highly sensitive to the extreme fluctuations of Bitcoin price can provide some useful insights into the bubble status on a shorter time scale - on a day to week scale, and the long-term LPPLS confidence indicator has a stable performance in terms of effectively monitoring the bubble status on a longer time scale - on a week to month scale. The adaptive multilevel time series detection methodology can provide real-time detection of bubbles and advanced forecast of crashes to warn of the imminent risk.},
	urldate = {2025-01-25},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Shu, Min and Zhu, Wei},
	month = jun,
	year = {2020},
	note = {arXiv:1905.09647 [q-fin]},
	keywords = {Quantitative Finance - Risk Management, Quantitative Finance - Statistical Finance, Statistics - Applications},
	pages = {124477},
}

@inproceedings{phillips_predicting_2017,
	address = {Honolulu, HI},
	title = {Predicting cryptocurrency price bubbles using social media data and epidemic modelling},
	isbn = {978-1-5386-2726-6},
	url = {http://ieeexplore.ieee.org/document/8280809/},
	doi = {10.1109/SSCI.2017.8280809},
	abstract = {Financial price bubbles have previously been linked with the epidemic-like spread of an investment idea; such bubbles are commonly seen in cryptocurrency prices. This paper aims to predict such bubbles for a number of cryptocurrencies using a hidden Markov model previously utilised to detect influenza epidemic outbreaks, based in this case on the behaviour of novel online social media indicators. To validate the methodology further, a trading strategy is built and tested on historical data. The resulting trading strategy outperforms a buy and hold strategy. The work demonstrates both the broader utility of epidemic-detecting hidden Markov models in the identification of bubble-like behaviour in time series, and that social media can provide valuable predictive information pertaining to cryptocurrency price movements.},
	language = {en},
	urldate = {2025-01-25},
	booktitle = {2017 {IEEE} {Symposium} {Series} on {Computational} {Intelligence} ({SSCI})},
	publisher = {IEEE},
	author = {Phillips, Ross C. and Gorse, Denise},
	month = nov,
	year = {2017},
	pages = {1--7},
}

@misc{bhargava_quantifying_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Quantifying {Narratives} and their {Impact} on {Financial} {Markets}},
	url = {https://papers.ssrn.com/abstract=4166640},
	doi = {10.2139/ssrn.4166640},
	abstract = {This paper introduces a media-coverage-based approach to quantify narratives and develops methodologies to explain the extent to which narratives drive financial markets and returns of investment portfolios. We show that media-derived narratives may contain predictive information for market returns beyond traditional macro indicators. Finally, we demonstrate that narrative indicators can be used to enhance asset allocation strategies and to gain or hedge exposure to narratives by constructing portfolios of narrative-sensitive assets.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Bhargava, Rajeev and Lou, Xiaoxia and Ozik, Gideon and Sadka, Ronnie and Whitmore, Travis},
	month = jul,
	year = {2022},
	keywords = {Economic Themes, Investor Behavior, Market Drivers, Media Sentiment, Narratives},
}

@article{tuckett_role_2017,
	title = {The role of conviction and narrative in decision-making under radical uncertainty},
	volume = {27},
	issn = {0959-3543},
	url = {https://doi.org/10.1177/0959354317713158},
	doi = {10.1177/0959354317713158},
	abstract = {We propose conviction narrative theory (CNT) to broaden decision-making theory in order to better understand and analyse how subjectively means–end rational actors cope in contexts in which the traditional assumptions in decision-making models fail to hold. Conviction narratives enable actors to draw on their beliefs, causal models, and rules of thumb to identify opportunities worth acting on, to simulate the future outcome of their actions, and to feel sufficiently convinced to act. The framework focuses on how narrative and emotion combine to allow actors to deliberate and to select actions that they think will produce the outcomes they desire. It specifies connections between particular emotions and deliberative thought, hypothesising that approach and avoidance emotions evoked during narrative simulation play a crucial role. Two mental states, Divided and Integrated, in which narratives can be formed or updated, are introduced and used to explain some familiar problems that traditional models cannot.},
	language = {en},
	number = {4},
	urldate = {2025-01-25},
	journal = {Theory \& Psychology},
	author = {Tuckett, David and Nikolic, Milena},
	month = aug,
	year = {2017},
	note = {Publisher: SAGE Publications Ltd},
	pages = {501--523},
}

@misc{shiller_narrative_2017-1,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Narrative {Economics}},
	url = {https://papers.ssrn.com/abstract=2896857},
	doi = {10.2139/ssrn.2896857},
	abstract = {This address considers the epidemiology of narratives relevant to economic fluctuations. The human brain has always been highly tuned towards narratives, whether factual or not, to justify ongoing actions, even such basic actions as spending and investing. Stories motivate and connect activities to deeply felt values and needs. Narratives “go viral” and spread far, even worldwide, with economic impact. The 1920-21 Depression, the Great Depression of the 1930s, the so-called “Great Recession” of 2007-9 and the contentious political-economic situation of today, are considered as the results of the popular narratives of their respective times. Though these narratives are deeply human phenomena that are difficult to study in a scientific manner, quantitative analysis may help us gain a better understanding of these epidemics in the future.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Shiller, Robert J.},
	month = jan,
	year = {2017},
	keywords = {2008 Financial Crisis, Bubbles, Business Cycles, Depression of 1920, Economic Fluctuations, Epidemic, Great Depression, Kermack and McKendrick, Meme, Multipliers, Post-Truth, Profiteer, SIR Model, Stock Market Crash, Story},
}

@article{roos_narratives_2024-1,
	title = {Narratives in economics},
	volume = {38},
	copyright = {© 2023 The Authors. Journal of Economic Surveys published by John Wiley \& Sons Ltd.},
	issn = {1467-6419},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/joes.12576},
	doi = {10.1111/joes.12576},
	abstract = {There is growing awareness within the economics profession of the important role narratives play in the economy. Even though empirical approaches that try to quantify economic narratives are getting increasingly popular, there is no theory or even a universally accepted definition of economic narratives underlying this research. First, we review and categorize the economic literature concerned with narratives and work out the different paradigms at play. Only a subset of the literature considers narratives to be active drivers of economic activity. To solidify the foundation of narrative economics, we propose a definition of collective economic narratives, isolating five important characteristics. We argue that, for a narrative to be economically relevant, it must be a sense-making story that emerges in a social context and suggests action to a social group. We also systematize how a collective economic narrative differs from a topic and from other kinds of narratives that are likely to have less impact on the economy. With regard to the popular use of topic modeling, we suggest that the complementary use of other methods from the natural language processing (NLP) toolkit and the development of new methods is inevitable to go beyond identifying topics and move towards true empirical narrative economics.},
	language = {en},
	number = {2},
	urldate = {2025-01-25},
	journal = {Journal of Economic Surveys},
	author = {Roos, Michael and Reccius, Matthias},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/joes.12576},
	keywords = {NLP, complexity economics, narrative economics, narrative turn, text as data},
	pages = {303--341},
}

@misc{lounsbury_cultural_2001,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Cultural {Entrepreneurship}: {Stories}, {Legitimacy} and the {Acquisition} of {Resources}},
	shorttitle = {Cultural {Entrepreneurship}},
	url = {https://papers.ssrn.com/abstract=1830380},
	abstract = {We define cultural entrepreneurship as the process of storytelling that mediates between extant stocks of entrepreneurial resources and subsequent capital acquisition and wealth creation.  We propose a framework that focuses on how entrepreneurial stories facilitate the crafting of a new venture identity that serves as a touchstone upon which legitimacy may be conferred by investors, competitors, and consumers, opening up access to new capital and market opportunities.  Stories help create competitive advantage for entrepreneurs through focal content shaped by two key forms of entrepreneurial capital: firm-specific resource capital and industry-level institutional capital.  We illustrate our ideas with anecdotal entrepreneurial stories that range from contemporary high technology accounts to the evolution of the mutual fund industry.  Propositions are offered to guide future empirical research based on our framework.  Theoretically, we aim to extend recent efforts to synthesize strategic and institutional perspectives by incorporating insights from contemporary approaches to culture and organizational identity.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Lounsbury, Michael},
	year = {2001},
	keywords = {Cultural Entrepreneurship: Stories, Legitimacy and the Acquisition of Resources, Michael Lounsbury, SSRN},
}

@misc{garud_entrepreneurial_2014,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Entrepreneurial {Storytelling}, {Future} {Expectations}, and the {Paradox} of {Legitimacy}},
	url = {https://papers.ssrn.com/abstract=2471304},
	abstract = {Prior research highlights storytelling as a means for entrepreneurs to establish venture legitimacy and gain stakeholder support. We extend this line of research by examining the role that projective stories play in setting expectations and the dynamics that ensue. Such attention highlights a paradox – the very expectations that are set through projective stories to gain venture legitimacy can also serve as the source of future disappointments. Because of inherent uncertainties that projective stories mask, ventures will likely deviate from their early projections, thereby disappointing stakeholders. This, in turn, can result in a loss of legitimacy. Recognizing that entrepreneurship is an ongoing process, we examine the constraints and possibilities of maintaining or regaining legitimacy through revised storytelling. We conclude the paper with implications for research on entrepreneurial storytelling as an ongoing process.},
	language = {en},
	urldate = {2025-01-25},
	publisher = {Social Science Research Network},
	author = {Garud, Raghu and Schildt, Henri and Lant, Theresa K.},
	month = mar,
	year = {2014},
	keywords = {cultural, entrepreneurship, future expectations, institutional capital, legitimacy, paradox, projective narratives, sensemaking},
}

@article{mccloskey_rhetoric_2011,
	title = {The {Rhetoric} of the {Economy} and the {Polity}},
	volume = {14},
	issn = {1094-2939, 1545-1577},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-polisci-041309-110519},
	doi = {10.1146/annurev-polisci-041309-110519},
	abstract = {The Great Recession is not the end of capitalism. An innovative economy makes mistakes, but that is not a good reason to regulate it out of its innovations. The innovations—not unions or regulation—have increased real income per head by a factor of 100 in the places that have adopted bourgeois liberty and dignity. An innovative economy is “rhetorical” because, if our economic lives are not frozen by tradition, we must persuade each other what is to be done. “Rhetoric,” of course, is the ancient word for unforced persuasion. Samuelsonian economics, which is the usual kind, ignores words, persuasion, rhetoric. Yet one quarter of national income in a modern economy is earned from “sweet talk.” Discovery, which Austrian economists like Schumpeter and Kirzner emphasize, depends on rhetoric, and the rhetoric depends on ethics. Realist political philosophy, and agency theory in business schools, miss the ethical foundations of our lives.},
	language = {en},
	number = {1},
	urldate = {2025-01-25},
	journal = {Annual Review of Political Science},
	author = {McCloskey, Deirdre Nansen},
	month = jun,
	year = {2011},
	pages = {181--199},
}

@article{mancini_self-induced_2022,
	title = {Self-induced consensus of {Reddit} users to characterise the {GameStop} short squeeze},
	volume = {12},
	copyright = {2022 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-17925-2},
	doi = {10.1038/s41598-022-17925-2},
	abstract = {The short squeeze of GameStop (GME) shares in mid-January 2021 has been primarily orchestrated by retail investors of the Reddit r/wallstreetbets community. As such, it represents a paramount example of collective coordination action on social media, resulting in large-scale consensus formation and significant market impact. In this work we characterise the structure and time evolution of Reddit conversation data, showing that the occurrence and sentiment of GME-related comments (representing how much users are engaged with GME) increased significantly much before the short squeeze actually took place. Taking inspiration from these early warnings as well as evidence from previous literature, we introduce a model of opinion dynamics where user engagement can trigger a self-reinforcing mechanism leading to the emergence of consensus, which in this particular case is associated to the success of the short squeeze operation. Analytical solutions and model simulations on interaction networks of Reddit users feature a phase transition from heterogeneous to homogeneous opinions as engagement grows, which we qualitatively compare to the sudden hike of GME stock price. Although the model cannot be validated with available data, it offers a possible and minimal interpretation for the increasingly important phenomenon of self-organized collective actions taking place on social networks.},
	language = {en},
	number = {1},
	urldate = {2025-01-25},
	journal = {Scientific Reports},
	author = {Mancini, Anna and Desiderio, Antonio and Di Clemente, Riccardo and Cimini, Giulio},
	month = aug,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Complex networks, Statistical physics},
	pages = {13780},
}

@article{anand_role_2022,
	title = {The role of {Reddit} in the {GameStop} short squeeze},
	volume = {211},
	issn = {01651765},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165176521004808},
	doi = {10.1016/j.econlet.2021.110249},
	abstract = {We present evidence that the tone of r/wallstreetbets (WSB) discussions displayed significant predictive associations with intraday GameStop variables and that the comment distribution obeyed a power law and in fact it was 462 users whose posts most impacted GME.},
	language = {en},
	urldate = {2025-01-25},
	journal = {Economics Letters},
	author = {Anand, Abhinav and Pathak, Jalaj},
	month = feb,
	year = {2022},
	pages = {110249},
}

@article{huber_boom_2022,
	title = {Boom, {Bust}, and {Bitcoin}: {Bitcoin}-{Bubbles} as {Innovation} {Accelerators}},
	volume = {56},
	issn = {0021-3624},
	shorttitle = {Boom, {Bust}, and {Bitcoin}},
	url = {https://doi.org/10.1080/00213624.2022.2020023},
	doi = {10.1080/00213624.2022.2020023},
	abstract = {Bitcoin represents one of the most interesting technological breakthroughs and socio-economic experiments of the last decades. In this paper, we examine the role of speculative bubbles in the process of Bitcoin’s technological adoption by analyzing its social dynamics. We trace Bitcoin’s genesis and dissect the nature of its techno-economic innovation. In particular, we present an analysis of the techno-economic feedback loops that drive Bitcoin’s price and network effects. Based on our analysis of Bitcoin, we test and further refine the Social Bubble Hypothesis, which holds that bubbles constitute an essential component in the process of technological innovation. We argue that a hierarchy of repeating and exponentially increasing series of bubbles and hype cycles, which has occurred over the past decade since its inception, has bootstrapped Bitcoin into existence.},
	number = {1},
	urldate = {2025-01-25},
	journal = {Journal of Economic Issues},
	author = {Huber, Tobias A. and Sornette, Didier},
	month = jan,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00213624.2022.2020023},
	keywords = {G12, O33, O43, bitcoin, cryptocurrencies, economic growth, financial bubbles, money, reflexivity, technological innovation},
	pages = {113--136},
}

@article{brunnermeier_complexity_nodate,
	title = {{COMPLEXITY} {IN} {FINANCIAL} {MARKETS}},
	abstract = {Should we regulate complex securities, subject them to an FDA-style approval process, or limit who can invest in them? To answer these questions, one first needs to establish why complexity matters, and what defines a complex security. Complexity is an important concept in financial markets with boundedly rational agents, but that finding a workable definition of complexity is difficult. For example, while CDOs are viewed by most as highly complex, equity shares of financial institutions, whose payoff structures are even more complicated, are often seen as less complex. We point out three different ways in which boundedly rational investors can deal with complexity: (i) by dividing up difficult problems into smaller sub-problems or by using separation results, (ii) by using models – simplified pictures of reality, (iii) through standardization and commoditization of securities. Importantly, simply increasing the quantity of information disclosed to investors does not resolve complexity, since in the presence of bounded rationality it leads to information overload.},
	language = {en},
	author = {Brunnermeier, Markus K and Oehmke, Martin},
}

@misc{gu_efficient_2022,
	title = {Efficient {Dynamic} {Clustering}: {Capturing} {Patterns} from {Historical} {Cluster} {Evolution}},
	shorttitle = {Efficient {Dynamic} {Clustering}},
	url = {http://arxiv.org/abs/2203.00812},
	doi = {10.48786/EDBT.2022.21},
	abstract = {Clustering aims to group unlabeled objects based on similarity inherent among them into clusters. It is important for many tasks such as anomaly detection, database sharding, record linkage, and others. Some clustering methods are taken as batch algorithms that incur a high overhead as they cluster all the objects in the database from scratch or assume an incremental workload. In practice, database objects are updated, added, and removed from databases continuously which makes previous results stale. Running batch algorithms is infeasible in such scenarios as it would incur a significant overhead if performed continuously. This is particularly the case for high-velocity scenarios such as ones in Internet of Things applications. In this paper, we tackle the problem of clustering in high-velocity dynamic scenarios, where the objects are continuously updated, inserted, and deleted. Specifically, we propose a generally dynamic approach to clustering that utilizes previous clustering results. Our system, DynamicC, uses a machine learning model that is augmented with an existing batch algorithm. The DynamicC model trains by observing the clustering decisions made by the batch algorithm. After training, the DynamicC model is usedin cooperation with the batch algorithm to achieve both accurate and fast clustering decisions. The experimental results on four real-world and one synthetic datasets show that our approach has a better performance compared to the state-of-the-art method while achieving similarly accurate clustering results to the baseline batch algorithm.},
	urldate = {2025-01-25},
	author = {Gu, Binbin and Kargar, Saeed and Nawab, Faisal},
	year = {2022},
	note = {arXiv:2203.00812 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Databases},
}

@inproceedings{shukla_raphael_2023,
	address = {Singapore (Hybrid)},
	title = {Raphael at {ArAIEval} {Shared} {Task}: {Understanding} {Persuasive} {Language} and {Tone}, an {LLM} {Approach}},
	shorttitle = {Raphael at {ArAIEval} {Shared} {Task}},
	url = {https://aclanthology.org/2023.arabicnlp-1.60/},
	doi = {10.18653/v1/2023.arabicnlp-1.60},
	abstract = {The widespread dissemination of propaganda and disinformation on both social media and mainstream media platforms has become an urgent concern, attracting the interest of various stakeholders such as government bodies and social media companies. The challenge intensifies when dealing with understudied languages like Arabic. In this paper, we outline our approach for detecting persuasion techniques in Arabic tweets and news article paragraphs. We submitted our system to ArAIEval 2023 Shared Task 1, covering both subtasks. Our main contributions include utilizing GPT-3 to discern tone and potential persuasion techniques in text, exploring various base language models, and employing a multi-task learning approach for the specified subtasks.},
	urldate = {2025-01-23},
	booktitle = {Proceedings of {ArabicNLP} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Shukla, Utsav and Vyas, Manan and Tiwari, Shailendra},
	editor = {Sawaf, Hassan and El-Beltagy, Samhaa and Zaghouani, Wajdi and Magdy, Walid and Abdelali, Ahmed and Tomeh, Nadi and Abu Farha, Ibrahim and Habash, Nizar and Khalifa, Salam and Keleg, Amr and Haddad, Hatem and Zitouni, Imed and Mrini, Khalil and Almatham, Rawan},
	month = dec,
	year = {2023},
	pages = {589--593},
}

@article{wang_bankruptcy_2020,
	title = {Bankruptcy and the {COVID}-19 {Crisis}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=3690398},
	doi = {10.2139/ssrn.3690398},
	abstract = {We examine the impact of the COVID-19 economic crisis on business and consumer bankruptcies in the United States using real-time data on the universe of ﬁlings. Historically, bankruptcies have closely tracked the business cycle and contemporaneous unemployment rates. However, this relationship has reversed during the COVID-19 crisis thus far. While aggregate ﬁling rates were very similar to 2019 levels prior to the severe onset of the pandemic, ﬁlings by consumers and small businesses dropped dramatically starting in mid-March, contrary to media reports and many experts’ expectations. The total number of bankruptcy ﬁlings is down by 27 percent year-over-year between January and August. Consumer and business Chapter 7 ﬁlings rebounded moderately starting in mid-April and stabilized around 20 percent below 2019 levels, but Chapter 13 ﬁlings remained at 55-65 percent below 2019 levels through the end of August. In contrast to the 2007-9 recession, states with a larger increase in unemployment between April and July experienced greater drops in bankruptcies. Although they make up a small share of overall bankruptcies, Chapter 11 ﬁlings by large corporations have increased since 2019, and are up nearly 200 percent year-over-year from January through August. These patterns suggest that the ﬁnancial experiences of consumers, small businesses, and large corporations have diverged during the COVID-19 crisis. Large businesses have continued to seek and receive relief from the bankruptcy system as they would during a normal recession, and relatively wealthy homeowners have on average beneﬁted from the ﬁscal stimulus and housing moratoria mandated by the CARES Act and other policies. However, non-homeowners and small businesses may face ﬁnancial, physical, and technological barriers to accessing the bankruptcy system, especially in the areas hardest-hit by unemployment.},
	language = {en},
	urldate = {2025-01-22},
	journal = {SSRN Electronic Journal},
	author = {Wang, Jialan and Yang, Jeyul and Iverson, Benjamin Charles and Kluender, Raymond},
	year = {2020},
}

@article{megerdoomian_automated_2019,
	title = {Automated {Narrative} {Extraction} from {Administrative} {Records}},
	abstract = {The U.S. Probation and Pretrial Services Office staff produce billions of pages of information on defendants’ and offenders’ profile and conduct. While it is critical for probation officers and district chiefs to have up-to-date knowledge on their clients to better assist and reduce risk of recidivism, the data are often stored in narrative texts in multiple large documents. As a result, these records remain mostly out of reach without the use of painstaking manual review. This paper describes an analytic prototype developed to automatically acquire structured information from natural language text in probation office documents through the application of PDF content extraction, text mining, and language analytics. Since serious mental illness is very prevalent in the U.S. corrections system, the first phase of the project focused on extracting information and constructing timelines from narrative text regarding the defendants’ mental health conditions, substance use and treatment history.},
	language = {en},
	author = {Megerdoomian, Karine and Marsh, Amy B and Scott, Eric O and Branting, Karl and Modly, Nick and Wariyar, Sujit B and Horowitz, Charles E and Petersen, Stacy J},
	year = {2019},
}

@article{diaz_sobrino_narrative_2022,
	title = {The narrative about the economy as a shadow forecast: an analysis using {Bank} of {Spain} quarterly reports},
	volume = {54},
	issn = {0003-6846},
	shorttitle = {The narrative about the economy as a shadow forecast},
	url = {https://doi.org/10.1080/00036846.2021.1999386},
	doi = {10.1080/00036846.2021.1999386},
	abstract = {This paper constructs a text-based indicator that reflects the sentiment of the Bank of Spain economic outlook reports. Our sentiment indicator mimics very closely the first release of the GDP growth rate, which is published after the publication of the reports, and the Bank of Spain’s quarterly forecasts of the GDP growth rate. In addition, not only the narrative is consistent with the quantitative projections, but it also complements them by discussing information which is not directly reflected in the point forecasts, and may put on the table potential risks that will be included in the numerical projections of the next quarter. Thus, while the quantitative projections tend to underestimate the GDP growth rate especially during upturns, the narrative allows to outweigh this conservative bias. Overall, from a Central Bank’s communication perspective, it is the combination of quantitative forecast and narrative that provides a more precise picture of expected economic activity.},
	number = {25},
	urldate = {2025-01-21},
	journal = {Applied Economics},
	author = {Díaz Sobrino, Nélida and Ghirelli, Corinna and Hurtado, Samuel and Pérez, Javier J. and Urtasun, Alberto},
	month = may,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/00036846.2021.1999386},
	keywords = {C53, E37, E58, E66, Textual analysis, central bank reports, forecasting, gdp growth rate},
	pages = {2874--2887},
}

@article{chen_covid_2022,
	title = {{COVID} risk narratives: a computational linguistic approach to the econometric identification of narrative risk during a pandemic},
	volume = {4},
	issn = {2524-6186},
	shorttitle = {{COVID} risk narratives},
	url = {https://doi.org/10.1007/s42521-021-00045-3},
	doi = {10.1007/s42521-021-00045-3},
	abstract = {In this paper, we study the role of narratives in stock markets with a particular focus on the relationship with the ongoing COVID-19 pandemic. The pandemic represents a natural setting for the development of viral financial market narratives. We thus treat the pandemic as a natural experiment on the relation between prevailing narratives and financial markets. We adopt natural language processing (NLP) on financial news to characterize the evolution of important narratives. Doing so, we reduce the high-dimensional narrative information to few interpretable and important features while avoiding over-fitting. In addition to the common features, we consider virality as a novel feature of narratives, inspired by Shiller (Am Econ Rev 107:967–1004, 2017). Our aim is to establish whether the prevailing narratives drive or are driven by stock market conditions. Focusing on the coronavirus narratives, we document some stylized facts about its evolution around a severe event-driven stock market decline. We find the pandemic-relevant narratives are influenced by stock market conditions and act as a cellar for brewing a perennial economic narrative. We successfully identified a perennial risk narrative, whose shock is followed by a severe market drop and a long-term increase of market volatility. In the out-of-sample test, this narrative went viral since the start of the global COVID-19 pandemic, when the pandemic-relevant narratives dominate news media, show negative sentiment and were more linked to “crisis” context. Our findings encourage the use of narratives to evaluate long-term market conditions and to early warn event-driven severe market declines.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {Digital Finance},
	author = {Chen, Yuting and Bredin, Don and Potì, Valerio and Matkovskyy, Roman},
	month = mar,
	year = {2022},
	keywords = {C53, COVID-19, D81, E37, E71, Early warning indicator, G17, G41, Narrative economics, Natural language processing, Tone analysis},
	pages = {17--61},
}

@article{alonso-robisco_analysis_2023,
	title = {Analysis of {CBDC} narrative by central banks using large language models},
	volume = {58},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612323010152},
	doi = {10.1016/j.frl.2023.104643},
	abstract = {One topic that is gaining importance in central bank communication is central bank digital currency (CBDC). To better understand central banks’ stance towards CBDCs, we used different natural language processing techniques on a set of central bank speeches. We found that the sentiment calculated by Large Language Models, and in particular by ChatGPT, is the one that most resembles the sentiment identified by human experts in those same speeches. Our study suggests that LLMs are an effective tool for improving sentiment measurements on specific policy texts, although they are not infallible and may be subject to new risks.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Finance Research Letters},
	author = {Alonso-Robisco, Andres and Carbó, José Manuel},
	month = dec,
	year = {2023},
	pages = {104643},
}

@misc{miori_narratives_2023,
	title = {Narratives from {GPT}-derived {Networks} of {News}, and a link to {Financial} {Markets} {Dislocations}},
	url = {http://arxiv.org/abs/2311.14419},
	doi = {10.48550/arXiv.2311.14419},
	abstract = {Starting from a corpus of economic articles from The Wall Street Journal, we present a novel systematic way to analyse news content that evolves over time. We leverage on state-of-the-art natural language processing techniques (i.e. GPT3.5) to extract the most important entities of each article available, and aggregate co-occurrence of entities in a related graph at the weekly level. Network analysis techniques and fuzzy community detection are tested on the proposed set of graphs, and a framework is introduced that allows systematic but interpretable detection of topics and narratives. In parallel, we propose to consider the sentiment around main entities of an article as a more accurate proxy for the overall sentiment of such piece of text, and describe a case-study to motivate this choice. Finally, we design features that characterise the type and structure of news within each week, and map them to moments of financial markets dislocations. The latter are identified as dates with unusually high volatility across asset classes, and we find quantitative evidence that they relate to instances of high entropy in the high-dimensional space of interconnected news. This result further motivates the pursued efforts to provide a novel framework for the systematic analysis of narratives within news.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Miori, Deborah and Petrov, Constantin},
	month = nov,
	year = {2023},
	note = {arXiv:2311.14419 [q-fin]},
	keywords = {Economics - General Economics, Quantitative Finance - Computational Finance, Quantitative Finance - Economics},
}

@article{agarwal_investor_2024,
	title = {Investor emotions and market bubbles},
	issn = {1573-7179},
	url = {https://doi.org/10.1007/s11156-024-01309-w},
	doi = {10.1007/s11156-024-01309-w},
	abstract = {Asset pricing bubbles are highly emotional market episodes. Despite this, investor emotions are not part of traditional bubble models. We measure the powerful affects influencing investor decisions during speculative market bubbles directly employing textual analysis of media narratives and domain-specific emotion keyword dictionaries and show how understanding investor emotional dynamics helps explain market behavior. Specifically, we focus on the two Chinese stock market bubbles of 2005–2008 and 2014–2016; there is no evidence of investor learning from experience. Despite Chinese media being censored we show it still has strong explanatory power although the independent English language media can provide an additional perspective. Deeper emotions dominate more superficial feelings in information content.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Review of Quantitative Finance and Accounting},
	author = {Agarwal, Vineet and Taffler, Richard J. and Wang, Chenyang},
	month = jul,
	year = {2024},
	keywords = {Asset pricing bubbles, Chinese stock market, Economic narratives, G12, G15, G41, Investor emotions, Textual analysis},
}

@article{taffler_narrative_nodate,
	title = {Narrative {Emotions} and {Market} {Crises}},
	volume = {0},
	issn = {1542-7560},
	url = {https://doi.org/10.1080/15427560.2024.2365723},
	doi = {10.1080/15427560.2024.2365723},
	abstract = {Robert Shiller highlights the role popular stories play in driving economic behavior and argues the need to analyze these scientifically. However, their impacts are difficult to measure directly and often conflict. We show the strength of such stories resides in the emotions they generate, and that the tenor and persuasiveness of financial narratives and their association with the market can be empirically quantified. Specifically, we textually analyze financial media reports to identify the different powerful investor emotions manifest during three recent extreme market periods, dot.com mania, the Global Financial Crisis and the COVID-19 pandemic, constructing original context-specific emotion word dictionaries for this purpose. We find investor emotions are associated with up to 52\% of market returns and 67\% of market uncertainty during these market crises, and provide general evidence that investor emotional dynamics may be time and context invariant.},
	number = {0},
	urldate = {2025-01-21},
	journal = {Journal of Behavioral Finance},
	author = {Taffler, Richard J. and Agarwal, Vineet and Obring, Maximilian},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/15427560.2024.2365723},
	keywords = {A12, B41, COVID-19 pandemic, G01, G12, G41, Global Financial Crisis, internet bubble, investor emotions, market pricing, media stories},
	pages = {1--21},
}

@inproceedings{diaf_uncovering_2024,
	address = {Cham},
	title = {Uncovering {Uncertainty} in {Narrative} {Economics}: {A} {Semantic} {Search} {Approach}},
	isbn = {978-3-031-55917-4},
	shorttitle = {Uncovering {Uncertainty} in {Narrative} {Economics}},
	doi = {10.1007/978-3-031-55917-4_26},
	abstract = {The study of narrative economics using text mining techniques has grown recently, with a dominance of unsupervised models built upon the bag-of-word assumption that try to extract meaningful information for further inferences. Yet, word independence remains a constraining hypothesis when the narratives rely on implicit word usage that belongs to a specific jargon. But recent advances in natural language processing offer powerful distributional representation tools to preserve the semantic and syntactic meaning of the text as a reliable alternative to frequency-based probabilistic topic models. Monetary policy, as an important application field of narrative economics, carries uncertainty in its decision-making process as a forward guidance tool, besides being a strategic aspect of its communication policy. It witnessed several attempts to construct uncertainty indices using uncertainty-related word counts, yielding questionable measurements that overlook key technical terms not encompassed in word lists, hence making the computed indices biased and semantically agnostic vis-à-vis the proper jargon. This work proposes an in-depth assessment of uncertainty in a collection of international central bankers’ speeches (1997–2022) and identifies its key drivers using semantic search models, namely, Top2Vec, to uncover nested semantic topic structures at the national and international levels as proxies of uncertainty sources. These proved to be robust in discerning uncertainty features associated with probability and risk, in line with the Keynes-Knight debate about uncertainty in macroeconomics. Moreover, a robust uncertainty index could be built from the similarity between each document and the term uncertainty, either country-specific or internationally, which was found to follow major world financial and banking events of the last two decades.},
	language = {en},
	booktitle = {New {Frontiers} in {Textual} {Data} {Analysis}},
	publisher = {Springer Nature Switzerland},
	author = {Diaf, Sami and Schütze, Florian},
	editor = {Giordano, Giuseppe and Misuraca, Michelangelo},
	year = {2024},
	pages = {323--335},
}

@article{le_studying_2024,
	title = {Studying the impact of profitability, bankruptcy risk, and pandemic on narrative tone in annual reports in an emerging market in the {East}},
	volume = {11},
	copyright = {2024 The Author(s)},
	issn = {2662-9992},
	url = {https://www.nature.com/articles/s41599-024-03980-9},
	doi = {10.1057/s41599-024-03980-9},
	abstract = {The purpose of this paper is to investigate whether the narrative tone of annual reports is influenced by profitability, bankruptcy risk, and pandemic in the context of Vietnam. The study applies the necessary regression analysis steps such as ordinary least squares (OLS), random effects model (REM), fixed effects model (FEM), and feasible generalized least squares (FGLS). Bootstrapping and System Generalized Method of Moments (SGMM) methods are used to test the robustness and address endogeneity and dynamic relationships in the data. The findings show that net tones increase while negative tones decrease in companies with high profitability. Companies at risk of bankruptcy use more negative tone and less net tone than companies that are not at risk of bankruptcy. The study also affirms that bankruptcy risk moderates the relationship between profitability and negative tone. During the COVID-19 pandemic, companies used more positive and negative tones than they did before the pandemic. After the COVID-19 situation stabilized, positive tones were used more, and negative tones were used less than during the outbreak. The research results also recognized that companies do not intend to hide information through impression management when faced with difficult economic conditions. This study has practical implications for investors and information users when considering management disclosures through the narrative tone of annual reports. To our knowledge, this is the first study (1) in an emerging market in the East—where there are fundamental cultural and linguistic differences compared to Western countries, (2) to build a list of Vietnamese words and phrases expressing emotional nuances used in finance and accounting, and (3) refers to the narrative tone of annual reports across different groups of companies.},
	language = {en},
	number = {1},
	urldate = {2025-01-21},
	journal = {Humanities and Social Sciences Communications},
	author = {Le, Binh Thi Hai and Nguyen, Cong Van},
	month = oct,
	year = {2024},
	note = {Publisher: Palgrave},
	keywords = {Business and management, Finance},
	pages = {1--16},
}

@article{du_natural_2025,
	title = {Natural language processing in finance: {A} survey},
	volume = {115},
	issn = {15662535},
	shorttitle = {Natural language processing in finance},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253524005335},
	doi = {10.1016/j.inffus.2024.102755},
	abstract = {This survey presents an in-depth review of the transformative role of Natural Language Processing (NLP) in finance, highlighting its impact on ten major financial applications: (1) financial sentiment analysis, (2) financial narrative processing, (3) financial forecasting, (4) portfolio management, (5) question answering, virtual assistant and chatbot, (6) risk management, (7) regulatory compliance monitoring, (8) Environmental, Social, Governance (ESG) and sustainable finance, (9) explainable artificial intelligence (XAI) in finance and (10) NLP for digital assets. With the integration of vast amounts of unstructured financial data and advanced NLP techniques, the study explores how NLP enables data-driven decision-making and innovation in the financial sector, alongside the limitations and challenges. By providing a comprehensive analysis of NLP applications combining both academic and industrial perspectives, this study postulates the future trends and evolution of financial services. It introduces a unique review framework to understand the interaction of financial data and NLP technologies systematically and outlines the key drivers, transformations, and emerging areas in this field. This survey targets researchers, practitioners, and professionals, aiming to close their knowledge gap by highlighting the significance and future direction of NLP in enhancing financial services.},
	language = {en},
	urldate = {2025-01-21},
	journal = {Information Fusion},
	author = {Du, Kelvin and Zhao, Yazhi and Mao, Rui and Xing, Frank and Cambria, Erik},
	month = mar,
	year = {2025},
	pages = {102755},
}

@article{herrmann-pillath_robert_2021,
	title = {Robert {J}. {Shiller}, {Narrative} {Economics}: {How} {Stories} {Go} {Viral} \& {Drive} {Major} {Economic} {Events}},
	issn = {2113-5207, 2269-8450},
	shorttitle = {Robert {J}. {Shiller}, {Narrative} {Economics}},
	url = {http://journals.openedition.org/oeconomia/11128},
	doi = {10.4000/oeconomia.11128},
	language = {fr},
	number = {11-2},
	urldate = {2025-01-21},
	journal = {OEconomia},
	author = {Herrmann-Pillath, Carsten},
	month = jun,
	year = {2021},
	pages = {403--408},
}

@article{dubremetz_rhetorical_2018,
	title = {Rhetorical {Figure} {Detection}: {Chiasmus}, {Epanaphora}, {Epiphora}},
	volume = {5},
	issn = {2297-2668},
	shorttitle = {Rhetorical {Figure} {Detection}},
	url = {https://www.frontiersin.org/journals/digital-humanities/articles/10.3389/fdigh.2018.00010/full},
	doi = {10.3389/fdigh.2018.00010},
	abstract = {{\textless}p{\textgreater}Rhetorical figures are valuable linguistic data for literary analysis. In this article, we target the detection of three rhetorical figures that belong to the family of repetitive figures: chiasmus (I {\textless}bold{\textgreater}go{\textless}/bold{\textgreater} where I {\textless}bold{\textgreater}please{\textless}/bold{\textgreater}, and I {\textless}bold{\textgreater}please{\textless}/bold{\textgreater} where I {\textless}bold{\textgreater}go{\textless}/bold{\textgreater}.), epanaphora also called anaphora (“{\textless}bold{\textgreater}Poor old{\textless}/bold{\textgreater} European Commission! {\textless}bold{\textgreater}Poor old{\textless}/bold{\textgreater} European Council.”) and epiphora (“This house is {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}. This car is {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}. You are {\textless}bold{\textgreater}mine{\textless}/bold{\textgreater}.”). Detecting repetition of words is easy for a computer but detecting only the ones provoking a rhetorical effect is difficult because of many accidental and irrelevant repetitions. For all figures, we train a log-linear classifier on a corpus of political debates. The corpus is only very partially annotated, but we nevertheless obtain good results, with more than 50\% precision for all figures. We then apply our models to totally different genres and perform a comparative analysis, by comparing corpora of fiction, science and quotes. Thanks to the automatic detection of rhetorical figures, we discover that chiasmus is more likely to appear in the scientific context whereas epanaphora and epiphora are more common in fiction.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2025-01-21},
	journal = {Frontiers in Digital Humanities},
	author = {Dubremetz, Marie and Nivre, Joakim},
	month = may,
	year = {2018},
	note = {Publisher: Frontiers},
	keywords = {Antimetabole, Chiasmus, Epiphora, Rhetorical Device, computational stylistics., epanaphora, repetitive figures},
}

@misc{ghosh_rheframedetect_2021,
	title = {{RheFrameDetect}: {A} {Text} {Classification} {System} for {Automatic} {Detection} of {Rhetorical} {Frames} in {AI} from {Open} {Sources}},
	shorttitle = {{RheFrameDetect}},
	url = {http://arxiv.org/abs/2112.14933},
	doi = {10.48550/arXiv.2112.14933},
	abstract = {Rhetorical Frames in AI can be thought of as expressions that describe AI development as a competition between two or more actors, such as governments or companies. Examples of such Frames include robotic arms race, AI rivalry, technological supremacy, cyberwarfare dominance and 5G race. Detection of Rhetorical Frames from open sources can help us track the attitudes of governments or companies towards AI, specifically whether attitudes are becoming more cooperative or competitive over time. Given the rapidly increasing volumes of open sources (online news media, twitter, blogs), it is difficult for subject matter experts to identify Rhetorical Frames in (near) real-time. Moreover, these sources are in general unstructured (noisy) and therefore, detecting Frames from these sources will require state-of-the-art text classification techniques. In this paper, we develop RheFrameDetect, a text classification system for (near) real-time capture of Rhetorical Frames from open sources. Given an input document, RheFrameDetect employs text classification techniques at multiple levels (document level and paragraph level) to identify all occurrences of Frames used in the discussion of AI. We performed extensive evaluation of the text classification techniques used in RheFrameDetect against human annotated Frames from multiple news sources. To further demonstrate the effectiveness of RheFrameDetect, we show multiple case studies depicting the Frames identified by RheFrameDetect compared against human annotated Frames.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Ghosh, Saurav and Loustaunau, Philippe},
	month = dec,
	year = {2021},
	note = {arXiv:2112.14933 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{yang_kolmogorov-arnold_2024,
	title = {Kolmogorov-{Arnold} {Transformer}},
	url = {http://arxiv.org/abs/2409.10594},
	doi = {10.48550/arXiv.2409.10594},
	abstract = {Transformers stand as the cornerstone of mordern deep learning. Traditionally, these models rely on multi-layer perceptron (MLP) layers to mix the information between channels. In this paper, we introduce the Kolmogorov-Arnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model. Integrating KANs into transformers, however, is no easy feat, especially when scaled up. Specifically, we identify three key challenges: (C1) Base function. The standard B-spline function used in KANs is not optimized for parallel computing on modern hardware, resulting in slower inference speeds. (C2) Parameter and Computation Inefficiency. KAN requires a unique function for each input-output pair, making the computation extremely large. (C3) Weight initialization. The initialization of weights in KANs is particularly challenging due to their learnable activation functions, which are critical for achieving convergence in deep neural networks. To overcome the aforementioned challenges, we propose three key solutions: (S1) Rational basis. We replace B-spline functions with rational functions to improve compatibility with modern GPUs. By implementing this in CUDA, we achieve faster computations. (S2) Group KAN. We share the activation weights through a group of neurons, to reduce the computational load without sacrificing performance. (S3) Variance-preserving initialization. We carefully initialize the activation weights to make sure that the activation variance is maintained across layers. With these designs, KAT scales effectively and readily outperforms traditional MLP-based transformers.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Yang, Xingyi and Wang, Xinchao},
	month = sep,
	year = {2024},
	note = {arXiv:2409.10594 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@misc{behrouz_titans_2024,
	title = {Titans: {Learning} to {Memorize} at {Test} {Time}},
	shorttitle = {Titans},
	url = {http://arxiv.org/abs/2501.00663},
	doi = {10.48550/arXiv.2501.00663},
	abstract = {Over more than a decade there has been an extensive research effort on how to effectively utilize recurrent models and attention. While recurrent models aim to compress the data into a fixed-size memory (called hidden state), attention allows attending to the entire context window, capturing the direct dependencies of all tokens. This more accurate modeling of dependencies, however, comes with a quadratic cost, limiting the model to a fixed-length context. We present a new neural long-term memory module that learns to memorize historical context and helps attention to attend to the current context while utilizing long past information. We show that this neural memory has the advantage of fast parallelizable training while maintaining a fast inference. From a memory perspective, we argue that attention due to its limited context but accurate dependency modeling performs as a short-term memory, while neural memory due to its ability to memorize the data, acts as a long-term, more persistent, memory. Based on these two modules, we introduce a new family of architectures, called Titans, and present three variants to address how one can effectively incorporate memory into this architecture. Our experimental results on language modeling, common-sense reasoning, genomics, and time series tasks show that Titans are more effective than Transformers and recent modern linear recurrent models. They further can effectively scale to larger than 2M context window size with higher accuracy in needle-in-haystack tasks compared to baselines.},
	urldate = {2025-01-21},
	publisher = {arXiv},
	author = {Behrouz, Ali and Zhong, Peilin and Mirrokni, Vahab},
	month = dec,
	year = {2024},
	note = {arXiv:2501.00663 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{nyman_news_2021,
	title = {News and narratives in financial systems: {Exploiting} big data for systemic risk assessment},
	volume = {127},
	issn = {0165-1889},
	shorttitle = {News and narratives in financial systems},
	url = {https://www.sciencedirect.com/science/article/pii/S0165188921000543},
	doi = {10.1016/j.jedc.2021.104119},
	abstract = {This paper applies algorithmic analysis to financial market text-based data to assess how narratives and sentiment might drive financial system developments. We find changes in emotional content in narratives are highly correlated across data sources and show the formation (and subsequent collapse) of exuberance prior to the global financial crisis. Our metrics also have predictive power for other commonly used indicators of sentiment and appear to influence economic variables. A novel machine learning application also points towards increasing consensus around the strongly positive narrative prior to the crisis. Together, our metrics might help to warn about impending financial system distress.},
	urldate = {2025-01-21},
	journal = {Journal of Economic Dynamics and Control},
	author = {Nyman, Rickard and Kapadia, Sujit and Tuckett, David},
	month = jun,
	year = {2021},
	keywords = {Big data, Early warning indicators, Narratives, Sentiment, Systemic risk, Text mining, Uncertainty},
	pages = {104119},
}

@techreport{ward_identifying_2022,
	title = {Identifying {Disinformation} {Using} {Rhetorical} {Devices} in {Natural} {Language} {Models}},
	url = {https://www.osti.gov/servlets/purl/1891194/},
	abstract = {Foreign disinformation campaigns are strategically organized, extended efforts using disinformation – false or misleading information deliberately placed by an adversary – to achieve some goal. Disinformation campaigns pose severe threats to our nation’s security by misinforming decision makers and negatively influencing their actions when they are operating on limited amounts of evidence. Current efforts rely on subject matter experts to manually identify disinformation [1] [2], or on computers and traditional natural language processing algorithms to identify patterns in data to calculate the probability that something is disinformation or not. While both have their merits and successes, subject matter experts are unable to keep up with the high volumes of global information and traditional natural language algorithms do not do well in identifying “why” something is disinformation or not. Our hypothesis is that we can identify disinformation by looking at the way someone speaks, in the rhetorical devices they use. We have curated and annotated a dataset designed for multiple natural language processing tasks, but specifically useful for disinformation detection algorithms.},
	language = {en},
	number = {SAND2022-13730, 1891194, 710638},
	urldate = {2025-01-21},
	author = {Ward, Katrina and Link, Hamilton and Avramov, Kiril and Goodwin, Jean},
	month = sep,
	year = {2022},
	doi = {10.2172/1891194},
	pages = {SAND2022--13730, 1891194, 710638},
}

@inproceedings{volpetti_temporal_2020,
	address = {Shenzhen China},
	title = {Temporal {Word} {Embeddings} for {Narrative} {Understanding}},
	isbn = {978-1-4503-7642-6},
	url = {https://dl.acm.org/doi/10.1145/3383972.3383988},
	doi = {10.1145/3383972.3383988},
	abstract = {We propose temporal word embeddings as a suitable tool to study the evolution of characters and their sentiments across the plot of a narrative text. The dynamic evolution of instances within a narrative text is a challenging task, where complex behavioral evolutions and other characteristics specific to the narrative text need to be inferred and interpreted. While starting from an existing approach to the learning of these models, we propose an alternative initialization procedure which seems to be especially suited for the case of narrative text. As a validation benchmark, we use the Harry Potter series of books as a challenging case study for such character trait evolution. A benchmark data set based on temporal word analogies related to the characters in the plot of the series is considered. The results are promising, and the empirical validation seems to support the working ideas behind this proposal.},
	language = {en},
	urldate = {2025-01-21},
	booktitle = {Proceedings of the 2020 12th {International} {Conference} on {Machine} {Learning} and {Computing}},
	publisher = {ACM},
	author = {Volpetti, Claudia and Vani, K. and Antonucci, Alessandro},
	month = feb,
	year = {2020},
	pages = {68--72},
}

@book{shiller_narrative_2019,
	address = {Princeton},
	series = {Book collections on project {MUSE}},
	title = {Narrative economics: how stories go viral \& drive major economic events},
	isbn = {978-0-691-18229-2},
	shorttitle = {Narrative economics},
	abstract = {Economists have long based their forecasts on financial aggregates such as price-earnings ratios, asset prices, and exchange rate fluctuations, and used them to produce statistically informed speculations about the future, with limited success. Robert Shiller employs such aggregates in his own forecasts, but has famously complemented them with observations about the influence of mass psychology on certain events. This approach has come to be known as behavioral economics. How can economists effectively capture the effects of psychology and its influence on economic events and change? Shiller attempts to help us better understand how psychology affects events by explaining how popular economic stories arise, how they grow viral, and ultimately how they drive economic developments. After defining narrative economics in the book's preface with allusions to the advent of both the Great Depression and to World War II, Shiller presents an example of a recent economic narrative gone viral in the story of Bitcoin. Next, he explains how narrative economics works with reference to how other disciplines incorporate narrative into their analyses and also to how epidemiology explains how disease goes viral. He then presents accounts of recurring economic narratives, including the gold standard, real estate booms, war and depression, and stock market boom and crashes. He ends his book with a blueprint for future research by economists on narrative economics},
	language = {eng},
	publisher = {Princeton University press},
	author = {Shiller, Robert James},
	year = {2019},
}

@misc{lorenz_drift_2013,
	title = {Drift dependence of optimal trade execution strategies under transient price impact},
	url = {http://arxiv.org/abs/1204.2716},
	doi = {10.48550/arXiv.1204.2716},
	abstract = {We give a complete solution to the problem of minimizing the expected liquidity costs in presence of a general drift when the underlying market impact model has linear transient price impact with exponential resilience. It turns out that this problem is well-posed only if the drift is absolutely continuous. Optimal strategies often do not exist, and when they do, they depend strongly on the derivative of the drift. Our approach uses elements from singular stochastic control, even though the problem is essentially non-Markovian due to the transience of price impact and the lack in Markovian structure of the underlying price process. As a corollary, we give a complete solution to the minimization of a certain cost-risk criterion in our setting.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Lorenz, Christopher and Schied, Alexander},
	month = mar,
	year = {2013},
	note = {arXiv:1204.2716},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@article{almgren_optimal_2001,
	title = {Optimal execution of portfolio transactions},
	volume = {3},
	issn = {14651211},
	url = {http://www.risk.net/journal-of-risk/technical-paper/2161150/optimal-execution-portfolio-transactions},
	doi = {10.21314/JOR.2001.041},
	abstract = {We consider the execution of portfolio transactions with the aim of minimizing a combination of volatility risk and transaction costs arising from permanent and temporary market impact. For a simple linear cost model, we explicitly construct the eﬃcient frontier in the space of time-dependent liquidation strategies, which have minimum expected cost for a given level of uncertainty. We may then select optimal strategies either by minimizing a quadratic utility function, or by minimizing Value at Risk. The latter choice leads to the concept of Liquidity-adjusted VAR, or L-VaR, that explicitly considers the best tradeoﬀ between volatility risk and liquidation costs.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {The Journal of Risk},
	author = {Almgren, Robert and Chriss, Neil},
	month = jan,
	year = {2001},
	pages = {5--39},
}

@inproceedings{hutchison_evolving_2010,
	address = {Berlin, Heidelberg},
	title = {Evolving {Dynamic} {Trade} {Execution} {Strategies} {Using} {Grammatical} {Evolution}},
	volume = {6025},
	isbn = {978-3-642-12241-5 978-3-642-12242-2},
	url = {http://link.springer.com/10.1007/978-3-642-12242-2_20},
	doi = {10.1007/978-3-642-12242-2_20},
	abstract = {Although there is a plentiful literature on the use of evolutionary methodologies for the trading of financial assets, little attention has been paid to potential use of these methods for efficient trade execution. Trade execution is concerned with the actual mechanics of buying or selling the desired amount of a financial instrument of interest. Grammatical Evolution (GE) is an evolutionary automatic programming methodology which can be used to evolve rule sets. In this paper we use a GE algorithm to discover dynamic, efficient, trade execution strategies which adapt to changing market conditions. The strategies are tested in an artificial limit order market. GE was found to be able to evolve quality trade execution strategies which are highly competitive with two benchmark trade execution strategies.},
	urldate = {2024-10-31},
	publisher = {Springer Berlin Heidelberg},
	author = {Cui, Wei and Brabazon, Anthony and O’Neill, Michael},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Di Chio, Cecilia and Brabazon, Anthony and Di Caro, Gianni A. and Ebner, Marc and Farooq, Muddassar and Fink, Andreas and Grahl, Jörn and Greenfield, Gary and Machado, Penousal and O’Neill, Michael and Tarantino, Ernesto and Urquhart, Neil},
	year = {2010},
	doi = {10.1007/978-3-642-12242-2_20},
	note = {Book Title: Applications of Evolutionary Computation
Series Title: Lecture Notes in Computer Science},
	pages = {192--201},
}

@misc{ackermann_optimal_2021,
	title = {Optimal trade execution in an order book model with stochastic liquidity parameters},
	url = {http://arxiv.org/abs/2006.05843},
	doi = {10.48550/arXiv.2006.05843},
	abstract = {We analyze an optimal trade execution problem in a financial market with stochastic liquidity. To this end we set up a limit order book model in which both order book depth and resilience evolve randomly in time. Trading is allowed in both directions and at discrete points in time. We derive an explicit recursion that, under certain structural assumptions, characterizes minimal execution costs. We also discuss several qualitative aspects of optimal strategies, such as existence of profitable round trips or closing the position in one go, and compare our findings with the literature.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Ackermann, Julia and Kruse, Thomas and Urusov, Mikhail},
	month = apr,
	year = {2021},
	note = {arXiv:2006.05843},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@article{cheridito_optimal_2014,
	title = {Optimal {Trade} {Execution} {Under} {Stochastic} {Volatility} and {Liquidity}},
	volume = {21},
	issn = {1350-486X},
	url = {https://doi.org/10.1080/1350486X.2014.881005},
	doi = {10.1080/1350486X.2014.881005},
	abstract = {We study the problem of optimally liquidating a financial position in a discrete-time model with stochastic volatility and liquidity. We consider the three cases where the objective is to minimize the expectation, an expected exponential or a mean-variance criterion of the implementation cost. In the first case, the optimal solution can be fully characterized by a forward-backward system of stochastic equations depending on conditional expectations of future liquidity. In the other two cases, we derive Bellman equations from which the optimal solutions can be obtained numerically by discretizing the control space. In all three cases, we compute optimal strategies for different simulated realizations of prices, volatility and liquidity and compare the outcomes to the ones produced by the deterministic strategies of Bertsimas and Lo (1998; Optimal control of execution costs. Journal of Financial Markets, 1, 1–50) and Almgren and Chriss (2001; Optimal execution of portfolio transactions. Journal of Risk, 3, 5–33).},
	number = {4},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Cheridito, Patrick and Sepin, Tardu},
	month = jul,
	year = {2014},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2014.881005},
	keywords = {Bellman equation, Optimal trade execution, discrete-time stochastic control, implementation cost, stochastic liquidity, stochastic volatility},
	pages = {342--362},
}

@article{fruth_optimal_2019,
	title = {Optimal trade execution in order books with stochastic liquidity},
	volume = {29},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12180},
	doi = {10.1111/mafi.12180},
	abstract = {In financial markets, liquidity changes randomly over time. We consider such random variations of the depth of the order book and evaluate their influence on optimal trade execution strategies. If the stochastic structure of liquidity changes satisfies certain conditions, then the unique optimal trading strategy exhibits a conventional structure with a single wait region and a single buy region, and profitable round-trip strategies do not exist. In other cases, optimal strategies can feature multiple wait regions and optimal trade sizes that can be decreasing in the size of the position to be liquidated. Furthermore, round-trip strategies can be profitable depending on bid–ask spread assumptions. We illustrate our findings with several examples including the Cox–Ingersoll–Ross model for the evolution of liquidity.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Fruth, Antje and Schöneborn, Torsten and Urusov, Mikhail},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12180},
	keywords = {limit order book, market impact model, optimal order execution, profitable round trip trading strategies, resilience, stochastic order book depth, time-varying liquidity},
	pages = {507--541},
}

@article{gueant_optimal_2015,
	title = {Optimal {Execution} and {Block} {Trade} {Pricing}: {A} {General} {Framework}},
	volume = {22},
	issn = {1350-486X},
	shorttitle = {Optimal {Execution} and {Block} {Trade} {Pricing}},
	url = {https://doi.org/10.1080/1350486X.2015.1042188},
	doi = {10.1080/1350486X.2015.1042188},
	abstract = {In this article, we develop a general framework to study optimal execution and to price block trades. We prove existence of optimal liquidation strategies and provide regularity results for optimal strategies under very general hypotheses. We exhibit a Hamiltonian characterization for the optimal strategy that can be used for numerical approximation. We also focus on the important topic of block trade pricing and propose a methodology to give a price to financial (il)liquidity. In particular, we provide a closed-form formula for the price of a block trade when there is no time constraint to liquidate.},
	number = {4},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Guéant, Olivier},
	month = jul,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2015.1042188},
	keywords = {Hamilton-Jacobi equations, Optimal execution, block trade pricing, viscosity solutions},
	pages = {336--365},
}

@misc{graewe_optimal_2017,
	title = {Optimal {Trade} {Execution} with {Instantaneous} {Price} {Impact} and {Stochastic} {Resilience}},
	url = {http://arxiv.org/abs/1611.03435},
	doi = {10.48550/arXiv.1611.03435},
	abstract = {We study an optimal execution problem in illiquid markets with both instantaneous and persistent price impact and stochastic resilience when only absolutely continuous trading strategies are admissible. In our model the value function can be described by a three-dimensional system of backward stochastic differential equations (BSDE) with a singular terminal condition in one component. We prove existence and uniqueness of a solution to the BSDE system and characterize both the value function and the optimal strategy in terms of the unique solution to the BSDE system. Our existence proof is based on an asymptotic expansion of the BSDE system at the terminal time that allows us to express the system in terms of a equivalent system with finite terminal value but singular driver.},
	urldate = {2024-10-31},
	publisher = {arXiv},
	author = {Graewe, Paulwin and Horst, Ulrich},
	month = jul,
	year = {2017},
	note = {arXiv:1611.03435},
	keywords = {Mathematics - Optimization and Control, Mathematics - Probability, Quantitative Finance - Trading and Market Microstructure},
}

@misc{ohnishi_trade_2024,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Trade {Execution} {Games} in a {Markovian} {Environment}},
	url = {https://papers.ssrn.com/abstract=4818028},
	doi = {10.2139/ssrn.4818028},
	abstract = {This paper examines a trade execution game for two large traders in a generalized price impact model. We incorporate a stochastic and sequentially dependent factor that exogenously affects the market price into financial markets. Our model accounts for how strategic and environmental uncertainties affect the large traders' execution strategies. We formulate an expected utility maximization problem for two large traders as a Markov game model. Applying the backward induction method of dynamic programming, we provide an explicit closed-form execution strategy at a Markov perfect equilibrium. Our theoretical results reveal that the execution strategy generally lies in a dynamic and non-randomized class; it becomes deterministic if the Markovian environment is also deterministic. In addition, our simulation-based numerical experiments suggest that the execution strategy captures various features observed in financial markets.},
	language = {en},
	urldate = {2024-10-31},
	publisher = {Social Science Research Network},
	author = {Ohnishi, Masamitsu and Shimoshimizu, Makoto},
	month = may,
	year = {2024},
	keywords = {Backward induction, Dynamic programming, Markov perfect equilibrium, Markovian environment, Price Impact, Trade execution game},
}

@article{kissell_practical_2004,
	title = {A practical framework for estimating transaction costs and developing optimal trading strategies to achieve best execution},
	volume = {1},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {15446123},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1544612303000047},
	doi = {10.1016/S1544-6123(03)00004-7},
	abstract = {In this paper we provide both a decision framework to estimate transaction costs and develop optimal trading strategies to achieve best execution. The methodology is based on an unbundling approach whereby costs are categorized into transparent and hidden, and ﬁxed and variable components. The classiﬁcation serves as the foundation for developing execution strategies for a fund’s implementation goals. For example, the methodology easily adapts to strategies aimed at preserving asset value, achieving the closing price or volume weighted average price (“VWAP”), and minimizing tracking error. Further, we show how to determine the best execution strategy (“BES”) from a set of optimal strategies given a fund’s goal and objectives via a set of decision-making criteria. Ultimately, best execution translates to lower transaction costs and higher portfolio returns.},
	language = {en},
	number = {1},
	urldate = {2024-10-31},
	journal = {Finance Research Letters},
	author = {Kissell, Robert and Glantz, Morton and Malamut, Roberto},
	month = mar,
	year = {2004},
	pages = {35--46},
}

@article{almgren_optimal_2003,
	title = {Optimal execution with nonlinear impact functions and trading-enhanced risk},
	volume = {10},
	issn = {1350-486X},
	url = {https://doi.org/10.1080/135048602100056},
	doi = {10.1080/135048602100056},
	abstract = {Optimal trading strategies are determined for liquidation of a large single-asset portfolio to minimize a combination of volatility risk and market impact costs. The market impact cost per share is taken to be a power law function of the trading rate, with an arbitrary positive exponent. This includes, for example, the square root law that has been proposed based on market microstructure theory. In analogy to the linear model, a ‘characteristic time’ for optimal trading is defined, which now depends on the initial portfolio size and decreases as execution proceeds. A model is also considered in which uncertainty of the realized price is increased by demanding rapid execution; it is shown that optimal trajectories are described by a ‘critical portfolio size’ above which this effect is dominant and below which it may be neglected.},
	number = {1},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Almgren, Robert F.},
	month = jan,
	year = {2003},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/135048602100056},
	keywords = {Liquidity Modeling, Market Impact, Trading Strategy},
	pages = {1--18},
}

@article{donnelly_optimal_2022,
	title = {Optimal {Execution}: {A} {Review}},
	volume = {29},
	issn = {1350-486X},
	shorttitle = {Optimal {Execution}},
	url = {https://doi.org/10.1080/1350486X.2022.2161588},
	doi = {10.1080/1350486X.2022.2161588},
	abstract = {This review article is intended to collect and summarize many of the results in the field of optimal execution over the last twenty years. In doing so, we describe the general workings of the limit order book so that the sources of costs and risks which need to be optimized are understood. The initial models considered propose simple dynamics for prices which allow easily computable strategies which maximize risk-adjusted profits. Subsequently, the review is divided into two major parts. The first explores several works which investigate how optimal liquidation strategies are modified to account for more complex dynamics, namely other stochastic or non-linear factors. The second presents optimal trading strategies when the agent utilizes benchmarks in addition to risk-adjusted wealth, or when she has objectives beyond optimal liquidation.},
	number = {3},
	urldate = {2024-10-31},
	journal = {Applied Mathematical Finance},
	author = {Donnelly, Ryan},
	month = may,
	year = {2022},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/1350486X.2022.2161588},
	keywords = {Algorithmic trading, price impact, stochastic optimization},
	pages = {181--212},
}

@article{guilbaud_optimal_2013,
	title = {Optimal high-frequency trading with limit and market orders},
	volume = {13},
	issn = {1469-7688},
	url = {https://doi.org/10.1080/14697688.2012.708779},
	doi = {10.1080/14697688.2012.708779},
	abstract = {We propose a framework for studying optimal market-making policies in a limit order book (LOB). The bid–ask spread of the LOB is modeled by a tick-valued continuous-time Markov chain. We consider a small agent who continuously submits limit buy/sell orders at best bid/ask quotes, and may also set limit orders at best bid (resp. ask) plus (resp. minus) a tick for obtaining execution order priority, which is a crucial issue in high-frequency trading. The agent faces an execution risk since her limit orders are executed only when they meet counterpart market orders. She is also subject to inventory risk due to price volatility when holding the risky asset. The agent can then also choose to trade with market orders, and therefore obtain immediate execution, but at a less favorable price. The objective of the market maker is to maximize her expected utility from revenue over a short-term horizon by a trade-off between limit and market orders, while controlling her inventory position. This is formulated as a mixed regime switching regular/impulse control problem that we characterize in terms of a quasi-variational system by dynamic programming methods. Calibration procedures are derived for estimating the transition matrix and intensity parameters for the spread and for Cox processes modelling the execution of limit orders. We provide an explicit backward splitting scheme for solving the problem and show how it can be reduced to a system of simple equations involving only the inventory and spread variables. Several computational tests are performed both on simulated and real data, and illustrate the impact and profit when considering execution priority in limit orders and market orders.},
	number = {1},
	urldate = {2024-10-31},
	journal = {Quantitative Finance},
	author = {Guilbaud, Fabien and Pham, Huyên},
	month = jan,
	year = {2013},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14697688.2012.708779},
	keywords = {Applied mathematical finance, G1, G10, G11, Market microstructure, Portfolio optimization, Quantitative finance techniques, Stochastic control, Trading strategies},
	pages = {79--94},
}

@article{cartea_optimal_2015,
	title = {Optimal execution with limit and market orders},
	volume = {15},
	issn = {1469-7688},
	url = {https://doi.org/10.1080/14697688.2015.1032543},
	doi = {10.1080/14697688.2015.1032543},
	abstract = {We develop an optimal execution policy for an investor seeking to execute a large order using limit and market orders. The investor solves the optimal policy considering different restrictions on volume of both types of orders and depth at which limit orders are posted. We show how the execution policies perform when targeting the volume schedule of the Almgren–Chriss execution strategy. The different strategies considered by the investor outperform the Almgren–Chriss price with an average savings per share of about one to two and a half times the spread. This improvement over Almgren–Chriss is due to the strategies benefiting from the optimal mix of limit orders, which earn the spread and market orders, which keep the investor’s inventory schedule on target.},
	number = {8},
	urldate = {2024-10-31},
	journal = {Quantitative Finance},
	author = {Cartea, Álvaro and Jaimungal, Sebastian},
	month = aug,
	year = {2015},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14697688.2015.1032543},
	keywords = {Acquisition, Algorithmic trading, High-frequency trading, Impulse control, Liquidation, TWAP},
	pages = {1279--1291},
}

@article{fruth_optimal_2019-1,
	title = {Optimal trade execution in order books with stochastic liquidity},
	volume = {29},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12180},
	doi = {10.1111/mafi.12180},
	abstract = {In financial markets, liquidity changes randomly over time. We consider such random variations of the depth of the order book and evaluate their influence on optimal trade execution strategies. If the stochastic structure of liquidity changes satisfies certain conditions, then the unique optimal trading strategy exhibits a conventional structure with a single wait region and a single buy region, and profitable round-trip strategies do not exist. In other cases, optimal strategies can feature multiple wait regions and optimal trade sizes that can be decreasing in the size of the position to be liquidated. Furthermore, round-trip strategies can be profitable depending on bid–ask spread assumptions. We illustrate our findings with several examples including the Cox–Ingersoll–Ross model for the evolution of liquidity.},
	language = {en},
	number = {2},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Fruth, Antje and Schöneborn, Torsten and Urusov, Mikhail},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12180},
	keywords = {limit order book, market impact model, optimal order execution, profitable round trip trading strategies, resilience, stochastic order book depth, time-varying liquidity},
	pages = {507--541},
}

@article{dixon_high-frequency_2018,
	title = {A high-frequency trade execution model for supervised learning},
	volume = {1},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {2470-6981},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hf2.10016},
	doi = {10.1002/hf2.10016},
	abstract = {This article introduces a high-frequency trade execution model to evaluate the economic impact of supervised machine learners. Extending the concept of a confusion matrix, we present a “trade information matrix” to attribute the expected profit and loss of the high-frequency strategy under execution constraints, such as fill probabilities and position dependent trade rules, to correct and incorrect predictions. We apply the trade execution model and trade information matrix to Level II E-mini S\&P 500 futures history and demonstrate an estimation approach for measuring the sensitivity of the P\&L to the error of a recurrent neural network. Our approach directly evaluates the performance sensitivity of a market-making strategy to prediction error and augments traditional market simulation-based testing.},
	language = {en},
	number = {1},
	urldate = {2024-10-31},
	journal = {High Frequency},
	author = {Dixon, Matthew},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hf2.10016},
	keywords = {execution model, high frequency trading, market making, recurrent neural networks, supervised learning},
	pages = {32--52},
}

@article{bayraktar_optimal_2011,
	title = {Optimal {Trade} {Execution} in {Illiquid} {Markets}},
	volume = {21},
	copyright = {© 2010 Wiley Periodicals, Inc.},
	issn = {1467-9965},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9965.2010.00446.x},
	doi = {10.1111/j.1467-9965.2010.00446.x},
	abstract = {We study optimal trade execution strategies in financial markets with discrete order flow. The agent has a finite liquidation horizon and must minimize price impact given a random number of incoming trade counterparties. Assuming that the order flow N is given by a Poisson process, we give a full analysis of the properties and computation of the optimal dynamic execution strategy. Extensions, whereby N is a Markov-modulated compound Poisson process are also considered. We derive and compare the properties of the various cases and illustrate our results with computational examples.},
	language = {en},
	number = {4},
	urldate = {2024-10-31},
	journal = {Mathematical Finance},
	author = {Bayraktar, Erhan and Ludkovski, Michael},
	year = {2011},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9965.2010.00446.x},
	keywords = {Markov-modulated Poisson process, dark pools, liquidity modeling, optimal order execution},
	pages = {681--701},
}

@article{bessembinder_issues_nodate,
	title = {Issues in assessing trade execution costs\$},
	abstract = {This study assesses the sensitivity of trading cost estimates derived from publicly-available trade and quote data to two methodological issues: the time adjustment made before comparing trades to quotes, and the procedure used to designate trades as buyer or sellerinitiated. The results indicate that making no allowance for trade reporting lags is optimal when assessing whether trades are buyer or seller initiated, for both Nasdaq and NYSE stocks. However, trade prices are best compared to earlier quotations when assessing trade execution costs, in order to capture the effect of systematic quotation revisions in the seconds before trades are reported. A technique for inferring trade direction recommended by Ellis et al. (J. Financial Quant. Anal. 35 (2000) 529) leads to signiﬁcantly smaller estimates of trading costs than the well-known Lee and Ready (J. Finance 46 (1991) 733) algorithm. Despite the sensitivity of trading cost measures to these methodological issues, inference as to whether the Nasdaq dealer market or the NYSE auction market provides lower trade execution costs is not sensitive.},
	language = {en},
	author = {Bessembinder, Hendrik},
}

@misc{noauthor_updating_2018,
	title = {Updating {Chrome} extension},
	url = {https://forums.zotero.org/discussion/69790/updating-chrome-extension},
	abstract = {Zotero is a free, easy-to-use tool to help you collect, organize, annotate, cite, and share research.},
	language = {en},
	urldate = {2024-10-03},
	journal = {Zotero Forums},
	month = jan,
	year = {2018},
}
